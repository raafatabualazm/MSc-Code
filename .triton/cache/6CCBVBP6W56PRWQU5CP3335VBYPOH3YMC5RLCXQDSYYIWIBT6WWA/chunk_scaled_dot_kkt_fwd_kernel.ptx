//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel // -- Begin function chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @chunk_scaled_dot_kkt_fwd_kernel
.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 .ptr .global .align 1 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 .ptr .global .align 1 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 .ptr .global .align 1 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 .ptr .global .align 1 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u64 .ptr .global .align 1 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.reqntid 64
{
	.reg .pred 	%p<82>;
	.reg .b16 	%rs<18>;
	.reg .b32 	%r<2651>;
	.reg .b64 	%rd<139>;
	.loc	1 28 0                          // chunk_scaled_dot_kkt.py:28:0
$L__func_begin0:
	.loc	1 28 0                          // chunk_scaled_dot_kkt.py:28:0

// %bb.0:
	ld.param.b64 	%rd35, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.b64 	%rd36, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 43 30                         // chunk_scaled_dot_kkt.py:43:30
	mov.u32 	%r2082, %ctaid.x;
	ld.param.b64 	%rd37, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	.loc	1 43 48                         // chunk_scaled_dot_kkt.py:43:48
	mov.u32 	%r2083, %ctaid.y;
	.loc	1 50 25                         // chunk_scaled_dot_kkt.py:50:25
	and.b32 	%r2084, %r2083, 65504;
	ld.param.b64 	%rd38, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 44 33                         // chunk_scaled_dot_kkt.py:44:33
	and.b32 	%r2085, %r2083, 31;
	ld.param.b32 	%r2086, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 51 16                         // chunk_scaled_dot_kkt.py:51:16
	shl.b32 	%r2087, %r2082, 6;
	.loc	1 51 34                         // chunk_scaled_dot_kkt.py:51:34
	mov.u32 	%r2088, %tid.x;
	and.b32 	%r2089, %r2088, 16;
	shr.u32 	%r2090, %r2088, 4;
	bfe.u32 	%r2091, %r2088, 4, 2;
	or.b32 	%r2092, %r2091, 4;
	or.b32 	%r2093, %r2091, 8;
	or.b32 	%r2094, %r2091, 12;
	or.b32 	%r2095, %r2091, 16;
	or.b32 	%r2096, %r2091, 20;
	or.b32 	%r2097, %r2091, 24;
	or.b32 	%r2098, %r2091, 28;
	or.b32 	%r2099, %r2091, 32;
	or.b32 	%r2100, %r2091, 36;
	or.b32 	%r2101, %r2091, 40;
	or.b32 	%r2102, %r2091, 44;
	or.b32 	%r2103, %r2091, 48;
	or.b32 	%r2104, %r2091, 52;
	or.b32 	%r2105, %r2091, 56;
	or.b32 	%r2106, %r2090, 60;
	bfe.s32 	%r2107, %r2088, 2, 1;
	and.b32 	%r2108, %r2088, 4;
	and.b32 	%r2109, %r2088, 8;
	shr.u32 	%r2110, %r2088, 2;
	bfe.u32 	%r2111, %r2088, 2, 2;
	shr.u32 	%r2112, %r2089, 2;
	shl.b32 	%r2113, %r2088, 1;
	and.b32 	%r2114, %r2113, 6;
	and.b32 	%r2115, %r2110, 8;
	shl.b32 	%r2116, %r2088, 2;
	and.b32 	%r2117, %r2116, 60;
	and.b32 	%r2118, %r2088, 63;
	or.b32 	%r2119, %r2111, %r2112;
	or.b32 	%r2120, %r2119, 8;
	or.b32 	%r2121, %r2119, 16;
	or.b32 	%r2122, %r2119, 24;
	or.b32 	%r2123, %r2119, 32;
	or.b32 	%r2124, %r2119, 40;
	or.b32 	%r2125, %r2119, 48;
	or.b32 	%r2126, %r2119, 56;
	or.b32 	%r2127, %r2114, %r2115;
	or.b32 	%r2128, %r2127, 1;
	or.b32 	%r2129, %r2127, 16;
	or.b32 	%r2130, %r2127, 17;
	or.b32 	%r2131, %r2127, 32;
	or.b32 	%r2132, %r2127, 33;
	or.b32 	%r2133, %r2127, 48;
	or.b32 	%r2134, %r2127, 49;
	.loc	1 51 21                         // chunk_scaled_dot_kkt.py:51:21
	or.b32 	%r2135, %r2127, %r2087;
	or.b32 	%r2136, %r2119, %r2087;
	or.b32 	%r2137, %r2128, %r2087;
	or.b32 	%r2138, %r2120, %r2087;
	or.b32 	%r2139, %r2121, %r2087;
	or.b32 	%r2140, %r2122, %r2087;
	or.b32 	%r2141, %r2129, %r2087;
	or.b32 	%r2142, %r2130, %r2087;
	or.b32 	%r2143, %r2123, %r2087;
	or.b32 	%r2144, %r2124, %r2087;
	or.b32 	%r2145, %r2131, %r2087;
	or.b32 	%r2146, %r2132, %r2087;
	or.b32 	%r2147, %r2125, %r2087;
	or.b32 	%r2148, %r2126, %r2087;
	or.b32 	%r2149, %r2133, %r2087;
	or.b32 	%r2150, %r2134, %r2087;
	.loc	1 52 16                         // chunk_scaled_dot_kkt.py:52:16
	setp.lt.s32 	%p35, %r2150, %r2086;
	setp.lt.s32 	%p36, %r2149, %r2086;
	setp.lt.s32 	%p37, %r2148, %r2086;
	setp.lt.s32 	%p38, %r2147, %r2086;
	setp.lt.s32 	%p39, %r2146, %r2086;
	setp.lt.s32 	%p40, %r2145, %r2086;
	setp.lt.s32 	%p41, %r2144, %r2086;
	setp.lt.s32 	%p42, %r2143, %r2086;
	setp.lt.s32 	%p43, %r2142, %r2086;
	setp.lt.s32 	%p44, %r2141, %r2086;
	setp.lt.s32 	%p45, %r2140, %r2086;
	setp.lt.s32 	%p46, %r2139, %r2086;
	setp.lt.s32 	%p47, %r2138, %r2086;
	setp.lt.s32 	%p48, %r2137, %r2086;
	setp.lt.s32 	%p49, %r2136, %r2086;
	setp.lt.s32 	%p50, %r2135, %r2086;
	.loc	1 54 42                         // chunk_scaled_dot_kkt.py:54:42
	mul.lo.s32 	%r2151, %r2084, %r2086;
	.loc	1 54 38                         // chunk_scaled_dot_kkt.py:54:38
	mul.wide.s32 	%rd39, %r2151, 2;
	add.s64 	%rd40, %rd37, %rd39;
	.loc	1 54 46                         // chunk_scaled_dot_kkt.py:54:46
	mul.wide.u32 	%rd41, %r2085, 2;
	add.s64 	%rd42, %rd40, %rd41;
	.loc	1 54 83                         // chunk_scaled_dot_kkt.py:54:83
	cvt.s64.s32 	%rd43, %r2086;
	cvt.s64.s32 	%rd44, %r2087;
	.loc	1 55 21                         // chunk_scaled_dot_kkt.py:55:21
	cvt.u64.u32 	%rd45, %r2091;
	cvt.u64.u32 	%rd46, %r2092;
	cvt.u64.u32 	%rd47, %r2093;
	cvt.u64.u32 	%rd48, %r2094;
	cvt.u64.u32 	%rd49, %r2095;
	cvt.u64.u32 	%rd50, %r2096;
	cvt.u64.u32 	%rd51, %r2097;
	cvt.u64.u32 	%rd52, %r2098;
	cvt.u64.u32 	%rd53, %r2099;
	cvt.u64.u32 	%rd54, %r2100;
	cvt.u64.u32 	%rd55, %r2101;
	cvt.u64.u32 	%rd56, %r2102;
	cvt.u64.u32 	%rd57, %r2103;
	cvt.u64.u32 	%rd58, %r2104;
	cvt.u64.u32 	%rd59, %r2105;
	cvt.u64.u32 	%rd60, %r2106;
	cvt.u64.u32 	%rd61, %r2118;
	or.b64 	%rd62, %rd45, %rd44;
	or.b64 	%rd63, %rd46, %rd44;
	or.b64 	%rd64, %rd47, %rd44;
	or.b64 	%rd65, %rd48, %rd44;
	or.b64 	%rd66, %rd49, %rd44;
	or.b64 	%rd67, %rd50, %rd44;
	or.b64 	%rd68, %rd51, %rd44;
	or.b64 	%rd69, %rd52, %rd44;
	or.b64 	%rd70, %rd53, %rd44;
	or.b64 	%rd71, %rd54, %rd44;
	or.b64 	%rd72, %rd55, %rd44;
	or.b64 	%rd73, %rd56, %rd44;
	or.b64 	%rd74, %rd57, %rd44;
	or.b64 	%rd75, %rd58, %rd44;
	or.b64 	%rd76, %rd59, %rd44;
	or.b64 	%rd77, %rd60, %rd44;
	or.b64 	%rd78, %rd44, %rd61;
	shl.b64 	%rd79, %rd78, 6;
	add.s64 	%rd1, %rd42, %rd79;
	setp.gt.s32 	%p51, %r2087, -1;
	setp.lt.s64 	%p52, %rd78, %rd43;
	and.pred 	%p1, %p51, %p52;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p1 ld.global.b16 { %rs1 }, [ %rd1 + 0 ];
	// end inline asm
	.loc	1 59 45                         // chunk_scaled_dot_kkt.py:59:45
	or.b32 	%r2152, %r2151, %r2085;
	.loc	1 59 52                         // chunk_scaled_dot_kkt.py:59:52
	shl.b32 	%r2153, %r2152, 7;
	.loc	1 59 36                         // chunk_scaled_dot_kkt.py:59:36
	mul.wide.s32 	%rd80, %r2153, 2;
	add.s64 	%rd81, %rd35, %rd80;
	.loc	1 60 22                         // chunk_scaled_dot_kkt.py:60:22
	shl.b32 	%r2154, %r2088, 3;
	and.b32 	%r2155, %r2154, 24;
	shl.b32 	%r2156, %r2108, 3;
	or.b32 	%r2157, %r2155, %r2156;
	shl.b32 	%r2158, %r2109, 3;
	or.b32 	%r2159, %r2157, %r2158;
	shl.b64 	%rd82, %rd62, 13;
	add.s64 	%rd83, %rd81, %rd82;
	mul.wide.u32 	%rd84, %r2159, 2;
	add.s64 	%rd2, %rd83, %rd84;
	shl.b64 	%rd85, %rd63, 13;
	add.s64 	%rd86, %rd81, %rd85;
	add.s64 	%rd3, %rd86, %rd84;
	shl.b64 	%rd87, %rd64, 13;
	add.s64 	%rd88, %rd81, %rd87;
	add.s64 	%rd4, %rd88, %rd84;
	shl.b64 	%rd89, %rd65, 13;
	add.s64 	%rd90, %rd81, %rd89;
	add.s64 	%rd5, %rd90, %rd84;
	shl.b64 	%rd91, %rd66, 13;
	add.s64 	%rd92, %rd81, %rd91;
	add.s64 	%rd6, %rd92, %rd84;
	shl.b64 	%rd93, %rd67, 13;
	add.s64 	%rd94, %rd81, %rd93;
	add.s64 	%rd7, %rd94, %rd84;
	shl.b64 	%rd95, %rd68, 13;
	add.s64 	%rd96, %rd81, %rd95;
	add.s64 	%rd8, %rd96, %rd84;
	shl.b64 	%rd97, %rd69, 13;
	add.s64 	%rd98, %rd81, %rd97;
	add.s64 	%rd9, %rd98, %rd84;
	shl.b64 	%rd99, %rd70, 13;
	add.s64 	%rd100, %rd81, %rd99;
	add.s64 	%rd10, %rd100, %rd84;
	shl.b64 	%rd101, %rd71, 13;
	add.s64 	%rd102, %rd81, %rd101;
	add.s64 	%rd11, %rd102, %rd84;
	shl.b64 	%rd103, %rd72, 13;
	add.s64 	%rd104, %rd81, %rd103;
	add.s64 	%rd12, %rd104, %rd84;
	shl.b64 	%rd105, %rd73, 13;
	add.s64 	%rd106, %rd81, %rd105;
	add.s64 	%rd13, %rd106, %rd84;
	shl.b64 	%rd107, %rd74, 13;
	add.s64 	%rd108, %rd81, %rd107;
	add.s64 	%rd14, %rd108, %rd84;
	shl.b64 	%rd109, %rd75, 13;
	add.s64 	%rd110, %rd81, %rd109;
	add.s64 	%rd15, %rd110, %rd84;
	shl.b64 	%rd111, %rd76, 13;
	add.s64 	%rd112, %rd81, %rd111;
	add.s64 	%rd16, %rd112, %rd84;
	shl.b64 	%rd113, %rd77, 13;
	add.s64 	%rd114, %rd81, %rd113;
	add.s64 	%rd17, %rd114, %rd84;
	setp.lt.s64 	%p53, %rd62, %rd43;
	setp.lt.s64 	%p54, %rd63, %rd43;
	setp.lt.s64 	%p55, %rd64, %rd43;
	setp.lt.s64 	%p56, %rd65, %rd43;
	setp.lt.s64 	%p57, %rd66, %rd43;
	setp.lt.s64 	%p58, %rd67, %rd43;
	setp.lt.s64 	%p59, %rd68, %rd43;
	setp.lt.s64 	%p60, %rd69, %rd43;
	setp.lt.s64 	%p61, %rd70, %rd43;
	setp.lt.s64 	%p62, %rd71, %rd43;
	setp.lt.s64 	%p63, %rd72, %rd43;
	setp.lt.s64 	%p64, %rd73, %rd43;
	setp.lt.s64 	%p65, %rd74, %rd43;
	setp.lt.s64 	%p66, %rd75, %rd43;
	setp.lt.s64 	%p67, %rd76, %rd43;
	setp.lt.s64 	%p68, %rd77, %rd43;
	and.pred 	%p2, %p51, %p53;
	and.pred 	%p3, %p51, %p54;
	and.pred 	%p4, %p51, %p55;
	and.pred 	%p5, %p51, %p56;
	and.pred 	%p6, %p51, %p57;
	and.pred 	%p7, %p51, %p58;
	and.pred 	%p8, %p51, %p59;
	and.pred 	%p9, %p51, %p60;
	and.pred 	%p10, %p51, %p61;
	and.pred 	%p11, %p51, %p62;
	and.pred 	%p12, %p51, %p63;
	and.pred 	%p13, %p51, %p64;
	and.pred 	%p14, %p51, %p65;
	and.pred 	%p15, %p51, %p66;
	and.pred 	%p16, %p51, %p67;
	and.pred 	%p17, %p51, %p68;
	// begin inline asm
	mov.u32 %r1, 0x0;
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	@%p2 ld.global.v4.b32 { %r1, %r2, %r3, %r4 }, [ %rd2 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	@%p3 ld.global.v4.b32 { %r5, %r6, %r7, %r8 }, [ %rd3 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r9, 0x0;
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	@%p4 ld.global.v4.b32 { %r9, %r10, %r11, %r12 }, [ %rd4 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	@%p5 ld.global.v4.b32 { %r13, %r14, %r15, %r16 }, [ %rd5 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r17, 0x0;
	mov.u32 %r18, 0x0;
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	@%p6 ld.global.v4.b32 { %r17, %r18, %r19, %r20 }, [ %rd6 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p7 ld.global.v4.b32 { %r21, %r22, %r23, %r24 }, [ %rd7 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r25, 0x0;
	mov.u32 %r26, 0x0;
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	@%p8 ld.global.v4.b32 { %r25, %r26, %r27, %r28 }, [ %rd8 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r29, 0x0;
	mov.u32 %r30, 0x0;
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	@%p9 ld.global.v4.b32 { %r29, %r30, %r31, %r32 }, [ %rd9 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r33, 0x0;
	mov.u32 %r34, 0x0;
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	@%p10 ld.global.v4.b32 { %r33, %r34, %r35, %r36 }, [ %rd10 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r37, 0x0;
	mov.u32 %r38, 0x0;
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	@%p11 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd11 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r41, 0x0;
	mov.u32 %r42, 0x0;
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	@%p12 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd12 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r45, 0x0;
	mov.u32 %r46, 0x0;
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	@%p13 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd13 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r49, 0x0;
	mov.u32 %r50, 0x0;
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	@%p14 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd14 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r53, 0x0;
	mov.u32 %r54, 0x0;
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	@%p15 ld.global.v4.b32 { %r53, %r54, %r55, %r56 }, [ %rd15 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r57, 0x0;
	mov.u32 %r58, 0x0;
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	@%p16 ld.global.v4.b32 { %r57, %r58, %r59, %r60 }, [ %rd16 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r61, 0x0;
	mov.u32 %r62, 0x0;
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p17 ld.global.v4.b32 { %r61, %r62, %r63, %r64 }, [ %rd17 + 0 ];
	// end inline asm
	shr.u32 	%r2160, %r2089, 1;
	shr.u32 	%r2161, %r2088, 1;
	and.b32 	%r2162, %r2161, 24;
	xor.b32 	%r2163, %r2162, %r2159;
	shl.b32 	%r2164, %r2163, 1;
	mov.b32 	%r2165, global_smem;
	add.s32 	%r2166, %r2165, %r2164;
	shl.b32 	%r2167, %r2091, 8;
	add.s32 	%r2168, %r2166, %r2167;
	st.shared.v4.b32 	[%r2168], {%r1, %r2, %r3, %r4};
	or.b32 	%r2169, %r2155, 32;
	xor.b32 	%r2170, %r2169, %r2156;
	or.b32 	%r2171, %r2170, %r2158;
	xor.b32 	%r2172, %r2162, %r2171;
	shl.b32 	%r2173, %r2172, 1;
	add.s32 	%r2174, %r2165, %r2173;
	add.s32 	%r2175, %r2174, %r2167;
	st.shared.v4.b32 	[%r2175+1024], {%r5, %r6, %r7, %r8};
	st.shared.v4.b32 	[%r2168+2048], {%r9, %r10, %r11, %r12};
	st.shared.v4.b32 	[%r2175+3072], {%r13, %r14, %r15, %r16};
	st.shared.v4.b32 	[%r2168+4096], {%r17, %r18, %r19, %r20};
	st.shared.v4.b32 	[%r2175+5120], {%r21, %r22, %r23, %r24};
	st.shared.v4.b32 	[%r2168+6144], {%r25, %r26, %r27, %r28};
	st.shared.v4.b32 	[%r2175+7168], {%r29, %r30, %r31, %r32};
	st.shared.v4.b32 	[%r2168+8192], {%r33, %r34, %r35, %r36};
	st.shared.v4.b32 	[%r2175+9216], {%r37, %r38, %r39, %r40};
	st.shared.v4.b32 	[%r2168+10240], {%r41, %r42, %r43, %r44};
	st.shared.v4.b32 	[%r2175+11264], {%r45, %r46, %r47, %r48};
	st.shared.v4.b32 	[%r2168+12288], {%r49, %r50, %r51, %r52};
	st.shared.v4.b32 	[%r2175+13312], {%r53, %r54, %r55, %r56};
	st.shared.v4.b32 	[%r2168+14336], {%r57, %r58, %r59, %r60};
	st.shared.v4.b32 	[%r2175+15360], {%r61, %r62, %r63, %r64};
	.loc	1 61 36                         // chunk_scaled_dot_kkt.py:61:36
	and.b32 	%r2176, %r2154, 384;
	or.b32 	%r2177, %r2159, %r2176;
	shl.b32 	%r2178, %r2088, 5;
	and.b32 	%r2179, %r2178, 1920;
	shr.u32 	%r2180, %r2177, 3;
	and.b32 	%r2181, %r2180, 48;
	add.s32 	%r2182, %r2165, 16384;
	add.s32 	%r2183, %r2182, %r2181;
	shl.b32 	%r2184, %r2177, 1;
	add.s32 	%r2185, %r2183, %r2184;
	st.shared.v4.b32 	[%r2185], {%r1, %r2, %r3, %r4};
	or.b32 	%r2186, %r2177, 512;
	shr.u32 	%r2187, %r2186, 3;
	and.b32 	%r2188, %r2187, 268435440;
	add.s32 	%r2189, %r2182, %r2188;
	add.s32 	%r2190, %r2189, %r2184;
	st.shared.v4.b32 	[%r2190+1024], {%r5, %r6, %r7, %r8};
	or.b32 	%r2191, %r2177, 1024;
	shr.u32 	%r2192, %r2191, 3;
	and.b32 	%r2193, %r2192, 268435440;
	add.s32 	%r2194, %r2182, %r2193;
	add.s32 	%r2195, %r2194, %r2184;
	st.shared.v4.b32 	[%r2195+2048], {%r9, %r10, %r11, %r12};
	or.b32 	%r2196, %r2177, 1536;
	shr.u32 	%r2197, %r2196, 3;
	and.b32 	%r2198, %r2197, 268435440;
	add.s32 	%r2199, %r2182, %r2198;
	add.s32 	%r2200, %r2199, %r2184;
	st.shared.v4.b32 	[%r2200+3072], {%r13, %r14, %r15, %r16};
	bar.sync 	0;
	shr.u32 	%r2201, %r2179, 3;
	add.s32 	%r2202, %r2182, %r2201;
	shl.b32 	%r2203, %r2179, 1;
	add.s32 	%r2204, %r2202, %r2203;
	shl.b32 	%r2205, %r2114, 1;
	add.s32 	%r2206, %r2204, %r2205;
	ld.shared.b32 	%r293, [%r2206];
	ld.shared.b32 	%r294, [%r2206+16];
	ld.shared.b32 	%r517, [%r2206+32];
	ld.shared.b32 	%r518, [%r2206+48];
	ld.shared.b32 	%r741, [%r2206+64];
	ld.shared.b32 	%r742, [%r2206+80];
	ld.shared.b32 	%r965, [%r2206+96];
	ld.shared.b32 	%r966, [%r2206+112];
	ld.shared.b32 	%r1189, [%r2206+128];
	ld.shared.b32 	%r1190, [%r2206+144];
	ld.shared.b32 	%r1413, [%r2206+160];
	ld.shared.b32 	%r1414, [%r2206+176];
	ld.shared.b32 	%r1637, [%r2206+192];
	ld.shared.b32 	%r1638, [%r2206+208];
	ld.shared.b32 	%r1861, [%r2206+224];
	ld.shared.b32 	%r1862, [%r2206+240];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2185], {%r17, %r18, %r19, %r20};
	st.shared.v4.b32 	[%r2190+1024], {%r21, %r22, %r23, %r24};
	st.shared.v4.b32 	[%r2195+2048], {%r25, %r26, %r27, %r28};
	st.shared.v4.b32 	[%r2200+3072], {%r29, %r30, %r31, %r32};
	bar.sync 	0;
	ld.shared.b32 	%r307, [%r2206];
	ld.shared.b32 	%r308, [%r2206+16];
	ld.shared.b32 	%r531, [%r2206+32];
	ld.shared.b32 	%r532, [%r2206+48];
	ld.shared.b32 	%r755, [%r2206+64];
	ld.shared.b32 	%r756, [%r2206+80];
	ld.shared.b32 	%r979, [%r2206+96];
	ld.shared.b32 	%r980, [%r2206+112];
	ld.shared.b32 	%r1203, [%r2206+128];
	ld.shared.b32 	%r1204, [%r2206+144];
	ld.shared.b32 	%r1427, [%r2206+160];
	ld.shared.b32 	%r1428, [%r2206+176];
	ld.shared.b32 	%r1651, [%r2206+192];
	ld.shared.b32 	%r1652, [%r2206+208];
	ld.shared.b32 	%r1875, [%r2206+224];
	ld.shared.b32 	%r1876, [%r2206+240];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2185], {%r33, %r34, %r35, %r36};
	st.shared.v4.b32 	[%r2190+1024], {%r37, %r38, %r39, %r40};
	st.shared.v4.b32 	[%r2195+2048], {%r41, %r42, %r43, %r44};
	st.shared.v4.b32 	[%r2200+3072], {%r45, %r46, %r47, %r48};
	bar.sync 	0;
	ld.shared.b32 	%r321, [%r2206];
	ld.shared.b32 	%r322, [%r2206+16];
	ld.shared.b32 	%r545, [%r2206+32];
	ld.shared.b32 	%r546, [%r2206+48];
	ld.shared.b32 	%r769, [%r2206+64];
	ld.shared.b32 	%r770, [%r2206+80];
	ld.shared.b32 	%r993, [%r2206+96];
	ld.shared.b32 	%r994, [%r2206+112];
	ld.shared.b32 	%r1217, [%r2206+128];
	ld.shared.b32 	%r1218, [%r2206+144];
	ld.shared.b32 	%r1441, [%r2206+160];
	ld.shared.b32 	%r1442, [%r2206+176];
	ld.shared.b32 	%r1665, [%r2206+192];
	ld.shared.b32 	%r1666, [%r2206+208];
	ld.shared.b32 	%r1889, [%r2206+224];
	ld.shared.b32 	%r1890, [%r2206+240];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2185], {%r49, %r50, %r51, %r52};
	st.shared.v4.b32 	[%r2190+1024], {%r53, %r54, %r55, %r56};
	st.shared.v4.b32 	[%r2195+2048], {%r57, %r58, %r59, %r60};
	st.shared.v4.b32 	[%r2200+3072], {%r61, %r62, %r63, %r64};
	bar.sync 	0;
	ld.shared.b32 	%r335, [%r2206];
	ld.shared.b32 	%r336, [%r2206+16];
	ld.shared.b32 	%r559, [%r2206+32];
	ld.shared.b32 	%r560, [%r2206+48];
	ld.shared.b32 	%r783, [%r2206+64];
	ld.shared.b32 	%r784, [%r2206+80];
	ld.shared.b32 	%r1007, [%r2206+96];
	ld.shared.b32 	%r1008, [%r2206+112];
	ld.shared.b32 	%r1231, [%r2206+128];
	ld.shared.b32 	%r1232, [%r2206+144];
	ld.shared.b32 	%r1455, [%r2206+160];
	ld.shared.b32 	%r1456, [%r2206+176];
	ld.shared.b32 	%r1679, [%r2206+192];
	ld.shared.b32 	%r1680, [%r2206+208];
	ld.shared.b32 	%r1903, [%r2206+224];
	ld.shared.b32 	%r1904, [%r2206+240];
	.loc	1 60 22                         // chunk_scaled_dot_kkt.py:60:22
	and.b32 	%r2207, %r2088, 3;
	mul.lo.s32 	%r2208, %r2207, 136;
	and.b32 	%r2209, %r2107, 544;
	xor.b32 	%r2210, %r2209, %r2208;
	shl.b32 	%r2211, %r2109, 7;
	or.b32 	%r2212, %r2210, %r2211;
	xor.b32 	%r2213, %r2212, %r2160;
	shl.b32 	%r2214, %r2213, 1;
	add.s32 	%r69, %r2165, %r2214;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r233, %r234, %r235, %r236}, [%r69];
	// end inline asm
	xor.b32 	%r2215, %r2213, 16;
	shl.b32 	%r2216, %r2215, 1;
	add.s32 	%r74, %r2165, %r2216;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r457, %r458, %r459, %r460}, [%r74];
	// end inline asm
	xor.b32 	%r2217, %r2213, 32;
	shl.b32 	%r2218, %r2217, 1;
	add.s32 	%r79, %r2165, %r2218;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r681, %r682, %r683, %r684}, [%r79];
	// end inline asm
	xor.b32 	%r2219, %r2213, 48;
	shl.b32 	%r2220, %r2219, 1;
	add.s32 	%r84, %r2165, %r2220;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r905, %r906, %r907, %r908}, [%r84];
	// end inline asm
	xor.b32 	%r2221, %r2213, 64;
	shl.b32 	%r2222, %r2221, 1;
	add.s32 	%r89, %r2165, %r2222;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1129, %r1130, %r1131, %r1132}, [%r89];
	// end inline asm
	xor.b32 	%r2223, %r2213, 80;
	shl.b32 	%r2224, %r2223, 1;
	add.s32 	%r94, %r2165, %r2224;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1353, %r1354, %r1355, %r1356}, [%r94];
	// end inline asm
	xor.b32 	%r2225, %r2213, 96;
	shl.b32 	%r2226, %r2225, 1;
	add.s32 	%r99, %r2165, %r2226;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1577, %r1578, %r1579, %r1580}, [%r99];
	// end inline asm
	xor.b32 	%r2227, %r2213, 112;
	shl.b32 	%r2228, %r2227, 1;
	add.s32 	%r104, %r2165, %r2228;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1801, %r1802, %r1803, %r1804}, [%r104];
	// end inline asm
	add.s32 	%r109, %r69, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r289, %r290, %r291, %r292}, [%r109];
	// end inline asm
	xor.b32 	%r2229, %r2213, 2064;
	shl.b32 	%r2230, %r2229, 1;
	add.s32 	%r114, %r2165, %r2230;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r513, %r514, %r515, %r516}, [%r114];
	// end inline asm
	xor.b32 	%r2231, %r2213, 2080;
	shl.b32 	%r2232, %r2231, 1;
	add.s32 	%r119, %r2165, %r2232;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r737, %r738, %r739, %r740}, [%r119];
	// end inline asm
	xor.b32 	%r2233, %r2213, 2096;
	shl.b32 	%r2234, %r2233, 1;
	add.s32 	%r124, %r2165, %r2234;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r961, %r962, %r963, %r964}, [%r124];
	// end inline asm
	xor.b32 	%r2235, %r2213, 2112;
	shl.b32 	%r2236, %r2235, 1;
	add.s32 	%r129, %r2165, %r2236;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1185, %r1186, %r1187, %r1188}, [%r129];
	// end inline asm
	xor.b32 	%r2237, %r2213, 2128;
	shl.b32 	%r2238, %r2237, 1;
	add.s32 	%r134, %r2165, %r2238;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1409, %r1410, %r1411, %r1412}, [%r134];
	// end inline asm
	xor.b32 	%r2239, %r2213, 2144;
	shl.b32 	%r2240, %r2239, 1;
	add.s32 	%r139, %r2165, %r2240;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1633, %r1634, %r1635, %r1636}, [%r139];
	// end inline asm
	xor.b32 	%r2241, %r2213, 2160;
	shl.b32 	%r2242, %r2241, 1;
	add.s32 	%r144, %r2165, %r2242;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1857, %r1858, %r1859, %r1860}, [%r144];
	// end inline asm
	add.s32 	%r149, %r69, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r345, %r346, %r347, %r348}, [%r149];
	// end inline asm
	xor.b32 	%r2243, %r2213, 4112;
	shl.b32 	%r2244, %r2243, 1;
	add.s32 	%r154, %r2165, %r2244;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r569, %r570, %r571, %r572}, [%r154];
	// end inline asm
	xor.b32 	%r2245, %r2213, 4128;
	shl.b32 	%r2246, %r2245, 1;
	add.s32 	%r159, %r2165, %r2246;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r793, %r794, %r795, %r796}, [%r159];
	// end inline asm
	xor.b32 	%r2247, %r2213, 4144;
	shl.b32 	%r2248, %r2247, 1;
	add.s32 	%r164, %r2165, %r2248;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1017, %r1018, %r1019, %r1020}, [%r164];
	// end inline asm
	xor.b32 	%r2249, %r2213, 4160;
	shl.b32 	%r2250, %r2249, 1;
	add.s32 	%r169, %r2165, %r2250;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1241, %r1242, %r1243, %r1244}, [%r169];
	// end inline asm
	xor.b32 	%r2251, %r2213, 4176;
	shl.b32 	%r2252, %r2251, 1;
	add.s32 	%r174, %r2165, %r2252;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1465, %r1466, %r1467, %r1468}, [%r174];
	// end inline asm
	xor.b32 	%r2253, %r2213, 4192;
	shl.b32 	%r2254, %r2253, 1;
	add.s32 	%r179, %r2165, %r2254;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1689, %r1690, %r1691, %r1692}, [%r179];
	// end inline asm
	xor.b32 	%r2255, %r2213, 4208;
	shl.b32 	%r2256, %r2255, 1;
	add.s32 	%r184, %r2165, %r2256;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1913, %r1914, %r1915, %r1916}, [%r184];
	// end inline asm
	add.s32 	%r189, %r69, 12288;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r401, %r402, %r403, %r404}, [%r189];
	// end inline asm
	xor.b32 	%r2257, %r2213, 6160;
	shl.b32 	%r2258, %r2257, 1;
	add.s32 	%r194, %r2165, %r2258;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r625, %r626, %r627, %r628}, [%r194];
	// end inline asm
	xor.b32 	%r2259, %r2213, 6176;
	shl.b32 	%r2260, %r2259, 1;
	add.s32 	%r199, %r2165, %r2260;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r849, %r850, %r851, %r852}, [%r199];
	// end inline asm
	xor.b32 	%r2261, %r2213, 6192;
	shl.b32 	%r2262, %r2261, 1;
	add.s32 	%r204, %r2165, %r2262;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1073, %r1074, %r1075, %r1076}, [%r204];
	// end inline asm
	xor.b32 	%r2263, %r2213, 6208;
	shl.b32 	%r2264, %r2263, 1;
	add.s32 	%r209, %r2165, %r2264;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1297, %r1298, %r1299, %r1300}, [%r209];
	// end inline asm
	xor.b32 	%r2265, %r2213, 6224;
	shl.b32 	%r2266, %r2265, 1;
	add.s32 	%r214, %r2165, %r2266;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1521, %r1522, %r1523, %r1524}, [%r214];
	// end inline asm
	xor.b32 	%r2267, %r2213, 6240;
	shl.b32 	%r2268, %r2267, 1;
	add.s32 	%r219, %r2165, %r2268;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1745, %r1746, %r1747, %r1748}, [%r219];
	// end inline asm
	xor.b32 	%r2269, %r2213, 6256;
	shl.b32 	%r2270, %r2269, 1;
	add.s32 	%r224, %r2165, %r2270;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1969, %r1970, %r1971, %r1972}, [%r224];
	// end inline asm
	mov.b32 	%r229, 0;
	.loc	1 61 27                         // chunk_scaled_dot_kkt.py:61:27
	mov.b32 	%r449, %r229;
	mov.b32 	%r450, %r229;
	mov.b32 	%r451, %r229;
	mov.b32 	%r452, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r233, %r234, %r235, %r236 }, { %r293, %r294 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	mov.b32 	%r463, %r229;
	mov.b32 	%r464, %r229;
	mov.b32 	%r465, %r229;
	mov.b32 	%r466, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r233, %r234, %r235, %r236 }, { %r307, %r308 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	mov.b32 	%r477, %r229;
	mov.b32 	%r478, %r229;
	mov.b32 	%r479, %r229;
	mov.b32 	%r480, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r233, %r234, %r235, %r236 }, { %r321, %r322 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	mov.b32 	%r491, %r229;
	mov.b32 	%r492, %r229;
	mov.b32 	%r493, %r229;
	mov.b32 	%r494, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r233, %r234, %r235, %r236 }, { %r335, %r336 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	mov.b32 	%r505, %r229;
	mov.b32 	%r506, %r229;
	mov.b32 	%r507, %r229;
	mov.b32 	%r508, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r289, %r290, %r291, %r292 }, { %r293, %r294 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	mov.b32 	%r519, %r229;
	mov.b32 	%r520, %r229;
	mov.b32 	%r521, %r229;
	mov.b32 	%r522, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r289, %r290, %r291, %r292 }, { %r307, %r308 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	mov.b32 	%r533, %r229;
	mov.b32 	%r534, %r229;
	mov.b32 	%r535, %r229;
	mov.b32 	%r536, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r289, %r290, %r291, %r292 }, { %r321, %r322 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	mov.b32 	%r547, %r229;
	mov.b32 	%r548, %r229;
	mov.b32 	%r549, %r229;
	mov.b32 	%r550, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r289, %r290, %r291, %r292 }, { %r335, %r336 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	mov.b32 	%r561, %r229;
	mov.b32 	%r562, %r229;
	mov.b32 	%r563, %r229;
	mov.b32 	%r564, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r345, %r346, %r347, %r348 }, { %r293, %r294 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	mov.b32 	%r575, %r229;
	mov.b32 	%r576, %r229;
	mov.b32 	%r577, %r229;
	mov.b32 	%r578, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r345, %r346, %r347, %r348 }, { %r307, %r308 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	mov.b32 	%r589, %r229;
	mov.b32 	%r590, %r229;
	mov.b32 	%r591, %r229;
	mov.b32 	%r592, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r345, %r346, %r347, %r348 }, { %r321, %r322 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	mov.b32 	%r603, %r229;
	mov.b32 	%r604, %r229;
	mov.b32 	%r605, %r229;
	mov.b32 	%r606, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r345, %r346, %r347, %r348 }, { %r335, %r336 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	mov.b32 	%r617, %r229;
	mov.b32 	%r618, %r229;
	mov.b32 	%r619, %r229;
	mov.b32 	%r620, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r401, %r402, %r403, %r404 }, { %r293, %r294 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	mov.b32 	%r631, %r229;
	mov.b32 	%r632, %r229;
	mov.b32 	%r633, %r229;
	mov.b32 	%r634, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r401, %r402, %r403, %r404 }, { %r307, %r308 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	mov.b32 	%r645, %r229;
	mov.b32 	%r646, %r229;
	mov.b32 	%r647, %r229;
	mov.b32 	%r648, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r401, %r402, %r403, %r404 }, { %r321, %r322 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	mov.b32 	%r662, %r229;
	mov.b32 	%r659, %r229;
	mov.b32 	%r660, %r229;
	mov.b32 	%r661, %r229;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r401, %r402, %r403, %r404 }, { %r335, %r336 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r457, %r458, %r459, %r460 }, { %r517, %r518 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r457, %r458, %r459, %r460 }, { %r531, %r532 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r457, %r458, %r459, %r460 }, { %r545, %r546 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r457, %r458, %r459, %r460 }, { %r559, %r560 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r513, %r514, %r515, %r516 }, { %r517, %r518 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r513, %r514, %r515, %r516 }, { %r531, %r532 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r513, %r514, %r515, %r516 }, { %r545, %r546 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r513, %r514, %r515, %r516 }, { %r559, %r560 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r569, %r570, %r571, %r572 }, { %r517, %r518 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r569, %r570, %r571, %r572 }, { %r531, %r532 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r569, %r570, %r571, %r572 }, { %r545, %r546 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r569, %r570, %r571, %r572 }, { %r559, %r560 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r625, %r626, %r627, %r628 }, { %r517, %r518 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r625, %r626, %r627, %r628 }, { %r531, %r532 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r625, %r626, %r627, %r628 }, { %r545, %r546 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r625, %r626, %r627, %r628 }, { %r559, %r560 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r681, %r682, %r683, %r684 }, { %r741, %r742 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r681, %r682, %r683, %r684 }, { %r755, %r756 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r681, %r682, %r683, %r684 }, { %r769, %r770 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r681, %r682, %r683, %r684 }, { %r783, %r784 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r737, %r738, %r739, %r740 }, { %r741, %r742 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r737, %r738, %r739, %r740 }, { %r755, %r756 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r737, %r738, %r739, %r740 }, { %r769, %r770 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r737, %r738, %r739, %r740 }, { %r783, %r784 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r793, %r794, %r795, %r796 }, { %r741, %r742 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r793, %r794, %r795, %r796 }, { %r755, %r756 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r793, %r794, %r795, %r796 }, { %r769, %r770 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r793, %r794, %r795, %r796 }, { %r783, %r784 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r849, %r850, %r851, %r852 }, { %r741, %r742 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r849, %r850, %r851, %r852 }, { %r755, %r756 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r849, %r850, %r851, %r852 }, { %r769, %r770 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r849, %r850, %r851, %r852 }, { %r783, %r784 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r905, %r906, %r907, %r908 }, { %r965, %r966 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r905, %r906, %r907, %r908 }, { %r979, %r980 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r905, %r906, %r907, %r908 }, { %r993, %r994 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r905, %r906, %r907, %r908 }, { %r1007, %r1008 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r961, %r962, %r963, %r964 }, { %r965, %r966 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r961, %r962, %r963, %r964 }, { %r979, %r980 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r961, %r962, %r963, %r964 }, { %r993, %r994 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r961, %r962, %r963, %r964 }, { %r1007, %r1008 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r1017, %r1018, %r1019, %r1020 }, { %r965, %r966 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r1017, %r1018, %r1019, %r1020 }, { %r979, %r980 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r1017, %r1018, %r1019, %r1020 }, { %r993, %r994 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r1017, %r1018, %r1019, %r1020 }, { %r1007, %r1008 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r1073, %r1074, %r1075, %r1076 }, { %r965, %r966 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r1073, %r1074, %r1075, %r1076 }, { %r979, %r980 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r1073, %r1074, %r1075, %r1076 }, { %r993, %r994 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r1073, %r1074, %r1075, %r1076 }, { %r1007, %r1008 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r1129, %r1130, %r1131, %r1132 }, { %r1189, %r1190 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r1129, %r1130, %r1131, %r1132 }, { %r1203, %r1204 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r1129, %r1130, %r1131, %r1132 }, { %r1217, %r1218 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r1129, %r1130, %r1131, %r1132 }, { %r1231, %r1232 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r1185, %r1186, %r1187, %r1188 }, { %r1189, %r1190 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r1185, %r1186, %r1187, %r1188 }, { %r1203, %r1204 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r1185, %r1186, %r1187, %r1188 }, { %r1217, %r1218 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r1185, %r1186, %r1187, %r1188 }, { %r1231, %r1232 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r1241, %r1242, %r1243, %r1244 }, { %r1189, %r1190 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r1241, %r1242, %r1243, %r1244 }, { %r1203, %r1204 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r1241, %r1242, %r1243, %r1244 }, { %r1217, %r1218 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r1241, %r1242, %r1243, %r1244 }, { %r1231, %r1232 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r1297, %r1298, %r1299, %r1300 }, { %r1189, %r1190 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r1297, %r1298, %r1299, %r1300 }, { %r1203, %r1204 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r1297, %r1298, %r1299, %r1300 }, { %r1217, %r1218 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r1297, %r1298, %r1299, %r1300 }, { %r1231, %r1232 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r1353, %r1354, %r1355, %r1356 }, { %r1413, %r1414 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r1353, %r1354, %r1355, %r1356 }, { %r1427, %r1428 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r1353, %r1354, %r1355, %r1356 }, { %r1441, %r1442 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r1353, %r1354, %r1355, %r1356 }, { %r1455, %r1456 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r1409, %r1410, %r1411, %r1412 }, { %r1413, %r1414 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r1409, %r1410, %r1411, %r1412 }, { %r1427, %r1428 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r1409, %r1410, %r1411, %r1412 }, { %r1441, %r1442 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r1409, %r1410, %r1411, %r1412 }, { %r1455, %r1456 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r1465, %r1466, %r1467, %r1468 }, { %r1413, %r1414 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r1465, %r1466, %r1467, %r1468 }, { %r1427, %r1428 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r1465, %r1466, %r1467, %r1468 }, { %r1441, %r1442 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r1465, %r1466, %r1467, %r1468 }, { %r1455, %r1456 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r1521, %r1522, %r1523, %r1524 }, { %r1413, %r1414 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r1521, %r1522, %r1523, %r1524 }, { %r1427, %r1428 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r1521, %r1522, %r1523, %r1524 }, { %r1441, %r1442 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r1521, %r1522, %r1523, %r1524 }, { %r1455, %r1456 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r1577, %r1578, %r1579, %r1580 }, { %r1637, %r1638 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r1577, %r1578, %r1579, %r1580 }, { %r1651, %r1652 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r1577, %r1578, %r1579, %r1580 }, { %r1665, %r1666 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r1577, %r1578, %r1579, %r1580 }, { %r1679, %r1680 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r1633, %r1634, %r1635, %r1636 }, { %r1637, %r1638 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r1633, %r1634, %r1635, %r1636 }, { %r1651, %r1652 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r1633, %r1634, %r1635, %r1636 }, { %r1665, %r1666 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r1633, %r1634, %r1635, %r1636 }, { %r1679, %r1680 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r1689, %r1690, %r1691, %r1692 }, { %r1637, %r1638 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r1689, %r1690, %r1691, %r1692 }, { %r1651, %r1652 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r1689, %r1690, %r1691, %r1692 }, { %r1665, %r1666 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r1689, %r1690, %r1691, %r1692 }, { %r1679, %r1680 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r1745, %r1746, %r1747, %r1748 }, { %r1637, %r1638 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r1745, %r1746, %r1747, %r1748 }, { %r1651, %r1652 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r1745, %r1746, %r1747, %r1748 }, { %r1665, %r1666 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r1745, %r1746, %r1747, %r1748 }, { %r1679, %r1680 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r449, %r450, %r451, %r452 }, { %r1801, %r1802, %r1803, %r1804 }, { %r1861, %r1862 }, { %r449, %r450, %r451, %r452 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r463, %r464, %r465, %r466 }, { %r1801, %r1802, %r1803, %r1804 }, { %r1875, %r1876 }, { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r477, %r478, %r479, %r480 }, { %r1801, %r1802, %r1803, %r1804 }, { %r1889, %r1890 }, { %r477, %r478, %r479, %r480 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r491, %r492, %r493, %r494 }, { %r1801, %r1802, %r1803, %r1804 }, { %r1903, %r1904 }, { %r491, %r492, %r493, %r494 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r505, %r506, %r507, %r508 }, { %r1857, %r1858, %r1859, %r1860 }, { %r1861, %r1862 }, { %r505, %r506, %r507, %r508 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r519, %r520, %r521, %r522 }, { %r1857, %r1858, %r1859, %r1860 }, { %r1875, %r1876 }, { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r533, %r534, %r535, %r536 }, { %r1857, %r1858, %r1859, %r1860 }, { %r1889, %r1890 }, { %r533, %r534, %r535, %r536 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r547, %r548, %r549, %r550 }, { %r1857, %r1858, %r1859, %r1860 }, { %r1903, %r1904 }, { %r547, %r548, %r549, %r550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r561, %r562, %r563, %r564 }, { %r1913, %r1914, %r1915, %r1916 }, { %r1861, %r1862 }, { %r561, %r562, %r563, %r564 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r575, %r576, %r577, %r578 }, { %r1913, %r1914, %r1915, %r1916 }, { %r1875, %r1876 }, { %r575, %r576, %r577, %r578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r589, %r590, %r591, %r592 }, { %r1913, %r1914, %r1915, %r1916 }, { %r1889, %r1890 }, { %r589, %r590, %r591, %r592 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r603, %r604, %r605, %r606 }, { %r1913, %r1914, %r1915, %r1916 }, { %r1903, %r1904 }, { %r603, %r604, %r605, %r606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r617, %r618, %r619, %r620 }, { %r1969, %r1970, %r1971, %r1972 }, { %r1861, %r1862 }, { %r617, %r618, %r619, %r620 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r631, %r632, %r633, %r634 }, { %r1969, %r1970, %r1971, %r1972 }, { %r1875, %r1876 }, { %r631, %r632, %r633, %r634 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r645, %r646, %r647, %r648 }, { %r1969, %r1970, %r1971, %r1972 }, { %r1889, %r1890 }, { %r645, %r646, %r647, %r648 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r659, %r660, %r661, %r662 }, { %r1969, %r1970, %r1971, %r1972 }, { %r1903, %r1904 }, { %r659, %r660, %r661, %r662 };
	// end inline asm
	.loc	1 64 36                         // chunk_scaled_dot_kkt.py:64:36
	mul.wide.s32 	%rd115, %r2151, 4;
	add.s64 	%rd116, %rd36, %rd115;
	.loc	1 64 44                         // chunk_scaled_dot_kkt.py:64:44
	mul.wide.u32 	%rd117, %r2085, 4;
	add.s64 	%rd118, %rd116, %rd117;
	.loc	1 65 22                         // chunk_scaled_dot_kkt.py:65:22
	shl.b64 	%rd119, %rd78, 7;
	add.s64 	%rd18, %rd118, %rd119;
	// begin inline asm
	mov.u32 %r2017, 0x0;
	@%p1 ld.global.b32 { %r2017 }, [ %rd18 + 0 ];
	// end inline asm
	.loc	1 66 34                         // chunk_scaled_dot_kkt.py:66:34
	bar.sync 	0;
	shl.b32 	%r2271, %r2118, 2;
	add.s32 	%r2272, %r2165, %r2271;
	st.shared.b32 	[%r2272], %r2017;
	bar.sync 	0;
	shl.b32 	%r2273, %r2119, 2;
	add.s32 	%r2274, %r2165, %r2273;
	ld.shared.b32 	%r2275, [%r2274];
	ld.shared.b32 	%r2276, [%r2274+32];
	ld.shared.b32 	%r2277, [%r2274+64];
	ld.shared.b32 	%r2278, [%r2274+96];
	ld.shared.b32 	%r2279, [%r2274+128];
	ld.shared.b32 	%r2280, [%r2274+160];
	ld.shared.b32 	%r2281, [%r2274+192];
	ld.shared.b32 	%r2282, [%r2274+224];
	.loc	1 67 19                         // chunk_scaled_dot_kkt.py:67:19
	bar.sync 	0;
	st.shared.b32 	[%r2272], %r2017;
	bar.sync 	0;
	shl.b32 	%r2283, %r2127, 2;
	add.s32 	%r2284, %r2165, %r2283;
	ld.shared.v2.b32 	{%r2285, %r2286}, [%r2284];
	ld.shared.v2.b32 	{%r2287, %r2288}, [%r2284+64];
	ld.shared.v2.b32 	{%r2289, %r2290}, [%r2284+128];
	ld.shared.v2.b32 	{%r2291, %r2292}, [%r2284+192];
	.loc	1 66 34                         // chunk_scaled_dot_kkt.py:66:34
	sub.f32 	%r2293, %r2275, %r2285;
	sub.f32 	%r2294, %r2275, %r2286;
	sub.f32 	%r2295, %r2276, %r2285;
	sub.f32 	%r2296, %r2276, %r2286;
	sub.f32 	%r2297, %r2277, %r2285;
	sub.f32 	%r2298, %r2277, %r2286;
	sub.f32 	%r2299, %r2278, %r2285;
	sub.f32 	%r2300, %r2278, %r2286;
	sub.f32 	%r2301, %r2277, %r2287;
	sub.f32 	%r2302, %r2277, %r2288;
	sub.f32 	%r2303, %r2278, %r2287;
	sub.f32 	%r2304, %r2278, %r2288;
	sub.f32 	%r2305, %r2279, %r2285;
	sub.f32 	%r2306, %r2279, %r2286;
	sub.f32 	%r2307, %r2280, %r2285;
	sub.f32 	%r2308, %r2280, %r2286;
	sub.f32 	%r2309, %r2279, %r2287;
	sub.f32 	%r2310, %r2279, %r2288;
	sub.f32 	%r2311, %r2280, %r2287;
	sub.f32 	%r2312, %r2280, %r2288;
	sub.f32 	%r2313, %r2279, %r2289;
	sub.f32 	%r2314, %r2279, %r2290;
	sub.f32 	%r2315, %r2280, %r2289;
	sub.f32 	%r2316, %r2280, %r2290;
	sub.f32 	%r2317, %r2281, %r2285;
	sub.f32 	%r2318, %r2281, %r2286;
	sub.f32 	%r2319, %r2282, %r2285;
	sub.f32 	%r2320, %r2282, %r2286;
	sub.f32 	%r2321, %r2281, %r2287;
	sub.f32 	%r2322, %r2281, %r2288;
	sub.f32 	%r2323, %r2282, %r2287;
	sub.f32 	%r2324, %r2282, %r2288;
	sub.f32 	%r2325, %r2281, %r2289;
	sub.f32 	%r2326, %r2281, %r2290;
	sub.f32 	%r2327, %r2282, %r2289;
	sub.f32 	%r2328, %r2282, %r2290;
	sub.f32 	%r2329, %r2281, %r2291;
	sub.f32 	%r2330, %r2281, %r2292;
	sub.f32 	%r2331, %r2282, %r2291;
	sub.f32 	%r2332, %r2282, %r2292;
	.loc	1 67 19                         // chunk_scaled_dot_kkt.py:67:19
	mul.f32 	%r2333, %r2293, 0f3FB8AA3B;
	ex2.approx.f32 	%r2334, %r2333;
	mul.f32 	%r2335, %r2294, 0f3FB8AA3B;
	ex2.approx.f32 	%r2336, %r2335;
	mul.f32 	%r2337, %r2295, 0f3FB8AA3B;
	ex2.approx.f32 	%r2338, %r2337;
	mul.f32 	%r2339, %r2296, 0f3FB8AA3B;
	ex2.approx.f32 	%r2340, %r2339;
	mul.f32 	%r2341, %r2297, 0f3FB8AA3B;
	ex2.approx.f32 	%r2342, %r2341;
	mul.f32 	%r2343, %r2298, 0f3FB8AA3B;
	ex2.approx.f32 	%r2344, %r2343;
	mul.f32 	%r2345, %r2299, 0f3FB8AA3B;
	ex2.approx.f32 	%r2346, %r2345;
	mul.f32 	%r2347, %r2300, 0f3FB8AA3B;
	ex2.approx.f32 	%r2348, %r2347;
	mul.f32 	%r2349, %r2301, 0f3FB8AA3B;
	ex2.approx.f32 	%r2350, %r2349;
	mul.f32 	%r2351, %r2302, 0f3FB8AA3B;
	ex2.approx.f32 	%r2352, %r2351;
	mul.f32 	%r2353, %r2303, 0f3FB8AA3B;
	ex2.approx.f32 	%r2354, %r2353;
	mul.f32 	%r2355, %r2304, 0f3FB8AA3B;
	ex2.approx.f32 	%r2356, %r2355;
	mul.f32 	%r2357, %r2305, 0f3FB8AA3B;
	ex2.approx.f32 	%r2358, %r2357;
	mul.f32 	%r2359, %r2306, 0f3FB8AA3B;
	ex2.approx.f32 	%r2360, %r2359;
	mul.f32 	%r2361, %r2307, 0f3FB8AA3B;
	ex2.approx.f32 	%r2362, %r2361;
	mul.f32 	%r2363, %r2308, 0f3FB8AA3B;
	ex2.approx.f32 	%r2364, %r2363;
	mul.f32 	%r2365, %r2309, 0f3FB8AA3B;
	ex2.approx.f32 	%r2366, %r2365;
	mul.f32 	%r2367, %r2310, 0f3FB8AA3B;
	ex2.approx.f32 	%r2368, %r2367;
	mul.f32 	%r2369, %r2311, 0f3FB8AA3B;
	ex2.approx.f32 	%r2370, %r2369;
	mul.f32 	%r2371, %r2312, 0f3FB8AA3B;
	ex2.approx.f32 	%r2372, %r2371;
	mul.f32 	%r2373, %r2313, 0f3FB8AA3B;
	ex2.approx.f32 	%r2374, %r2373;
	mul.f32 	%r2375, %r2314, 0f3FB8AA3B;
	ex2.approx.f32 	%r2376, %r2375;
	mul.f32 	%r2377, %r2315, 0f3FB8AA3B;
	ex2.approx.f32 	%r2378, %r2377;
	mul.f32 	%r2379, %r2316, 0f3FB8AA3B;
	ex2.approx.f32 	%r2380, %r2379;
	mul.f32 	%r2381, %r2317, 0f3FB8AA3B;
	ex2.approx.f32 	%r2382, %r2381;
	mul.f32 	%r2383, %r2318, 0f3FB8AA3B;
	ex2.approx.f32 	%r2384, %r2383;
	mul.f32 	%r2385, %r2319, 0f3FB8AA3B;
	ex2.approx.f32 	%r2386, %r2385;
	mul.f32 	%r2387, %r2320, 0f3FB8AA3B;
	ex2.approx.f32 	%r2388, %r2387;
	mul.f32 	%r2389, %r2321, 0f3FB8AA3B;
	ex2.approx.f32 	%r2390, %r2389;
	mul.f32 	%r2391, %r2322, 0f3FB8AA3B;
	ex2.approx.f32 	%r2392, %r2391;
	mul.f32 	%r2393, %r2323, 0f3FB8AA3B;
	ex2.approx.f32 	%r2394, %r2393;
	mul.f32 	%r2395, %r2324, 0f3FB8AA3B;
	ex2.approx.f32 	%r2396, %r2395;
	mul.f32 	%r2397, %r2325, 0f3FB8AA3B;
	ex2.approx.f32 	%r2398, %r2397;
	mul.f32 	%r2399, %r2326, 0f3FB8AA3B;
	ex2.approx.f32 	%r2400, %r2399;
	mul.f32 	%r2401, %r2327, 0f3FB8AA3B;
	ex2.approx.f32 	%r2402, %r2401;
	mul.f32 	%r2403, %r2328, 0f3FB8AA3B;
	ex2.approx.f32 	%r2404, %r2403;
	mul.f32 	%r2405, %r2329, 0f3FB8AA3B;
	ex2.approx.f32 	%r2406, %r2405;
	mul.f32 	%r2407, %r2330, 0f3FB8AA3B;
	ex2.approx.f32 	%r2408, %r2407;
	mul.f32 	%r2409, %r2331, 0f3FB8AA3B;
	ex2.approx.f32 	%r2410, %r2409;
	mul.f32 	%r2411, %r2332, 0f3FB8AA3B;
	ex2.approx.f32 	%r2412, %r2411;
	.loc	1 67 15                         // chunk_scaled_dot_kkt.py:67:15
	mul.f32 	%r2413, %r449, %r2334;
	mul.f32 	%r2414, %r450, %r2336;
	mul.f32 	%r2415, %r451, %r2338;
	mul.f32 	%r2416, %r452, %r2340;
	mul.f32 	%r2417, %r505, %r2342;
	mul.f32 	%r2418, %r506, %r2344;
	mul.f32 	%r2419, %r507, %r2346;
	mul.f32 	%r2420, %r508, %r2348;
	mul.f32 	%r2421, %r519, %r2350;
	mul.f32 	%r2422, %r520, %r2352;
	mul.f32 	%r2423, %r521, %r2354;
	mul.f32 	%r2424, %r522, %r2356;
	mul.f32 	%r2425, %r561, %r2358;
	mul.f32 	%r2426, %r562, %r2360;
	mul.f32 	%r2427, %r563, %r2362;
	mul.f32 	%r2428, %r564, %r2364;
	mul.f32 	%r2429, %r575, %r2366;
	mul.f32 	%r2430, %r576, %r2368;
	mul.f32 	%r2431, %r577, %r2370;
	mul.f32 	%r2432, %r578, %r2372;
	mul.f32 	%r2433, %r589, %r2374;
	mul.f32 	%r2434, %r590, %r2376;
	mul.f32 	%r2435, %r591, %r2378;
	mul.f32 	%r2436, %r592, %r2380;
	mul.f32 	%r2437, %r617, %r2382;
	mul.f32 	%r2438, %r618, %r2384;
	mul.f32 	%r2439, %r619, %r2386;
	mul.f32 	%r2440, %r620, %r2388;
	mul.f32 	%r2441, %r631, %r2390;
	mul.f32 	%r2442, %r632, %r2392;
	mul.f32 	%r2443, %r633, %r2394;
	mul.f32 	%r2444, %r634, %r2396;
	mul.f32 	%r2445, %r645, %r2398;
	mul.f32 	%r2446, %r646, %r2400;
	mul.f32 	%r2447, %r647, %r2402;
	mul.f32 	%r2448, %r648, %r2404;
	mul.f32 	%r2449, %r659, %r2406;
	mul.f32 	%r2450, %r660, %r2408;
	mul.f32 	%r2451, %r661, %r2410;
	mul.f32 	%r2452, %r662, %r2412;
	.loc	1 68 11                         // chunk_scaled_dot_kkt.py:68:11
	bar.sync 	0;
	or.b32 	%r2453, %r2112, %r2115;
	shl.b32 	%r2454, %r2118, 1;
	sub.s32 	%r2455, %r2272, %r2454;
	st.shared.b16 	[%r2455], %rs1;
	bar.sync 	0;
	shl.b32 	%r2456, %r2453, 1;
	add.s32 	%r2457, %r2165, %r2456;
	ld.shared.v4.b16 	{%rs2, %rs3, %rs4, %rs5}, [%r2457];
	ld.shared.v4.b16 	{%rs6, %rs7, %rs8, %rs9}, [%r2457+32];
	ld.shared.v4.b16 	{%rs10, %rs11, %rs12, %rs13}, [%r2457+64];
	ld.shared.v4.b16 	{%rs14, %rs15, %rs16, %rs17}, [%r2457+96];
	cvt.f32.bf16 	%r2458, %rs2;
	cvt.f32.bf16 	%r2459, %rs3;
	cvt.f32.bf16 	%r2460, %rs4;
	cvt.f32.bf16 	%r2461, %rs5;
	cvt.f32.bf16 	%r2462, %rs6;
	cvt.f32.bf16 	%r2463, %rs7;
	cvt.f32.bf16 	%r2464, %rs8;
	cvt.f32.bf16 	%r2465, %rs9;
	cvt.f32.bf16 	%r2466, %rs10;
	cvt.f32.bf16 	%r2467, %rs11;
	cvt.f32.bf16 	%r2468, %rs12;
	cvt.f32.bf16 	%r2469, %rs13;
	cvt.f32.bf16 	%r2470, %rs14;
	cvt.f32.bf16 	%r2471, %rs15;
	cvt.f32.bf16 	%r2472, %rs16;
	cvt.f32.bf16 	%r2473, %rs17;
	bar.sync 	0;
	add.s32 	%r2474, %r2457, %r2456;
	st.shared.v4.b32 	[%r2474], {%r2458, %r2459, %r2460, %r2461};
	bar.sync 	0;
	ld.shared.b32 	%r2475, [%r2274];
	ld.shared.b32 	%r2476, [%r2274+32];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2474], {%r2462, %r2463, %r2464, %r2465};
	bar.sync 	0;
	ld.shared.b32 	%r2477, [%r2274];
	ld.shared.b32 	%r2478, [%r2274+32];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2474], {%r2466, %r2467, %r2468, %r2469};
	bar.sync 	0;
	ld.shared.b32 	%r2479, [%r2274];
	ld.shared.b32 	%r2480, [%r2274+32];
	bar.sync 	0;
	st.shared.v4.b32 	[%r2474], {%r2470, %r2471, %r2472, %r2473};
	bar.sync 	0;
	ld.shared.b32 	%r2481, [%r2274];
	ld.shared.b32 	%r2482, [%r2274+32];
	mul.f32 	%r2483, %r2413, %r2475;
	mul.f32 	%r2484, %r2414, %r2475;
	mul.f32 	%r2485, %r2415, %r2476;
	mul.f32 	%r2486, %r2416, %r2476;
	mul.f32 	%r2487, %r2417, %r2477;
	mul.f32 	%r2488, %r2418, %r2477;
	mul.f32 	%r2489, %r2419, %r2478;
	mul.f32 	%r2490, %r2420, %r2478;
	mul.f32 	%r2491, %r2421, %r2477;
	mul.f32 	%r2492, %r2422, %r2477;
	mul.f32 	%r2493, %r2423, %r2478;
	mul.f32 	%r2494, %r2424, %r2478;
	mul.f32 	%r2495, %r2425, %r2479;
	mul.f32 	%r2496, %r2426, %r2479;
	mul.f32 	%r2497, %r2427, %r2480;
	mul.f32 	%r2498, %r2428, %r2480;
	mul.f32 	%r2499, %r2429, %r2479;
	mul.f32 	%r2500, %r2430, %r2479;
	mul.f32 	%r2501, %r2431, %r2480;
	mul.f32 	%r2502, %r2432, %r2480;
	mul.f32 	%r2503, %r2433, %r2479;
	mul.f32 	%r2504, %r2434, %r2479;
	mul.f32 	%r2505, %r2435, %r2480;
	mul.f32 	%r2506, %r2436, %r2480;
	mul.f32 	%r2507, %r2437, %r2481;
	mul.f32 	%r2508, %r2438, %r2481;
	mul.f32 	%r2509, %r2439, %r2482;
	mul.f32 	%r2510, %r2440, %r2482;
	mul.f32 	%r2511, %r2441, %r2481;
	mul.f32 	%r2512, %r2442, %r2481;
	mul.f32 	%r2513, %r2443, %r2482;
	mul.f32 	%r2514, %r2444, %r2482;
	mul.f32 	%r2515, %r2445, %r2481;
	mul.f32 	%r2516, %r2446, %r2481;
	mul.f32 	%r2517, %r2447, %r2482;
	mul.f32 	%r2518, %r2448, %r2482;
	mul.f32 	%r2519, %r2449, %r2481;
	mul.f32 	%r2520, %r2450, %r2481;
	mul.f32 	%r2521, %r2451, %r2482;
	mul.f32 	%r2522, %r2452, %r2482;
	.loc	1 70 26                         // chunk_scaled_dot_kkt.py:70:26
	setp.gt.u32 	%p69, %r2119, %r2127;
	setp.gt.u32 	%p70, %r2119, %r2128;
	setp.gt.u32 	%p71, %r2120, %r2127;
	setp.gt.u32 	%p72, %r2120, %r2128;
	setp.gt.u32 	%p73, %r2121, %r2130;
	setp.gt.u32 	%p74, %r2122, %r2129;
	setp.gt.u32 	%p75, %r2122, %r2130;
	setp.gt.u32 	%p76, %r2123, %r2132;
	setp.gt.u32 	%p77, %r2124, %r2131;
	setp.gt.u32 	%p78, %r2124, %r2132;
	setp.gt.u32 	%p79, %r2125, %r2134;
	setp.gt.u32 	%p80, %r2126, %r2133;
	setp.gt.u32 	%p81, %r2126, %r2134;
	.loc	1 72 48                         // chunk_scaled_dot_kkt.py:72:48
	shl.b32 	%r2523, %r2152, 6;
	.loc	1 72 32                         // chunk_scaled_dot_kkt.py:72:32
	mul.wide.s32 	%rd120, %r2523, 4;
	add.s64 	%rd121, %rd38, %rd120;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	add.s64 	%rd122, %rd121, %rd82;
	mul.wide.u32 	%rd123, %r2117, 4;
	add.s64 	%rd19, %rd122, %rd123;
	add.s64 	%rd124, %rd121, %rd85;
	add.s64 	%rd20, %rd124, %rd123;
	add.s64 	%rd125, %rd121, %rd87;
	add.s64 	%rd21, %rd125, %rd123;
	add.s64 	%rd126, %rd121, %rd89;
	add.s64 	%rd22, %rd126, %rd123;
	add.s64 	%rd127, %rd121, %rd91;
	add.s64 	%rd23, %rd127, %rd123;
	add.s64 	%rd128, %rd121, %rd93;
	add.s64 	%rd24, %rd128, %rd123;
	add.s64 	%rd129, %rd121, %rd95;
	add.s64 	%rd25, %rd129, %rd123;
	add.s64 	%rd130, %rd121, %rd97;
	add.s64 	%rd26, %rd130, %rd123;
	add.s64 	%rd131, %rd121, %rd99;
	add.s64 	%rd27, %rd131, %rd123;
	add.s64 	%rd132, %rd121, %rd101;
	add.s64 	%rd28, %rd132, %rd123;
	add.s64 	%rd133, %rd121, %rd103;
	add.s64 	%rd29, %rd133, %rd123;
	add.s64 	%rd134, %rd121, %rd105;
	add.s64 	%rd30, %rd134, %rd123;
	add.s64 	%rd135, %rd121, %rd107;
	add.s64 	%rd31, %rd135, %rd123;
	add.s64 	%rd136, %rd121, %rd109;
	add.s64 	%rd32, %rd136, %rd123;
	add.s64 	%rd137, %rd121, %rd111;
	add.s64 	%rd33, %rd137, %rd123;
	add.s64 	%rd138, %rd121, %rd113;
	add.s64 	%rd34, %rd138, %rd123;
	bar.sync 	0;
	shl.b32 	%r2524, %r2088, 4;
	and.b32 	%r2525, %r2524, 448;
	or.b32 	%r2526, %r2127, %r2525;
	and.b32 	%r2527, %r2116, 252;
	shr.u32 	%r2528, %r2525, 2;
	add.s32 	%r2529, %r2165, %r2528;
	shl.b32 	%r2530, %r2526, 2;
	add.s32 	%r2531, %r2529, %r2530;
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2532, %r2483, 0, %p50;
	selp.b32 	%r2533, %r2532, 0, %p69;
	selp.b32 	%r2534, %r2533, 0, %p49;
	selp.b32 	%r2535, %r2484, 0, %p48;
	selp.b32 	%r2536, %r2535, 0, %p70;
	selp.b32 	%r2537, %r2536, 0, %p49;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531], {%r2534, %r2537};
	or.b32 	%r2538, %r2525, 512;
	shr.u32 	%r2539, %r2538, 2;
	add.s32 	%r2540, %r2165, %r2539;
	add.s32 	%r2541, %r2540, %r2530;
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2542, %r2485, 0, %p50;
	selp.b32 	%r2543, %r2542, 0, %p71;
	selp.b32 	%r2544, %r2543, 0, %p47;
	selp.b32 	%r2545, %r2486, 0, %p48;
	selp.b32 	%r2546, %r2545, 0, %p72;
	selp.b32 	%r2547, %r2546, 0, %p47;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2048], {%r2544, %r2547};
	st.shared.v2.b32 	[%r2531+64], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2112], {%r229, %r229};
	st.shared.v2.b32 	[%r2531+128], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2176], {%r229, %r229};
	st.shared.v2.b32 	[%r2531+192], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2240], {%r229, %r229};
	bar.sync 	0;
	and.b32 	%r2548, %r2088, 48;
	add.s32 	%r2549, %r2165, %r2548;
	shl.b32 	%r2550, %r2527, 2;
	add.s32 	%r2551, %r2549, %r2550;
	ld.shared.v4.b32 	{%r2018, %r2019, %r2020, %r2021}, [%r2551];
	or.b32 	%r2552, %r2527, 256;
	shr.u32 	%r2553, %r2552, 2;
	and.b32 	%r2554, %r2553, 112;
	add.s32 	%r2555, %r2165, %r2554;
	add.s32 	%r2556, %r2555, %r2550;
	ld.shared.v4.b32 	{%r2022, %r2023, %r2024, %r2025}, [%r2556+1024];
	or.b32 	%r2557, %r2527, 512;
	shr.u32 	%r2558, %r2557, 2;
	and.b32 	%r2559, %r2558, 176;
	add.s32 	%r2560, %r2165, %r2559;
	add.s32 	%r2561, %r2560, %r2550;
	ld.shared.v4.b32 	{%r2026, %r2027, %r2028, %r2029}, [%r2561+2048];
	or.b32 	%r2562, %r2527, 768;
	shr.u32 	%r2563, %r2562, 2;
	and.b32 	%r2564, %r2563, 240;
	add.s32 	%r2565, %r2165, %r2564;
	add.s32 	%r2566, %r2565, %r2550;
	ld.shared.v4.b32 	{%r2030, %r2031, %r2032, %r2033}, [%r2566+3072];
	bar.sync 	0;
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2567, %r2487, 0, %p50;
	selp.b32 	%r2568, %r2567, 0, %p46;
	selp.b32 	%r2569, %r2488, 0, %p48;
	selp.b32 	%r2570, %r2569, 0, %p46;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531], {%r2568, %r2570};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2571, %r2489, 0, %p50;
	selp.b32 	%r2572, %r2571, 0, %p45;
	selp.b32 	%r2573, %r2490, 0, %p48;
	selp.b32 	%r2574, %r2573, 0, %p45;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2048], {%r2572, %r2574};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2575, %r2491, 0, %p44;
	selp.b32 	%r2576, %r2575, 0, %p69;
	selp.b32 	%r2577, %r2576, 0, %p46;
	selp.b32 	%r2578, %r2492, 0, %p43;
	selp.b32 	%r2579, %r2578, 0, %p73;
	selp.b32 	%r2580, %r2579, 0, %p46;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+64], {%r2577, %r2580};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2581, %r2493, 0, %p44;
	selp.b32 	%r2582, %r2581, 0, %p74;
	selp.b32 	%r2583, %r2582, 0, %p45;
	selp.b32 	%r2584, %r2494, 0, %p43;
	selp.b32 	%r2585, %r2584, 0, %p75;
	selp.b32 	%r2586, %r2585, 0, %p45;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2112], {%r2583, %r2586};
	st.shared.v2.b32 	[%r2531+128], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2176], {%r229, %r229};
	st.shared.v2.b32 	[%r2531+192], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2240], {%r229, %r229};
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2034, %r2035, %r2036, %r2037}, [%r2551];
	ld.shared.v4.b32 	{%r2038, %r2039, %r2040, %r2041}, [%r2556+1024];
	ld.shared.v4.b32 	{%r2042, %r2043, %r2044, %r2045}, [%r2561+2048];
	ld.shared.v4.b32 	{%r2046, %r2047, %r2048, %r2049}, [%r2566+3072];
	bar.sync 	0;
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2587, %r2495, 0, %p50;
	selp.b32 	%r2588, %r2587, 0, %p42;
	selp.b32 	%r2589, %r2496, 0, %p48;
	selp.b32 	%r2590, %r2589, 0, %p42;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531], {%r2588, %r2590};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2591, %r2497, 0, %p50;
	selp.b32 	%r2592, %r2591, 0, %p41;
	selp.b32 	%r2593, %r2498, 0, %p48;
	selp.b32 	%r2594, %r2593, 0, %p41;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2048], {%r2592, %r2594};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2595, %r2499, 0, %p44;
	selp.b32 	%r2596, %r2595, 0, %p42;
	selp.b32 	%r2597, %r2500, 0, %p43;
	selp.b32 	%r2598, %r2597, 0, %p42;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+64], {%r2596, %r2598};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2599, %r2501, 0, %p44;
	selp.b32 	%r2600, %r2599, 0, %p41;
	selp.b32 	%r2601, %r2502, 0, %p43;
	selp.b32 	%r2602, %r2601, 0, %p41;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2112], {%r2600, %r2602};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2603, %r2503, 0, %p40;
	selp.b32 	%r2604, %r2603, 0, %p69;
	selp.b32 	%r2605, %r2604, 0, %p42;
	selp.b32 	%r2606, %r2504, 0, %p39;
	selp.b32 	%r2607, %r2606, 0, %p76;
	selp.b32 	%r2608, %r2607, 0, %p42;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+128], {%r2605, %r2608};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2609, %r2505, 0, %p40;
	selp.b32 	%r2610, %r2609, 0, %p77;
	selp.b32 	%r2611, %r2610, 0, %p41;
	selp.b32 	%r2612, %r2506, 0, %p39;
	selp.b32 	%r2613, %r2612, 0, %p78;
	selp.b32 	%r2614, %r2613, 0, %p41;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2176], {%r2611, %r2614};
	st.shared.v2.b32 	[%r2531+192], {%r229, %r229};
	st.shared.v2.b32 	[%r2541+2240], {%r229, %r229};
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2050, %r2051, %r2052, %r2053}, [%r2551];
	ld.shared.v4.b32 	{%r2054, %r2055, %r2056, %r2057}, [%r2556+1024];
	ld.shared.v4.b32 	{%r2058, %r2059, %r2060, %r2061}, [%r2561+2048];
	ld.shared.v4.b32 	{%r2062, %r2063, %r2064, %r2065}, [%r2566+3072];
	bar.sync 	0;
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2615, %r2507, 0, %p50;
	selp.b32 	%r2616, %r2615, 0, %p38;
	selp.b32 	%r2617, %r2508, 0, %p48;
	selp.b32 	%r2618, %r2617, 0, %p38;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531], {%r2616, %r2618};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2619, %r2509, 0, %p50;
	selp.b32 	%r2620, %r2619, 0, %p37;
	selp.b32 	%r2621, %r2510, 0, %p48;
	selp.b32 	%r2622, %r2621, 0, %p37;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2048], {%r2620, %r2622};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2623, %r2511, 0, %p44;
	selp.b32 	%r2624, %r2623, 0, %p38;
	selp.b32 	%r2625, %r2512, 0, %p43;
	selp.b32 	%r2626, %r2625, 0, %p38;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+64], {%r2624, %r2626};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2627, %r2513, 0, %p44;
	selp.b32 	%r2628, %r2627, 0, %p37;
	selp.b32 	%r2629, %r2514, 0, %p43;
	selp.b32 	%r2630, %r2629, 0, %p37;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2112], {%r2628, %r2630};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2631, %r2515, 0, %p40;
	selp.b32 	%r2632, %r2631, 0, %p38;
	selp.b32 	%r2633, %r2516, 0, %p39;
	selp.b32 	%r2634, %r2633, 0, %p38;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+128], {%r2632, %r2634};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2635, %r2517, 0, %p40;
	selp.b32 	%r2636, %r2635, 0, %p37;
	selp.b32 	%r2637, %r2518, 0, %p39;
	selp.b32 	%r2638, %r2637, 0, %p37;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2176], {%r2636, %r2638};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2639, %r2519, 0, %p36;
	selp.b32 	%r2640, %r2639, 0, %p69;
	selp.b32 	%r2641, %r2640, 0, %p38;
	selp.b32 	%r2642, %r2520, 0, %p35;
	selp.b32 	%r2643, %r2642, 0, %p79;
	selp.b32 	%r2644, %r2643, 0, %p38;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2531+192], {%r2641, %r2644};
	.loc	1 71 29                         // chunk_scaled_dot_kkt.py:71:29
	selp.b32 	%r2645, %r2522, 0, %p35;
	selp.b32 	%r2646, %r2645, 0, %p81;
	selp.b32 	%r2647, %r2646, 0, %p37;
	selp.b32 	%r2648, %r2521, 0, %p36;
	selp.b32 	%r2649, %r2648, 0, %p80;
	selp.b32 	%r2650, %r2649, 0, %p37;
	.loc	1 73 18                         // chunk_scaled_dot_kkt.py:73:18
	st.shared.v2.b32 	[%r2541+2240], {%r2650, %r2647};
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2066, %r2067, %r2068, %r2069}, [%r2551];
	ld.shared.v4.b32 	{%r2070, %r2071, %r2072, %r2073}, [%r2556+1024];
	ld.shared.v4.b32 	{%r2074, %r2075, %r2076, %r2077}, [%r2561+2048];
	ld.shared.v4.b32 	{%r2078, %r2079, %r2080, %r2081}, [%r2566+3072];
	// begin inline asm
	@%p2 st.global.v4.b32 [ %rd19 + 0 ], { %r2018, %r2019, %r2020, %r2021 };
	// end inline asm
	// begin inline asm
	@%p3 st.global.v4.b32 [ %rd20 + 0 ], { %r2022, %r2023, %r2024, %r2025 };
	// end inline asm
	// begin inline asm
	@%p4 st.global.v4.b32 [ %rd21 + 0 ], { %r2026, %r2027, %r2028, %r2029 };
	// end inline asm
	// begin inline asm
	@%p5 st.global.v4.b32 [ %rd22 + 0 ], { %r2030, %r2031, %r2032, %r2033 };
	// end inline asm
	// begin inline asm
	@%p6 st.global.v4.b32 [ %rd23 + 0 ], { %r2034, %r2035, %r2036, %r2037 };
	// end inline asm
	// begin inline asm
	@%p7 st.global.v4.b32 [ %rd24 + 0 ], { %r2038, %r2039, %r2040, %r2041 };
	// end inline asm
	// begin inline asm
	@%p8 st.global.v4.b32 [ %rd25 + 0 ], { %r2042, %r2043, %r2044, %r2045 };
	// end inline asm
	// begin inline asm
	@%p9 st.global.v4.b32 [ %rd26 + 0 ], { %r2046, %r2047, %r2048, %r2049 };
	// end inline asm
	// begin inline asm
	@%p10 st.global.v4.b32 [ %rd27 + 0 ], { %r2050, %r2051, %r2052, %r2053 };
	// end inline asm
	// begin inline asm
	@%p11 st.global.v4.b32 [ %rd28 + 0 ], { %r2054, %r2055, %r2056, %r2057 };
	// end inline asm
	// begin inline asm
	@%p12 st.global.v4.b32 [ %rd29 + 0 ], { %r2058, %r2059, %r2060, %r2061 };
	// end inline asm
	// begin inline asm
	@%p13 st.global.v4.b32 [ %rd30 + 0 ], { %r2062, %r2063, %r2064, %r2065 };
	// end inline asm
	// begin inline asm
	@%p14 st.global.v4.b32 [ %rd31 + 0 ], { %r2066, %r2067, %r2068, %r2069 };
	// end inline asm
	// begin inline asm
	@%p15 st.global.v4.b32 [ %rd32 + 0 ], { %r2070, %r2071, %r2072, %r2073 };
	// end inline asm
	// begin inline asm
	@%p16 st.global.v4.b32 [ %rd33 + 0 ], { %r2074, %r2075, %r2076, %r2077 };
	// end inline asm
	// begin inline asm
	@%p17 st.global.v4.b32 [ %rd34 + 0 ], { %r2078, %r2079, %r2080, %r2081 };
	// end inline asm
	.loc	1 73 4                          // chunk_scaled_dot_kkt.py:73:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.13/site-packages/fla/ops/common/chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 127                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x78 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 51
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 102
.b8 108
.b8 97
.b8 47
.b8 111
.b8 112
.b8 115
.b8 47
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
	}
	.section	.debug_macinfo	{	}
