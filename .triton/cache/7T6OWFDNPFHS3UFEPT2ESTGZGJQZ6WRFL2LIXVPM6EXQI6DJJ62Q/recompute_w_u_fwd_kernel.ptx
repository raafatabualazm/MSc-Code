//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	recompute_w_u_fwd_kernel // -- Begin function recompute_w_u_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @recompute_w_u_fwd_kernel
.visible .entry recompute_w_u_fwd_kernel(
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_0,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_1,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_2,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_3,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_4,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_5,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_6,
	.param .u32 recompute_w_u_fwd_kernel_param_7,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_8
)
.reqntid 64
{
	.reg .pred 	%p<102>;
	.reg .b16 	%rs<66>;
	.reg .b32 	%r<2623>;
	.reg .b64 	%rd<236>;
	.loc	1 144 0                         // wy_fast.py:144:0
$L__func_begin0:
	.loc	1 144 0                         // wy_fast.py:144:0

// %bb.0:
	ld.param.b64 	%rd60, [recompute_w_u_fwd_kernel_param_6];
	ld.param.b64 	%rd59, [recompute_w_u_fwd_kernel_param_3];
	ld.param.b64 	%rd58, [recompute_w_u_fwd_kernel_param_0];
	ld.param.b64 	%rd79, [recompute_w_u_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 166 30                        // wy_fast.py:166:30
	mov.u32 	%r139, %ctaid.x;
	ld.param.b64 	%rd80, [recompute_w_u_fwd_kernel_param_2];
	.loc	1 166 48                        // wy_fast.py:166:48
	mov.u32 	%r140, %ctaid.y;
	.loc	1 173 25                        // wy_fast.py:173:25
	and.b32 	%r141, %r140, 65504;
	.loc	1 167 33                        // wy_fast.py:167:33
	and.b32 	%r142, %r140, 31;
	ld.param.b64 	%rd81, [recompute_w_u_fwd_kernel_param_4];
	ld.param.b32 	%r143, [recompute_w_u_fwd_kernel_param_7];
	.loc	1 174 42                        // wy_fast.py:174:42
	mul.lo.s32 	%r144, %r141, %r143;
	ld.param.b64 	%rd82, [recompute_w_u_fwd_kernel_param_5];
	.loc	1 174 38                        // wy_fast.py:174:38
	mul.wide.s32 	%rd83, %r144, 2;
	add.s64 	%rd84, %rd80, %rd83;
	.loc	1 174 46                        // wy_fast.py:174:46
	mul.wide.u32 	%rd85, %r142, 2;
	add.s64 	%rd86, %rd84, %rd85;
	.loc	1 174 70                        // wy_fast.py:174:70
	shl.b32 	%r145, %r139, 6;
	.loc	1 174 83                        // wy_fast.py:174:83
	cvt.s64.s32 	%rd87, %r143;
	cvt.s64.s32 	%rd88, %r145;
	.loc	1 175 21                        // wy_fast.py:175:21
	mov.u32 	%r146, %tid.x;
	bfe.u32 	%r147, %r146, 3, 3;
	or.b32 	%r148, %r147, 8;
	or.b32 	%r149, %r147, 16;
	or.b32 	%r150, %r147, 24;
	or.b32 	%r151, %r147, 32;
	or.b32 	%r152, %r147, 40;
	or.b32 	%r153, %r147, 48;
	or.b32 	%r154, %r147, 56;
	bfe.s32 	%r155, %r146, 2, 1;
	shl.b32 	%r156, %r146, 3;
	and.b32 	%r157, %r156, 56;
	and.b32 	%r1, %r146, 63;
	cvt.u64.u32 	%rd89, %r147;
	cvt.u64.u32 	%rd90, %r148;
	cvt.u64.u32 	%rd91, %r149;
	cvt.u64.u32 	%rd92, %r150;
	cvt.u64.u32 	%rd93, %r151;
	cvt.u64.u32 	%rd94, %r152;
	cvt.u64.u32 	%rd95, %r153;
	cvt.u64.u32 	%rd96, %r154;
	cvt.u64.u32 	%rd1, %r157;
	cvt.u64.u32 	%rd97, %r1;
	or.b64 	%rd98, %rd89, %rd88;
	or.b64 	%rd99, %rd90, %rd88;
	or.b64 	%rd100, %rd91, %rd88;
	or.b64 	%rd101, %rd92, %rd88;
	or.b64 	%rd102, %rd93, %rd88;
	or.b64 	%rd103, %rd94, %rd88;
	or.b64 	%rd104, %rd95, %rd88;
	or.b64 	%rd105, %rd96, %rd88;
	or.b64 	%rd106, %rd88, %rd97;
	shl.b64 	%rd2, %rd106, 5;
	shl.b64 	%rd107, %rd106, 6;
	add.s64 	%rd61, %rd86, %rd107;
	setp.gt.s32 	%p54, %r145, -1;
	setp.lt.s64 	%p55, %rd106, %rd87;
	and.pred 	%p73, %p54, %p55;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p73 ld.global.b16 { %rs1 }, [ %rd61 + 0 ];
	// end inline asm
	.loc	1 196 21                        // wy_fast.py:196:21
	shl.b32 	%r158, %r146, 1;
	and.b32 	%r2, %r158, 6;
	shl.b32 	%r159, %r1, 1;
	mov.b32 	%r160, global_smem;
	add.s32 	%r161, %r160, %r159;
	st.shared.b16 	[%r161], %rs1;
	bar.sync 	0;
	shl.b32 	%r162, %r2, 1;
	add.s32 	%r163, %r160, %r162;
	ld.shared.b32 	%r3, [%r163];
	ld.shared.b32 	%r4, [%r163+16];
	ld.shared.b32 	%r5, [%r163+32];
	ld.shared.b32 	%r6, [%r163+48];
	ld.shared.b32 	%r7, [%r163+64];
	ld.shared.b32 	%r8, [%r163+80];
	ld.shared.b32 	%r9, [%r163+96];
	ld.shared.b32 	%r10, [%r163+112];
	.loc	1 177 41                        // wy_fast.py:177:41
	or.b32 	%r11, %r144, %r142;
	.loc	1 177 48                        // wy_fast.py:177:48
	shl.b32 	%r164, %r11, 6;
	.loc	1 177 32                        // wy_fast.py:177:32
	mul.wide.s32 	%rd108, %r164, 2;
	add.s64 	%rd109, %rd82, %rd108;
	.loc	1 178 18                        // wy_fast.py:178:18
	shl.b64 	%rd3, %rd98, 12;
	add.s64 	%rd110, %rd109, %rd3;
	mul.wide.u32 	%rd111, %r157, 2;
	add.s64 	%rd62, %rd110, %rd111;
	shl.b64 	%rd4, %rd99, 12;
	add.s64 	%rd112, %rd109, %rd4;
	add.s64 	%rd63, %rd112, %rd111;
	shl.b64 	%rd5, %rd100, 12;
	add.s64 	%rd113, %rd109, %rd5;
	add.s64 	%rd64, %rd113, %rd111;
	shl.b64 	%rd6, %rd101, 12;
	add.s64 	%rd114, %rd109, %rd6;
	add.s64 	%rd65, %rd114, %rd111;
	shl.b64 	%rd7, %rd102, 12;
	add.s64 	%rd115, %rd109, %rd7;
	add.s64 	%rd66, %rd115, %rd111;
	shl.b64 	%rd8, %rd103, 12;
	add.s64 	%rd116, %rd109, %rd8;
	add.s64 	%rd67, %rd116, %rd111;
	shl.b64 	%rd9, %rd104, 12;
	add.s64 	%rd117, %rd109, %rd9;
	add.s64 	%rd68, %rd117, %rd111;
	shl.b64 	%rd10, %rd105, 12;
	add.s64 	%rd118, %rd109, %rd10;
	add.s64 	%rd69, %rd118, %rd111;
	setp.lt.s64 	%p56, %rd98, %rd87;
	setp.lt.s64 	%p57, %rd99, %rd87;
	setp.lt.s64 	%p58, %rd100, %rd87;
	setp.lt.s64 	%p59, %rd101, %rd87;
	setp.lt.s64 	%p60, %rd102, %rd87;
	setp.lt.s64 	%p61, %rd103, %rd87;
	setp.lt.s64 	%p62, %rd104, %rd87;
	setp.lt.s64 	%p63, %rd105, %rd87;
	and.pred 	%p45, %p54, %p56;
	mov.pred 	%p94, %p45;
	and.pred 	%p46, %p54, %p57;
	mov.pred 	%p95, %p46;
	and.pred 	%p47, %p54, %p58;
	mov.pred 	%p96, %p47;
	and.pred 	%p48, %p54, %p59;
	mov.pred 	%p97, %p48;
	and.pred 	%p49, %p54, %p60;
	mov.pred 	%p98, %p49;
	and.pred 	%p50, %p54, %p61;
	mov.pred 	%p99, %p50;
	and.pred 	%p51, %p54, %p62;
	mov.pred 	%p100, %p51;
	and.pred 	%p52, %p54, %p63;
	mov.pred 	%p101, %p52;
	// begin inline asm
	mov.u32 %r91, 0x0;
	mov.u32 %r92, 0x0;
	mov.u32 %r93, 0x0;
	mov.u32 %r94, 0x0;
	@%p45 ld.global.v4.b32 { %r91, %r92, %r93, %r94 }, [ %rd62 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r95, 0x0;
	mov.u32 %r96, 0x0;
	mov.u32 %r97, 0x0;
	mov.u32 %r98, 0x0;
	@%p46 ld.global.v4.b32 { %r95, %r96, %r97, %r98 }, [ %rd63 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r99, 0x0;
	mov.u32 %r100, 0x0;
	mov.u32 %r101, 0x0;
	mov.u32 %r102, 0x0;
	@%p47 ld.global.v4.b32 { %r99, %r100, %r101, %r102 }, [ %rd64 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r103, 0x0;
	mov.u32 %r104, 0x0;
	mov.u32 %r105, 0x0;
	mov.u32 %r106, 0x0;
	@%p48 ld.global.v4.b32 { %r103, %r104, %r105, %r106 }, [ %rd65 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r107, 0x0;
	mov.u32 %r108, 0x0;
	mov.u32 %r109, 0x0;
	mov.u32 %r110, 0x0;
	@%p49 ld.global.v4.b32 { %r107, %r108, %r109, %r110 }, [ %rd66 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r111, 0x0;
	mov.u32 %r112, 0x0;
	mov.u32 %r113, 0x0;
	mov.u32 %r114, 0x0;
	@%p50 ld.global.v4.b32 { %r111, %r112, %r113, %r114 }, [ %rd67 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r115, 0x0;
	mov.u32 %r116, 0x0;
	mov.u32 %r117, 0x0;
	mov.u32 %r118, 0x0;
	@%p51 ld.global.v4.b32 { %r115, %r116, %r117, %r118 }, [ %rd68 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r119, 0x0;
	mov.u32 %r120, 0x0;
	mov.u32 %r121, 0x0;
	mov.u32 %r122, 0x0;
	@%p52 ld.global.v4.b32 { %r119, %r120, %r121, %r122 }, [ %rd69 + 0 ];
	// end inline asm
	bar.sync 	0;
	xor.b32 	%r165, %r156, %r146;
	and.b32 	%r166, %r165, 56;
	shl.b32 	%r167, %r166, 1;
	shl.b32 	%r168, %r147, 7;
	or.b32 	%r169, %r168, %r167;
	add.s32 	%r170, %r160, %r169;
	st.shared.v4.b32 	[%r170], {%r91, %r92, %r93, %r94};
	st.shared.v4.b32 	[%r170+1024], {%r95, %r96, %r97, %r98};
	st.shared.v4.b32 	[%r170+2048], {%r99, %r100, %r101, %r102};
	st.shared.v4.b32 	[%r170+3072], {%r103, %r104, %r105, %r106};
	st.shared.v4.b32 	[%r170+4096], {%r107, %r108, %r109, %r110};
	st.shared.v4.b32 	[%r170+5120], {%r111, %r112, %r113, %r114};
	st.shared.v4.b32 	[%r170+6144], {%r115, %r116, %r117, %r118};
	st.shared.v4.b32 	[%r170+7168], {%r119, %r120, %r121, %r122};
	.loc	1 181 52                        // wy_fast.py:181:52
	shl.b32 	%r171, %r11, 7;
	.loc	1 181 36                        // wy_fast.py:181:36
	cvt.s64.s32 	%rd11, %r171;
	mul.wide.s32 	%rd119, %r171, 2;
	add.s64 	%rd12, %rd79, %rd119;
	.loc	1 182 36                        // wy_fast.py:182:36
	add.s64 	%rd13, %rd81, %rd119;
	.loc	1 183 22                        // wy_fast.py:183:22
	or.b64 	%rd228, %rd3, %rd1;
	or.b64 	%rd229, %rd4, %rd1;
	or.b64 	%rd230, %rd5, %rd1;
	or.b64 	%rd231, %rd6, %rd1;
	or.b64 	%rd232, %rd7, %rd1;
	or.b64 	%rd233, %rd8, %rd1;
	or.b64 	%rd234, %rd9, %rd1;
	or.b64 	%rd235, %rd10, %rd1;
	shl.b64 	%rd120, %rd228, 1;
	add.s64 	%rd70, %rd12, %rd120;
	shl.b64 	%rd121, %rd229, 1;
	add.s64 	%rd71, %rd12, %rd121;
	shl.b64 	%rd122, %rd230, 1;
	add.s64 	%rd72, %rd12, %rd122;
	shl.b64 	%rd123, %rd231, 1;
	add.s64 	%rd73, %rd12, %rd123;
	shl.b64 	%rd124, %rd232, 1;
	add.s64 	%rd74, %rd12, %rd124;
	shl.b64 	%rd125, %rd233, 1;
	add.s64 	%rd75, %rd12, %rd125;
	shl.b64 	%rd126, %rd234, 1;
	add.s64 	%rd76, %rd12, %rd126;
	shl.b64 	%rd127, %rd235, 1;
	add.s64 	%rd77, %rd12, %rd127;
	add.s32 	%r172, %r160, 8192;
	add.s32 	%r1343, %r172, %r169;
	add.s32 	%r1345, %r1343, 1024;
	add.s32 	%r1347, %r1343, 2048;
	add.s32 	%r1349, %r1343, 3072;
	add.s32 	%r1351, %r1343, 4096;
	add.s32 	%r1353, %r1343, 5120;
	add.s32 	%r1355, %r1343, 6144;
	add.s32 	%r1357, %r1343, 7168;
	selp.b32 	%r1344, 16, 0, %p45;
	// begin inline asm
	cp.async.cg.shared.global [ %r1343 + 0 ], [ %rd70 + 0 ], 0x10, %r1344;
	// end inline asm
	selp.b32 	%r1346, 16, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r1345 + 0 ], [ %rd71 + 0 ], 0x10, %r1346;
	// end inline asm
	selp.b32 	%r1348, 16, 0, %p47;
	// begin inline asm
	cp.async.cg.shared.global [ %r1347 + 0 ], [ %rd72 + 0 ], 0x10, %r1348;
	// end inline asm
	selp.b32 	%r1350, 16, 0, %p48;
	// begin inline asm
	cp.async.cg.shared.global [ %r1349 + 0 ], [ %rd73 + 0 ], 0x10, %r1350;
	// end inline asm
	selp.b32 	%r1352, 16, 0, %p49;
	// begin inline asm
	cp.async.cg.shared.global [ %r1351 + 0 ], [ %rd74 + 0 ], 0x10, %r1352;
	// end inline asm
	selp.b32 	%r1354, 16, 0, %p50;
	// begin inline asm
	cp.async.cg.shared.global [ %r1353 + 0 ], [ %rd75 + 0 ], 0x10, %r1354;
	// end inline asm
	selp.b32 	%r1356, 16, 0, %p51;
	// begin inline asm
	cp.async.cg.shared.global [ %r1355 + 0 ], [ %rd76 + 0 ], 0x10, %r1356;
	// end inline asm
	selp.b32 	%r1358, 16, 0, %p52;
	// begin inline asm
	cp.async.cg.shared.global [ %r1357 + 0 ], [ %rd77 + 0 ], 0x10, %r1358;
	// end inline asm
	cp.async.commit_group;
	and.b32 	%r173, %r146, 3;
	mul.lo.s32 	%r174, %r173, 72;
	and.b32 	%r175, %r155, 288;
	xor.b32 	%r176, %r175, %r174;
	shl.b32 	%r177, %r146, 6;
	and.b32 	%r178, %r177, 512;
	or.b32 	%r179, %r176, %r178;
	and.b32 	%r180, %r177, 1536;
	or.b32 	%r181, %r176, %r180;
	shr.u32 	%r182, %r146, 2;
	and.b32 	%r183, %r182, 8;
	xor.b32 	%r184, %r181, %r183;
	xor.b32 	%r185, %r184, 16;
	xor.b32 	%r186, %r184, 2064;
	xor.b32 	%r187, %r184, 32;
	xor.b32 	%r188, %r184, 2080;
	xor.b32 	%r189, %r184, 48;
	xor.b32 	%r190, %r184, 2096;
	shr.u32 	%r191, %r146, 1;
	and.b32 	%r192, %r191, 8;
	xor.b32 	%r193, %r179, %r192;
	shl.b32 	%r194, %r193, 1;
	add.s32 	%r290, %r160, %r194;
	xor.b32 	%r195, %r193, 16;
	shl.b32 	%r196, %r195, 1;
	add.s32 	%r295, %r160, %r196;
	xor.b32 	%r197, %r193, 32;
	shl.b32 	%r198, %r197, 1;
	add.s32 	%r300, %r160, %r198;
	xor.b32 	%r199, %r193, 48;
	shl.b32 	%r200, %r199, 1;
	add.s32 	%r305, %r160, %r200;
	add.s32 	%r310, %r290, 2048;
	xor.b32 	%r201, %r193, 1040;
	shl.b32 	%r202, %r201, 1;
	add.s32 	%r315, %r160, %r202;
	xor.b32 	%r203, %r193, 1056;
	shl.b32 	%r204, %r203, 1;
	add.s32 	%r320, %r160, %r204;
	xor.b32 	%r205, %r193, 1072;
	shl.b32 	%r206, %r205, 1;
	add.s32 	%r325, %r160, %r206;
	add.s32 	%r330, %r290, 4096;
	xor.b32 	%r207, %r193, 2064;
	shl.b32 	%r208, %r207, 1;
	add.s32 	%r335, %r160, %r208;
	xor.b32 	%r209, %r193, 2080;
	shl.b32 	%r210, %r209, 1;
	add.s32 	%r340, %r160, %r210;
	xor.b32 	%r211, %r193, 2096;
	shl.b32 	%r212, %r211, 1;
	add.s32 	%r345, %r160, %r212;
	add.s32 	%r350, %r290, 6144;
	xor.b32 	%r213, %r193, 3088;
	shl.b32 	%r214, %r213, 1;
	add.s32 	%r355, %r160, %r214;
	xor.b32 	%r215, %r193, 3104;
	shl.b32 	%r216, %r215, 1;
	add.s32 	%r360, %r160, %r216;
	xor.b32 	%r217, %r193, 3120;
	shl.b32 	%r218, %r217, 1;
	add.s32 	%r365, %r160, %r218;
	shl.b32 	%r219, %r146, 4;
	and.b32 	%r220, %r219, 448;
	or.b32 	%r221, %r220, %r2;
	or.b32 	%r222, %r221, %r183;
	and.b32 	%r223, %r156, 504;
	shr.u32 	%r224, %r220, 2;
	add.s32 	%r225, %r160, 16384;
	add.s32 	%r226, %r225, %r224;
	shl.b32 	%r227, %r222, 1;
	add.s32 	%r44, %r226, %r227;
	or.b32 	%r228, %r220, 512;
	shr.u32 	%r229, %r228, 2;
	add.s32 	%r230, %r225, %r229;
	add.s32 	%r45, %r230, %r227;
	and.b32 	%r231, %r146, 56;
	shl.b32 	%r232, %r231, 1;
	add.s32 	%r233, %r225, %r232;
	shl.b32 	%r234, %r223, 1;
	add.s32 	%r49, %r233, %r234;
	or.b32 	%r235, %r223, 512;
	shr.u32 	%r236, %r235, 2;
	and.b32 	%r237, %r236, 240;
	add.s32 	%r238, %r225, %r237;
	add.s32 	%r50, %r238, %r234;
	shl.b32 	%r239, %r184, 1;
	add.s32 	%r250, %r172, %r239;
	add.s32 	%r255, %r250, 4096;
	shl.b32 	%r240, %r185, 1;
	add.s32 	%r260, %r172, %r240;
	shl.b32 	%r241, %r186, 1;
	add.s32 	%r265, %r172, %r241;
	shl.b32 	%r242, %r187, 1;
	add.s32 	%r270, %r172, %r242;
	shl.b32 	%r243, %r188, 1;
	add.s32 	%r275, %r172, %r243;
	shl.b32 	%r244, %r189, 1;
	add.s32 	%r280, %r172, %r244;
	shl.b32 	%r245, %r190, 1;
	add.s32 	%r285, %r172, %r245;
	mov.b64 	%rd218, 64;
	mov.pred 	%p84, -1;
	mov.pred 	%p85, %p94;
	mov.pred 	%p86, %p95;
	mov.pred 	%p87, %p96;
	mov.pred 	%p88, %p97;
	mov.pred 	%p89, %p98;
	mov.pred 	%p90, %p99;
	mov.pred 	%p91, %p100;
	mov.pred 	%p92, %p101;
	mov.b64 	%rd219, %rd228;
	mov.b64 	%rd220, %rd229;
	mov.b64 	%rd221, %rd230;
	mov.b64 	%rd222, %rd231;
	mov.b64 	%rd223, %rd232;
	mov.b64 	%rd224, %rd233;
	mov.b64 	%rd225, %rd234;
	mov.b64 	%rd226, %rd235;
$L__BB0_1:                              // =>This Inner Loop Header: Depth=1
	.loc	1 0 22                          // wy_fast.py:0:22
	mov.pred 	%p10, %p84;
	.loc	1 183 22                        // wy_fast.py:183:22
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 184 22                        // wy_fast.py:184:22
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r246, %r247, %r248, %r249}, [%r250];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r251, %r252, %r253, %r254}, [%r255];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r256, %r257, %r258, %r259}, [%r260];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r261, %r262, %r263, %r264}, [%r265];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r266, %r267, %r268, %r269}, [%r270];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r271, %r272, %r273, %r274}, [%r275];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r276, %r277, %r278, %r279}, [%r280];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r281, %r282, %r283, %r284}, [%r285];
	// end inline asm
	.loc	1 178 18                        // wy_fast.py:178:18
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r374, %r375, %r376, %r377}, [%r290];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r598, %r599, %r600, %r601}, [%r295];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r822, %r823, %r824, %r825}, [%r300];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1046, %r1047, %r1048, %r1049}, [%r305];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r430, %r431, %r432, %r433}, [%r310];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r654, %r655, %r656, %r657}, [%r315];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r878, %r879, %r880, %r881}, [%r320];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1102, %r1103, %r1104, %r1105}, [%r325];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r486, %r487, %r488, %r489}, [%r330];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r710, %r711, %r712, %r713}, [%r335];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r934, %r935, %r936, %r937}, [%r340];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1158, %r1159, %r1160, %r1161}, [%r345];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r542, %r543, %r544, %r545}, [%r350];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r766, %r767, %r768, %r769}, [%r355];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r990, %r991, %r992, %r993}, [%r360];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1214, %r1215, %r1216, %r1217}, [%r365];
	// end inline asm
	.loc	1 185 26                        // wy_fast.py:185:26
	mul.bf16x2 	%r434, %r3, %r246;
	mul.bf16x2 	%r435, %r4, %r247;
	mul.bf16x2 	%r658, %r5, %r248;
	mul.bf16x2 	%r659, %r6, %r249;
	mul.bf16x2 	%r882, %r7, %r251;
	mul.bf16x2 	%r883, %r8, %r252;
	mul.bf16x2 	%r1106, %r9, %r253;
	mul.bf16x2 	%r1107, %r10, %r254;
	mul.bf16x2 	%r448, %r3, %r256;
	mul.bf16x2 	%r449, %r4, %r257;
	mul.bf16x2 	%r672, %r5, %r258;
	mul.bf16x2 	%r673, %r6, %r259;
	mul.bf16x2 	%r896, %r7, %r261;
	mul.bf16x2 	%r897, %r8, %r262;
	mul.bf16x2 	%r1120, %r9, %r263;
	mul.bf16x2 	%r1121, %r10, %r264;
	mul.bf16x2 	%r462, %r3, %r266;
	mul.bf16x2 	%r463, %r4, %r267;
	mul.bf16x2 	%r686, %r5, %r268;
	mul.bf16x2 	%r687, %r6, %r269;
	mul.bf16x2 	%r910, %r7, %r271;
	mul.bf16x2 	%r911, %r8, %r272;
	mul.bf16x2 	%r1134, %r9, %r273;
	mul.bf16x2 	%r1135, %r10, %r274;
	mul.bf16x2 	%r476, %r3, %r276;
	mul.bf16x2 	%r477, %r4, %r277;
	mul.bf16x2 	%r700, %r5, %r278;
	mul.bf16x2 	%r701, %r6, %r279;
	mul.bf16x2 	%r924, %r7, %r281;
	mul.bf16x2 	%r925, %r8, %r282;
	mul.bf16x2 	%r1148, %r9, %r283;
	mul.bf16x2 	%r1149, %r10, %r284;
	mov.b32 	%r800, 0;
	mov.b32 	%r590, %r800;
	mov.b32 	%r591, %r800;
	mov.b32 	%r592, %r800;
	mov.b32 	%r593, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r590, %r591, %r592, %r593 }, { %r374, %r375, %r376, %r377 }, { %r434, %r435 }, { %r590, %r591, %r592, %r593 };
	// end inline asm
	mov.b32 	%r604, %r800;
	mov.b32 	%r605, %r800;
	mov.b32 	%r606, %r800;
	mov.b32 	%r607, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r604, %r605, %r606, %r607 }, { %r374, %r375, %r376, %r377 }, { %r448, %r449 }, { %r604, %r605, %r606, %r607 };
	// end inline asm
	mov.b32 	%r618, %r800;
	mov.b32 	%r619, %r800;
	mov.b32 	%r620, %r800;
	mov.b32 	%r621, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r618, %r619, %r620, %r621 }, { %r374, %r375, %r376, %r377 }, { %r462, %r463 }, { %r618, %r619, %r620, %r621 };
	// end inline asm
	mov.b32 	%r632, %r800;
	mov.b32 	%r633, %r800;
	mov.b32 	%r634, %r800;
	mov.b32 	%r635, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r632, %r633, %r634, %r635 }, { %r374, %r375, %r376, %r377 }, { %r476, %r477 }, { %r632, %r633, %r634, %r635 };
	// end inline asm
	mov.b32 	%r646, %r800;
	mov.b32 	%r647, %r800;
	mov.b32 	%r648, %r800;
	mov.b32 	%r649, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r646, %r647, %r648, %r649 }, { %r430, %r431, %r432, %r433 }, { %r434, %r435 }, { %r646, %r647, %r648, %r649 };
	// end inline asm
	mov.b32 	%r660, %r800;
	mov.b32 	%r661, %r800;
	mov.b32 	%r662, %r800;
	mov.b32 	%r663, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r660, %r661, %r662, %r663 }, { %r430, %r431, %r432, %r433 }, { %r448, %r449 }, { %r660, %r661, %r662, %r663 };
	// end inline asm
	mov.b32 	%r674, %r800;
	mov.b32 	%r675, %r800;
	mov.b32 	%r676, %r800;
	mov.b32 	%r677, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r674, %r675, %r676, %r677 }, { %r430, %r431, %r432, %r433 }, { %r462, %r463 }, { %r674, %r675, %r676, %r677 };
	// end inline asm
	mov.b32 	%r688, %r800;
	mov.b32 	%r689, %r800;
	mov.b32 	%r690, %r800;
	mov.b32 	%r691, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r688, %r689, %r690, %r691 }, { %r430, %r431, %r432, %r433 }, { %r476, %r477 }, { %r688, %r689, %r690, %r691 };
	// end inline asm
	mov.b32 	%r702, %r800;
	mov.b32 	%r703, %r800;
	mov.b32 	%r704, %r800;
	mov.b32 	%r705, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r702, %r703, %r704, %r705 }, { %r486, %r487, %r488, %r489 }, { %r434, %r435 }, { %r702, %r703, %r704, %r705 };
	// end inline asm
	mov.b32 	%r716, %r800;
	mov.b32 	%r717, %r800;
	mov.b32 	%r718, %r800;
	mov.b32 	%r719, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r716, %r717, %r718, %r719 }, { %r486, %r487, %r488, %r489 }, { %r448, %r449 }, { %r716, %r717, %r718, %r719 };
	// end inline asm
	mov.b32 	%r730, %r800;
	mov.b32 	%r731, %r800;
	mov.b32 	%r732, %r800;
	mov.b32 	%r733, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r730, %r731, %r732, %r733 }, { %r486, %r487, %r488, %r489 }, { %r462, %r463 }, { %r730, %r731, %r732, %r733 };
	// end inline asm
	mov.b32 	%r744, %r800;
	mov.b32 	%r745, %r800;
	mov.b32 	%r746, %r800;
	mov.b32 	%r747, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r744, %r745, %r746, %r747 }, { %r486, %r487, %r488, %r489 }, { %r476, %r477 }, { %r744, %r745, %r746, %r747 };
	// end inline asm
	mov.b32 	%r758, %r800;
	mov.b32 	%r759, %r800;
	mov.b32 	%r760, %r800;
	mov.b32 	%r761, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r758, %r759, %r760, %r761 }, { %r542, %r543, %r544, %r545 }, { %r434, %r435 }, { %r758, %r759, %r760, %r761 };
	// end inline asm
	mov.b32 	%r772, %r800;
	mov.b32 	%r773, %r800;
	mov.b32 	%r774, %r800;
	mov.b32 	%r775, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r772, %r773, %r774, %r775 }, { %r542, %r543, %r544, %r545 }, { %r448, %r449 }, { %r772, %r773, %r774, %r775 };
	// end inline asm
	mov.b32 	%r786, %r800;
	mov.b32 	%r787, %r800;
	mov.b32 	%r788, %r800;
	mov.b32 	%r789, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r786, %r787, %r788, %r789 }, { %r542, %r543, %r544, %r545 }, { %r462, %r463 }, { %r786, %r787, %r788, %r789 };
	// end inline asm
	mov.b32 	%r801, %r800;
	mov.b32 	%r802, %r800;
	mov.b32 	%r803, %r800;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r800, %r801, %r802, %r803 }, { %r542, %r543, %r544, %r545 }, { %r476, %r477 }, { %r800, %r801, %r802, %r803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r590, %r591, %r592, %r593 }, { %r598, %r599, %r600, %r601 }, { %r658, %r659 }, { %r590, %r591, %r592, %r593 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r604, %r605, %r606, %r607 }, { %r598, %r599, %r600, %r601 }, { %r672, %r673 }, { %r604, %r605, %r606, %r607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r618, %r619, %r620, %r621 }, { %r598, %r599, %r600, %r601 }, { %r686, %r687 }, { %r618, %r619, %r620, %r621 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r632, %r633, %r634, %r635 }, { %r598, %r599, %r600, %r601 }, { %r700, %r701 }, { %r632, %r633, %r634, %r635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r646, %r647, %r648, %r649 }, { %r654, %r655, %r656, %r657 }, { %r658, %r659 }, { %r646, %r647, %r648, %r649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r660, %r661, %r662, %r663 }, { %r654, %r655, %r656, %r657 }, { %r672, %r673 }, { %r660, %r661, %r662, %r663 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r674, %r675, %r676, %r677 }, { %r654, %r655, %r656, %r657 }, { %r686, %r687 }, { %r674, %r675, %r676, %r677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r688, %r689, %r690, %r691 }, { %r654, %r655, %r656, %r657 }, { %r700, %r701 }, { %r688, %r689, %r690, %r691 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r702, %r703, %r704, %r705 }, { %r710, %r711, %r712, %r713 }, { %r658, %r659 }, { %r702, %r703, %r704, %r705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r716, %r717, %r718, %r719 }, { %r710, %r711, %r712, %r713 }, { %r672, %r673 }, { %r716, %r717, %r718, %r719 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r730, %r731, %r732, %r733 }, { %r710, %r711, %r712, %r713 }, { %r686, %r687 }, { %r730, %r731, %r732, %r733 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r744, %r745, %r746, %r747 }, { %r710, %r711, %r712, %r713 }, { %r700, %r701 }, { %r744, %r745, %r746, %r747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r758, %r759, %r760, %r761 }, { %r766, %r767, %r768, %r769 }, { %r658, %r659 }, { %r758, %r759, %r760, %r761 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r772, %r773, %r774, %r775 }, { %r766, %r767, %r768, %r769 }, { %r672, %r673 }, { %r772, %r773, %r774, %r775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r786, %r787, %r788, %r789 }, { %r766, %r767, %r768, %r769 }, { %r686, %r687 }, { %r786, %r787, %r788, %r789 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r800, %r801, %r802, %r803 }, { %r766, %r767, %r768, %r769 }, { %r700, %r701 }, { %r800, %r801, %r802, %r803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r590, %r591, %r592, %r593 }, { %r822, %r823, %r824, %r825 }, { %r882, %r883 }, { %r590, %r591, %r592, %r593 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r604, %r605, %r606, %r607 }, { %r822, %r823, %r824, %r825 }, { %r896, %r897 }, { %r604, %r605, %r606, %r607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r618, %r619, %r620, %r621 }, { %r822, %r823, %r824, %r825 }, { %r910, %r911 }, { %r618, %r619, %r620, %r621 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r632, %r633, %r634, %r635 }, { %r822, %r823, %r824, %r825 }, { %r924, %r925 }, { %r632, %r633, %r634, %r635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r646, %r647, %r648, %r649 }, { %r878, %r879, %r880, %r881 }, { %r882, %r883 }, { %r646, %r647, %r648, %r649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r660, %r661, %r662, %r663 }, { %r878, %r879, %r880, %r881 }, { %r896, %r897 }, { %r660, %r661, %r662, %r663 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r674, %r675, %r676, %r677 }, { %r878, %r879, %r880, %r881 }, { %r910, %r911 }, { %r674, %r675, %r676, %r677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r688, %r689, %r690, %r691 }, { %r878, %r879, %r880, %r881 }, { %r924, %r925 }, { %r688, %r689, %r690, %r691 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r702, %r703, %r704, %r705 }, { %r934, %r935, %r936, %r937 }, { %r882, %r883 }, { %r702, %r703, %r704, %r705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r716, %r717, %r718, %r719 }, { %r934, %r935, %r936, %r937 }, { %r896, %r897 }, { %r716, %r717, %r718, %r719 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r730, %r731, %r732, %r733 }, { %r934, %r935, %r936, %r937 }, { %r910, %r911 }, { %r730, %r731, %r732, %r733 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r744, %r745, %r746, %r747 }, { %r934, %r935, %r936, %r937 }, { %r924, %r925 }, { %r744, %r745, %r746, %r747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r758, %r759, %r760, %r761 }, { %r990, %r991, %r992, %r993 }, { %r882, %r883 }, { %r758, %r759, %r760, %r761 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r772, %r773, %r774, %r775 }, { %r990, %r991, %r992, %r993 }, { %r896, %r897 }, { %r772, %r773, %r774, %r775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r786, %r787, %r788, %r789 }, { %r990, %r991, %r992, %r993 }, { %r910, %r911 }, { %r786, %r787, %r788, %r789 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r800, %r801, %r802, %r803 }, { %r990, %r991, %r992, %r993 }, { %r924, %r925 }, { %r800, %r801, %r802, %r803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r590, %r591, %r592, %r593 }, { %r1046, %r1047, %r1048, %r1049 }, { %r1106, %r1107 }, { %r590, %r591, %r592, %r593 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r604, %r605, %r606, %r607 }, { %r1046, %r1047, %r1048, %r1049 }, { %r1120, %r1121 }, { %r604, %r605, %r606, %r607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r618, %r619, %r620, %r621 }, { %r1046, %r1047, %r1048, %r1049 }, { %r1134, %r1135 }, { %r618, %r619, %r620, %r621 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r632, %r633, %r634, %r635 }, { %r1046, %r1047, %r1048, %r1049 }, { %r1148, %r1149 }, { %r632, %r633, %r634, %r635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r646, %r647, %r648, %r649 }, { %r1102, %r1103, %r1104, %r1105 }, { %r1106, %r1107 }, { %r646, %r647, %r648, %r649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r660, %r661, %r662, %r663 }, { %r1102, %r1103, %r1104, %r1105 }, { %r1120, %r1121 }, { %r660, %r661, %r662, %r663 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r674, %r675, %r676, %r677 }, { %r1102, %r1103, %r1104, %r1105 }, { %r1134, %r1135 }, { %r674, %r675, %r676, %r677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r688, %r689, %r690, %r691 }, { %r1102, %r1103, %r1104, %r1105 }, { %r1148, %r1149 }, { %r688, %r689, %r690, %r691 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r702, %r703, %r704, %r705 }, { %r1158, %r1159, %r1160, %r1161 }, { %r1106, %r1107 }, { %r702, %r703, %r704, %r705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r716, %r717, %r718, %r719 }, { %r1158, %r1159, %r1160, %r1161 }, { %r1120, %r1121 }, { %r716, %r717, %r718, %r719 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r730, %r731, %r732, %r733 }, { %r1158, %r1159, %r1160, %r1161 }, { %r1134, %r1135 }, { %r730, %r731, %r732, %r733 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r744, %r745, %r746, %r747 }, { %r1158, %r1159, %r1160, %r1161 }, { %r1148, %r1149 }, { %r744, %r745, %r746, %r747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r758, %r759, %r760, %r761 }, { %r1214, %r1215, %r1216, %r1217 }, { %r1106, %r1107 }, { %r758, %r759, %r760, %r761 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r772, %r773, %r774, %r775 }, { %r1214, %r1215, %r1216, %r1217 }, { %r1120, %r1121 }, { %r772, %r773, %r774, %r775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r786, %r787, %r788, %r789 }, { %r1214, %r1215, %r1216, %r1217 }, { %r1134, %r1135 }, { %r786, %r787, %r788, %r789 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r800, %r801, %r802, %r803 }, { %r1214, %r1215, %r1216, %r1217 }, { %r1148, %r1149 }, { %r800, %r801, %r802, %r803 };
	// end inline asm
	.loc	1 186 29                        // wy_fast.py:186:29
	cvt.rn.bf16x2.f32 	%r1310, %r591, %r590;
	cvt.rn.bf16x2.f32 	%r1311, %r593, %r592;
	cvt.rn.bf16x2.f32 	%r1312, %r605, %r604;
	cvt.rn.bf16x2.f32 	%r1313, %r607, %r606;
	cvt.rn.bf16x2.f32 	%r1314, %r619, %r618;
	cvt.rn.bf16x2.f32 	%r1315, %r621, %r620;
	cvt.rn.bf16x2.f32 	%r1316, %r633, %r632;
	cvt.rn.bf16x2.f32 	%r1317, %r635, %r634;
	cvt.rn.bf16x2.f32 	%r1318, %r647, %r646;
	cvt.rn.bf16x2.f32 	%r1319, %r649, %r648;
	cvt.rn.bf16x2.f32 	%r1320, %r661, %r660;
	cvt.rn.bf16x2.f32 	%r1321, %r663, %r662;
	cvt.rn.bf16x2.f32 	%r1322, %r675, %r674;
	cvt.rn.bf16x2.f32 	%r1323, %r677, %r676;
	cvt.rn.bf16x2.f32 	%r1324, %r689, %r688;
	cvt.rn.bf16x2.f32 	%r1325, %r691, %r690;
	cvt.rn.bf16x2.f32 	%r1326, %r703, %r702;
	cvt.rn.bf16x2.f32 	%r1327, %r705, %r704;
	cvt.rn.bf16x2.f32 	%r1328, %r717, %r716;
	cvt.rn.bf16x2.f32 	%r1329, %r719, %r718;
	cvt.rn.bf16x2.f32 	%r1330, %r731, %r730;
	cvt.rn.bf16x2.f32 	%r1331, %r733, %r732;
	cvt.rn.bf16x2.f32 	%r1332, %r745, %r744;
	cvt.rn.bf16x2.f32 	%r1333, %r747, %r746;
	cvt.rn.bf16x2.f32 	%r1334, %r759, %r758;
	cvt.rn.bf16x2.f32 	%r1335, %r761, %r760;
	cvt.rn.bf16x2.f32 	%r1336, %r773, %r772;
	cvt.rn.bf16x2.f32 	%r1337, %r775, %r774;
	cvt.rn.bf16x2.f32 	%r1338, %r787, %r786;
	cvt.rn.bf16x2.f32 	%r1339, %r789, %r788;
	cvt.rn.bf16x2.f32 	%r1340, %r801, %r800;
	cvt.rn.bf16x2.f32 	%r1341, %r803, %r802;
	.loc	1 186 22                        // wy_fast.py:186:22
	shl.b64 	%rd145, %rd219, 1;
	add.s64 	%rd128, %rd13, %rd145;
	shl.b64 	%rd146, %rd220, 1;
	add.s64 	%rd129, %rd13, %rd146;
	shl.b64 	%rd147, %rd221, 1;
	add.s64 	%rd130, %rd13, %rd147;
	shl.b64 	%rd148, %rd222, 1;
	add.s64 	%rd131, %rd13, %rd148;
	shl.b64 	%rd149, %rd223, 1;
	add.s64 	%rd132, %rd13, %rd149;
	shl.b64 	%rd150, %rd224, 1;
	add.s64 	%rd133, %rd13, %rd150;
	shl.b64 	%rd151, %rd225, 1;
	add.s64 	%rd134, %rd13, %rd151;
	shl.b64 	%rd152, %rd226, 1;
	add.s64 	%rd135, %rd13, %rd152;
	st.shared.b32 	[%r44], %r1310;
	st.shared.b32 	[%r45+1024], %r1311;
	st.shared.b32 	[%r44+32], %r1312;
	st.shared.b32 	[%r45+1056], %r1313;
	st.shared.b32 	[%r44+64], %r1314;
	st.shared.b32 	[%r45+1088], %r1315;
	st.shared.b32 	[%r44+96], %r1316;
	st.shared.b32 	[%r45+1120], %r1317;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1262, %r1263, %r1264, %r1265}, [%r49];
	ld.shared.v4.b32 	{%r1266, %r1267, %r1268, %r1269}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r1318;
	st.shared.b32 	[%r45+1024], %r1319;
	st.shared.b32 	[%r44+32], %r1320;
	st.shared.b32 	[%r45+1056], %r1321;
	st.shared.b32 	[%r44+64], %r1322;
	st.shared.b32 	[%r45+1088], %r1323;
	st.shared.b32 	[%r44+96], %r1324;
	st.shared.b32 	[%r45+1120], %r1325;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1270, %r1271, %r1272, %r1273}, [%r49];
	ld.shared.v4.b32 	{%r1274, %r1275, %r1276, %r1277}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r1326;
	st.shared.b32 	[%r45+1024], %r1327;
	st.shared.b32 	[%r44+32], %r1328;
	st.shared.b32 	[%r45+1056], %r1329;
	st.shared.b32 	[%r44+64], %r1330;
	st.shared.b32 	[%r45+1088], %r1331;
	st.shared.b32 	[%r44+96], %r1332;
	st.shared.b32 	[%r45+1120], %r1333;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1278, %r1279, %r1280, %r1281}, [%r49];
	ld.shared.v4.b32 	{%r1282, %r1283, %r1284, %r1285}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r1334;
	st.shared.b32 	[%r45+1024], %r1335;
	st.shared.b32 	[%r44+32], %r1336;
	st.shared.b32 	[%r45+1056], %r1337;
	st.shared.b32 	[%r44+64], %r1338;
	st.shared.b32 	[%r45+1088], %r1339;
	st.shared.b32 	[%r44+96], %r1340;
	st.shared.b32 	[%r45+1120], %r1341;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1286, %r1287, %r1288, %r1289}, [%r49];
	ld.shared.v4.b32 	{%r1290, %r1291, %r1292, %r1293}, [%r50+1024];
	// begin inline asm
	@%p85 st.global.v4.b32 [ %rd128 + 0 ], { %r1262, %r1263, %r1264, %r1265 };
	// end inline asm
	// begin inline asm
	@%p86 st.global.v4.b32 [ %rd129 + 0 ], { %r1266, %r1267, %r1268, %r1269 };
	// end inline asm
	// begin inline asm
	@%p87 st.global.v4.b32 [ %rd130 + 0 ], { %r1270, %r1271, %r1272, %r1273 };
	// end inline asm
	// begin inline asm
	@%p88 st.global.v4.b32 [ %rd131 + 0 ], { %r1274, %r1275, %r1276, %r1277 };
	// end inline asm
	// begin inline asm
	@%p89 st.global.v4.b32 [ %rd132 + 0 ], { %r1278, %r1279, %r1280, %r1281 };
	// end inline asm
	// begin inline asm
	@%p90 st.global.v4.b32 [ %rd133 + 0 ], { %r1282, %r1283, %r1284, %r1285 };
	// end inline asm
	// begin inline asm
	@%p91 st.global.v4.b32 [ %rd134 + 0 ], { %r1286, %r1287, %r1288, %r1289 };
	// end inline asm
	// begin inline asm
	@%p92 st.global.v4.b32 [ %rd135 + 0 ], { %r1290, %r1291, %r1292, %r1293 };
	// end inline asm
	.loc	1 183 22                        // wy_fast.py:183:22
	or.b64 	%rd153, %rd218, %rd1;
	or.b64 	%rd219, %rd153, %rd3;
	or.b64 	%rd220, %rd153, %rd4;
	or.b64 	%rd221, %rd153, %rd5;
	or.b64 	%rd222, %rd153, %rd6;
	or.b64 	%rd223, %rd153, %rd7;
	or.b64 	%rd224, %rd153, %rd8;
	or.b64 	%rd225, %rd153, %rd9;
	or.b64 	%rd226, %rd153, %rd10;
	shl.b64 	%rd154, %rd219, 1;
	add.s64 	%rd136, %rd12, %rd154;
	shl.b64 	%rd155, %rd220, 1;
	add.s64 	%rd137, %rd12, %rd155;
	shl.b64 	%rd156, %rd221, 1;
	add.s64 	%rd138, %rd12, %rd156;
	shl.b64 	%rd157, %rd222, 1;
	add.s64 	%rd139, %rd12, %rd157;
	shl.b64 	%rd158, %rd223, 1;
	add.s64 	%rd140, %rd12, %rd158;
	shl.b64 	%rd159, %rd224, 1;
	add.s64 	%rd141, %rd12, %rd159;
	shl.b64 	%rd160, %rd225, 1;
	add.s64 	%rd142, %rd12, %rd160;
	shl.b64 	%rd161, %rd226, 1;
	add.s64 	%rd143, %rd12, %rd161;
	and.pred 	%p85, %p45, %p10;
	and.pred 	%p86, %p46, %p10;
	and.pred 	%p87, %p47, %p10;
	and.pred 	%p88, %p48, %p10;
	and.pred 	%p89, %p49, %p10;
	and.pred 	%p90, %p50, %p10;
	and.pred 	%p91, %p51, %p10;
	and.pred 	%p92, %p52, %p10;
	selp.b32 	%r1295, 16, 0, %p85;
	// begin inline asm
	cp.async.cg.shared.global [ %r1343 + 0 ], [ %rd136 + 0 ], 0x10, %r1295;
	// end inline asm
	selp.b32 	%r1297, 16, 0, %p86;
	// begin inline asm
	cp.async.cg.shared.global [ %r1345 + 0 ], [ %rd137 + 0 ], 0x10, %r1297;
	// end inline asm
	selp.b32 	%r1299, 16, 0, %p87;
	// begin inline asm
	cp.async.cg.shared.global [ %r1347 + 0 ], [ %rd138 + 0 ], 0x10, %r1299;
	// end inline asm
	selp.b32 	%r1301, 16, 0, %p88;
	// begin inline asm
	cp.async.cg.shared.global [ %r1349 + 0 ], [ %rd139 + 0 ], 0x10, %r1301;
	// end inline asm
	selp.b32 	%r1303, 16, 0, %p89;
	// begin inline asm
	cp.async.cg.shared.global [ %r1351 + 0 ], [ %rd140 + 0 ], 0x10, %r1303;
	// end inline asm
	selp.b32 	%r1305, 16, 0, %p90;
	// begin inline asm
	cp.async.cg.shared.global [ %r1353 + 0 ], [ %rd141 + 0 ], 0x10, %r1305;
	// end inline asm
	selp.b32 	%r1307, 16, 0, %p91;
	// begin inline asm
	cp.async.cg.shared.global [ %r1355 + 0 ], [ %rd142 + 0 ], 0x10, %r1307;
	// end inline asm
	selp.b32 	%r1309, 16, 0, %p92;
	// begin inline asm
	cp.async.cg.shared.global [ %r1357 + 0 ], [ %rd143 + 0 ], 0x10, %r1309;
	// end inline asm
	cp.async.commit_group;
	mov.b64 	%rd218, 128;
	mov.pred 	%p84, 0;
	.loc	1 180 21                        // wy_fast.py:180:21
	@%p10 bra 	$L__BB0_1;
// %bb.2:
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 189 37                        // wy_fast.py:189:37
	mul.wide.s32 	%rd172, %r11, 4;
	add.s64 	%rd173, %rd60, %rd172;
	.loc	1 190 26                        // wy_fast.py:190:26
	shl.b64 	%rd174, %rd2, 2;
	add.s64 	%rd162, %rd173, %rd174;
	// begin inline asm
	mov.u32 %r1342, 0x0;
	@%p73 ld.global.b32 { %r1342 }, [ %rd162 + 0 ];
	// end inline asm
	.loc	1 190 18                        // wy_fast.py:190:18
	mul.f32 	%r1359, %r1342, 0f3FB8AA3B;
	ex2.approx.f32 	%r1360, %r1359;
	shl.b32 	%r1361, %r1, 2;
	add.s32 	%r1364, %r172, %r1361;
	st.shared.b32 	[%r1364], %r1360;
	bar.sync 	0;
	shl.b32 	%r1365, %r2, 2;
	add.s32 	%r1366, %r172, %r1365;
	ld.shared.v2.b32 	{%r89, %r90}, [%r1366];
	ld.shared.v2.b32 	{%r87, %r88}, [%r1366+32];
	ld.shared.v2.b32 	{%r85, %r86}, [%r1366+64];
	ld.shared.v2.b32 	{%r83, %r84}, [%r1366+96];
	ld.shared.v2.b32 	{%r81, %r82}, [%r1366+128];
	ld.shared.v2.b32 	{%r79, %r80}, [%r1366+160];
	ld.shared.v2.b32 	{%r77, %r78}, [%r1366+192];
	ld.shared.v2.b32 	{%r75, %r76}, [%r1366+224];
	.loc	1 193 36                        // wy_fast.py:193:36
	shl.b64 	%rd175, %rd11, 1;
	add.s64 	%rd39, %rd58, %rd175;
	.loc	1 194 36                        // wy_fast.py:194:36
	add.s64 	%rd40, %rd59, %rd175;
	.loc	1 195 22                        // wy_fast.py:195:22
	add.s64 	%rd163, %rd39, %rd120;
	add.s64 	%rd164, %rd39, %rd121;
	add.s64 	%rd165, %rd39, %rd122;
	add.s64 	%rd166, %rd39, %rd123;
	add.s64 	%rd167, %rd39, %rd124;
	add.s64 	%rd168, %rd39, %rd125;
	add.s64 	%rd169, %rd39, %rd126;
	add.s64 	%rd170, %rd39, %rd127;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r1343 + 0 ], [ %rd163 + 0 ], 0x10, %r1344;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1345 + 0 ], [ %rd164 + 0 ], 0x10, %r1346;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1347 + 0 ], [ %rd165 + 0 ], 0x10, %r1348;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1349 + 0 ], [ %rd166 + 0 ], 0x10, %r1350;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1351 + 0 ], [ %rd167 + 0 ], 0x10, %r1352;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1353 + 0 ], [ %rd168 + 0 ], 0x10, %r1354;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1355 + 0 ], [ %rd169 + 0 ], 0x10, %r1356;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1357 + 0 ], [ %rd170 + 0 ], 0x10, %r1358;
	// end inline asm
	cp.async.commit_group;
	mov.b64 	%rd227, 64;
	mov.pred 	%p93, -1;
$L__BB0_3:                              // =>This Inner Loop Header: Depth=1
	.loc	1 0 22                          // wy_fast.py:0:22
	mov.pred 	%p27, %p93;
	.loc	1 195 22                        // wy_fast.py:195:22
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 202 34                        // wy_fast.py:202:34
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1367, %r1368, %r1369, %r1370}, [%r250];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1372, %r1373, %r1374, %r1375}, [%r255];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1377, %r1378, %r1379, %r1380}, [%r260];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1382, %r1383, %r1384, %r1385}, [%r265];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1387, %r1388, %r1389, %r1390}, [%r270];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1392, %r1393, %r1394, %r1395}, [%r275];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1397, %r1398, %r1399, %r1400}, [%r280];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1402, %r1403, %r1404, %r1405}, [%r285];
	// end inline asm
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2431, %r3, %r1367;
	mov.b32 	{%rs2, %rs3}, %r2431;
	mul.bf16x2 	%r2432, %r4, %r1368;
	mov.b32 	{%rs4, %rs5}, %r2432;
	mul.bf16x2 	%r2433, %r5, %r1369;
	mov.b32 	{%rs6, %rs7}, %r2433;
	mul.bf16x2 	%r2434, %r6, %r1370;
	mov.b32 	{%rs8, %rs9}, %r2434;
	mul.bf16x2 	%r2435, %r7, %r1372;
	mov.b32 	{%rs10, %rs11}, %r2435;
	mul.bf16x2 	%r2436, %r8, %r1373;
	mov.b32 	{%rs12, %rs13}, %r2436;
	mul.bf16x2 	%r2437, %r9, %r1374;
	mov.b32 	{%rs14, %rs15}, %r2437;
	mul.bf16x2 	%r2438, %r10, %r1375;
	mov.b32 	{%rs16, %rs17}, %r2438;
	mul.bf16x2 	%r2439, %r3, %r1377;
	mov.b32 	{%rs18, %rs19}, %r2439;
	mul.bf16x2 	%r2440, %r4, %r1378;
	mov.b32 	{%rs20, %rs21}, %r2440;
	mul.bf16x2 	%r2441, %r5, %r1379;
	mov.b32 	{%rs22, %rs23}, %r2441;
	mul.bf16x2 	%r2442, %r6, %r1380;
	mov.b32 	{%rs24, %rs25}, %r2442;
	mul.bf16x2 	%r2443, %r7, %r1382;
	mov.b32 	{%rs26, %rs27}, %r2443;
	mul.bf16x2 	%r2444, %r8, %r1383;
	mov.b32 	{%rs28, %rs29}, %r2444;
	mul.bf16x2 	%r2445, %r9, %r1384;
	mov.b32 	{%rs30, %rs31}, %r2445;
	mul.bf16x2 	%r2446, %r10, %r1385;
	mov.b32 	{%rs32, %rs33}, %r2446;
	mul.bf16x2 	%r2447, %r3, %r1387;
	mov.b32 	{%rs34, %rs35}, %r2447;
	mul.bf16x2 	%r2448, %r4, %r1388;
	mov.b32 	{%rs36, %rs37}, %r2448;
	mul.bf16x2 	%r2449, %r5, %r1389;
	mov.b32 	{%rs38, %rs39}, %r2449;
	mul.bf16x2 	%r2450, %r6, %r1390;
	mov.b32 	{%rs40, %rs41}, %r2450;
	mul.bf16x2 	%r2451, %r7, %r1392;
	mov.b32 	{%rs42, %rs43}, %r2451;
	mul.bf16x2 	%r2452, %r8, %r1393;
	mov.b32 	{%rs44, %rs45}, %r2452;
	mul.bf16x2 	%r2453, %r9, %r1394;
	mov.b32 	{%rs46, %rs47}, %r2453;
	mul.bf16x2 	%r2454, %r10, %r1395;
	mov.b32 	{%rs48, %rs49}, %r2454;
	.loc	1 198 20                        // wy_fast.py:198:20
	cvt.f32.bf16 	%r2455, %rs2;
	cvt.f32.bf16 	%r2456, %rs3;
	cvt.f32.bf16 	%r2457, %rs4;
	cvt.f32.bf16 	%r2458, %rs5;
	cvt.f32.bf16 	%r2459, %rs6;
	cvt.f32.bf16 	%r2460, %rs7;
	cvt.f32.bf16 	%r2461, %rs8;
	cvt.f32.bf16 	%r2462, %rs9;
	cvt.f32.bf16 	%r2463, %rs10;
	cvt.f32.bf16 	%r2464, %rs11;
	cvt.f32.bf16 	%r2465, %rs12;
	cvt.f32.bf16 	%r2466, %rs13;
	cvt.f32.bf16 	%r2467, %rs14;
	cvt.f32.bf16 	%r2468, %rs15;
	cvt.f32.bf16 	%r2469, %rs16;
	cvt.f32.bf16 	%r2470, %rs17;
	cvt.f32.bf16 	%r2471, %rs18;
	cvt.f32.bf16 	%r2472, %rs19;
	cvt.f32.bf16 	%r2473, %rs20;
	cvt.f32.bf16 	%r2474, %rs21;
	cvt.f32.bf16 	%r2475, %rs22;
	cvt.f32.bf16 	%r2476, %rs23;
	cvt.f32.bf16 	%r2477, %rs24;
	cvt.f32.bf16 	%r2478, %rs25;
	cvt.f32.bf16 	%r2479, %rs26;
	cvt.f32.bf16 	%r2480, %rs27;
	cvt.f32.bf16 	%r2481, %rs28;
	cvt.f32.bf16 	%r2482, %rs29;
	cvt.f32.bf16 	%r2483, %rs30;
	cvt.f32.bf16 	%r2484, %rs31;
	cvt.f32.bf16 	%r2485, %rs32;
	cvt.f32.bf16 	%r2486, %rs33;
	cvt.f32.bf16 	%r2487, %rs34;
	cvt.f32.bf16 	%r2488, %rs35;
	cvt.f32.bf16 	%r2489, %rs36;
	cvt.f32.bf16 	%r2490, %rs37;
	cvt.f32.bf16 	%r2491, %rs38;
	cvt.f32.bf16 	%r2492, %rs39;
	cvt.f32.bf16 	%r2493, %rs40;
	cvt.f32.bf16 	%r2494, %rs41;
	cvt.f32.bf16 	%r2495, %rs42;
	cvt.f32.bf16 	%r2496, %rs43;
	cvt.f32.bf16 	%r2497, %rs44;
	cvt.f32.bf16 	%r2498, %rs45;
	cvt.f32.bf16 	%r2499, %rs46;
	cvt.f32.bf16 	%r2500, %rs47;
	cvt.f32.bf16 	%r2501, %rs48;
	cvt.f32.bf16 	%r2502, %rs49;
	mul.f32 	%r2503, %r89, %r2455;
	mul.f32 	%r2504, %r90, %r2456;
	mul.f32 	%r2505, %r87, %r2457;
	mul.f32 	%r2506, %r88, %r2458;
	mul.f32 	%r2507, %r85, %r2459;
	mul.f32 	%r2508, %r86, %r2460;
	mul.f32 	%r2509, %r83, %r2461;
	mul.f32 	%r2510, %r84, %r2462;
	mul.f32 	%r2511, %r81, %r2463;
	mul.f32 	%r2512, %r82, %r2464;
	mul.f32 	%r2513, %r79, %r2465;
	mul.f32 	%r2514, %r80, %r2466;
	mul.f32 	%r2515, %r77, %r2467;
	mul.f32 	%r2516, %r78, %r2468;
	mul.f32 	%r2517, %r75, %r2469;
	mul.f32 	%r2518, %r76, %r2470;
	mul.f32 	%r2519, %r89, %r2471;
	mul.f32 	%r2520, %r90, %r2472;
	mul.f32 	%r2521, %r87, %r2473;
	mul.f32 	%r2522, %r88, %r2474;
	mul.f32 	%r2523, %r85, %r2475;
	mul.f32 	%r2524, %r86, %r2476;
	mul.f32 	%r2525, %r83, %r2477;
	mul.f32 	%r2526, %r84, %r2478;
	mul.f32 	%r2527, %r81, %r2479;
	mul.f32 	%r2528, %r82, %r2480;
	mul.f32 	%r2529, %r79, %r2481;
	mul.f32 	%r2530, %r80, %r2482;
	mul.f32 	%r2531, %r77, %r2483;
	mul.f32 	%r2532, %r78, %r2484;
	mul.f32 	%r2533, %r75, %r2485;
	mul.f32 	%r2534, %r76, %r2486;
	mul.f32 	%r2535, %r89, %r2487;
	mul.f32 	%r2536, %r90, %r2488;
	mul.f32 	%r2537, %r87, %r2489;
	mul.f32 	%r2538, %r88, %r2490;
	mul.f32 	%r2539, %r85, %r2491;
	mul.f32 	%r2540, %r86, %r2492;
	mul.f32 	%r2541, %r83, %r2493;
	mul.f32 	%r2542, %r84, %r2494;
	mul.f32 	%r2543, %r81, %r2495;
	mul.f32 	%r2544, %r82, %r2496;
	mul.f32 	%r2545, %r79, %r2497;
	mul.f32 	%r2546, %r80, %r2498;
	mul.f32 	%r2547, %r77, %r2499;
	mul.f32 	%r2548, %r78, %r2500;
	mul.f32 	%r2549, %r75, %r2501;
	mul.f32 	%r2550, %r76, %r2502;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2551, %r3, %r1397;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs50, %rs51}, %r2551;
	cvt.f32.bf16 	%r2552, %rs51;
	cvt.f32.bf16 	%r2553, %rs50;
	mul.f32 	%r2554, %r89, %r2553;
	mul.f32 	%r2555, %r90, %r2552;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1597, %r2555, %r2554;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2556, %r4, %r1398;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs52, %rs53}, %r2556;
	cvt.f32.bf16 	%r2557, %rs53;
	cvt.f32.bf16 	%r2558, %rs52;
	mul.f32 	%r2559, %r87, %r2558;
	mul.f32 	%r2560, %r88, %r2557;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1598, %r2560, %r2559;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2561, %r5, %r1399;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs54, %rs55}, %r2561;
	cvt.f32.bf16 	%r2562, %rs55;
	cvt.f32.bf16 	%r2563, %rs54;
	mul.f32 	%r2564, %r85, %r2563;
	mul.f32 	%r2565, %r86, %r2562;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1821, %r2565, %r2564;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2566, %r6, %r1400;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs56, %rs57}, %r2566;
	cvt.f32.bf16 	%r2567, %rs57;
	cvt.f32.bf16 	%r2568, %rs56;
	mul.f32 	%r2569, %r83, %r2568;
	mul.f32 	%r2570, %r84, %r2567;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1822, %r2570, %r2569;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2571, %r7, %r1402;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs58, %rs59}, %r2571;
	cvt.f32.bf16 	%r2572, %rs59;
	cvt.f32.bf16 	%r2573, %rs58;
	mul.f32 	%r2574, %r81, %r2573;
	mul.f32 	%r2575, %r82, %r2572;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2045, %r2575, %r2574;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2576, %r8, %r1403;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs60, %rs61}, %r2576;
	cvt.f32.bf16 	%r2577, %rs61;
	cvt.f32.bf16 	%r2578, %rs60;
	mul.f32 	%r2579, %r79, %r2578;
	mul.f32 	%r2580, %r80, %r2577;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2046, %r2580, %r2579;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2581, %r9, %r1404;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs62, %rs63}, %r2581;
	cvt.f32.bf16 	%r2582, %rs63;
	cvt.f32.bf16 	%r2583, %rs62;
	mul.f32 	%r2584, %r77, %r2583;
	mul.f32 	%r2585, %r78, %r2582;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2269, %r2585, %r2584;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2586, %r10, %r1405;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs64, %rs65}, %r2586;
	cvt.f32.bf16 	%r2587, %rs65;
	cvt.f32.bf16 	%r2588, %rs64;
	mul.f32 	%r2589, %r75, %r2588;
	mul.f32 	%r2590, %r76, %r2587;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2270, %r2590, %r2589;
	.loc	1 178 18                        // wy_fast.py:178:18
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1495, %r1496, %r1497, %r1498}, [%r290];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1719, %r1720, %r1721, %r1722}, [%r295];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1943, %r1944, %r1945, %r1946}, [%r300];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2167, %r2168, %r2169, %r2170}, [%r305];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1551, %r1552, %r1553, %r1554}, [%r310];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1775, %r1776, %r1777, %r1778}, [%r315];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1999, %r2000, %r2001, %r2002}, [%r320];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2223, %r2224, %r2225, %r2226}, [%r325];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1607, %r1608, %r1609, %r1610}, [%r330];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1831, %r1832, %r1833, %r1834}, [%r335];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2055, %r2056, %r2057, %r2058}, [%r340];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2279, %r2280, %r2281, %r2282}, [%r345];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1663, %r1664, %r1665, %r1666}, [%r350];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1887, %r1888, %r1889, %r1890}, [%r355];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2111, %r2112, %r2113, %r2114}, [%r360];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2335, %r2336, %r2337, %r2338}, [%r365];
	// end inline asm
	.loc	1 202 26                        // wy_fast.py:202:26
	cvt.rn.bf16x2.f32 	%r1555, %r2504, %r2503;
	cvt.rn.bf16x2.f32 	%r1556, %r2506, %r2505;
	cvt.rn.bf16x2.f32 	%r1779, %r2508, %r2507;
	cvt.rn.bf16x2.f32 	%r1780, %r2510, %r2509;
	cvt.rn.bf16x2.f32 	%r2003, %r2512, %r2511;
	cvt.rn.bf16x2.f32 	%r2004, %r2514, %r2513;
	cvt.rn.bf16x2.f32 	%r2227, %r2516, %r2515;
	cvt.rn.bf16x2.f32 	%r2228, %r2518, %r2517;
	cvt.rn.bf16x2.f32 	%r1569, %r2520, %r2519;
	cvt.rn.bf16x2.f32 	%r1570, %r2522, %r2521;
	cvt.rn.bf16x2.f32 	%r1793, %r2524, %r2523;
	cvt.rn.bf16x2.f32 	%r1794, %r2526, %r2525;
	cvt.rn.bf16x2.f32 	%r2017, %r2528, %r2527;
	cvt.rn.bf16x2.f32 	%r2018, %r2530, %r2529;
	cvt.rn.bf16x2.f32 	%r2241, %r2532, %r2531;
	cvt.rn.bf16x2.f32 	%r2242, %r2534, %r2533;
	cvt.rn.bf16x2.f32 	%r1583, %r2536, %r2535;
	cvt.rn.bf16x2.f32 	%r1584, %r2538, %r2537;
	cvt.rn.bf16x2.f32 	%r1807, %r2540, %r2539;
	cvt.rn.bf16x2.f32 	%r1808, %r2542, %r2541;
	cvt.rn.bf16x2.f32 	%r2031, %r2544, %r2543;
	cvt.rn.bf16x2.f32 	%r2032, %r2546, %r2545;
	cvt.rn.bf16x2.f32 	%r2255, %r2548, %r2547;
	cvt.rn.bf16x2.f32 	%r2256, %r2550, %r2549;
	mov.b32 	%r1921, 0;
	mov.b32 	%r1711, %r1921;
	mov.b32 	%r1712, %r1921;
	mov.b32 	%r1713, %r1921;
	mov.b32 	%r1714, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1711, %r1712, %r1713, %r1714 }, { %r1495, %r1496, %r1497, %r1498 }, { %r1555, %r1556 }, { %r1711, %r1712, %r1713, %r1714 };
	// end inline asm
	mov.b32 	%r1725, %r1921;
	mov.b32 	%r1726, %r1921;
	mov.b32 	%r1727, %r1921;
	mov.b32 	%r1728, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1725, %r1726, %r1727, %r1728 }, { %r1495, %r1496, %r1497, %r1498 }, { %r1569, %r1570 }, { %r1725, %r1726, %r1727, %r1728 };
	// end inline asm
	mov.b32 	%r1739, %r1921;
	mov.b32 	%r1740, %r1921;
	mov.b32 	%r1741, %r1921;
	mov.b32 	%r1742, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1739, %r1740, %r1741, %r1742 }, { %r1495, %r1496, %r1497, %r1498 }, { %r1583, %r1584 }, { %r1739, %r1740, %r1741, %r1742 };
	// end inline asm
	mov.b32 	%r1753, %r1921;
	mov.b32 	%r1754, %r1921;
	mov.b32 	%r1755, %r1921;
	mov.b32 	%r1756, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1753, %r1754, %r1755, %r1756 }, { %r1495, %r1496, %r1497, %r1498 }, { %r1597, %r1598 }, { %r1753, %r1754, %r1755, %r1756 };
	// end inline asm
	mov.b32 	%r1767, %r1921;
	mov.b32 	%r1768, %r1921;
	mov.b32 	%r1769, %r1921;
	mov.b32 	%r1770, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1767, %r1768, %r1769, %r1770 }, { %r1551, %r1552, %r1553, %r1554 }, { %r1555, %r1556 }, { %r1767, %r1768, %r1769, %r1770 };
	// end inline asm
	mov.b32 	%r1781, %r1921;
	mov.b32 	%r1782, %r1921;
	mov.b32 	%r1783, %r1921;
	mov.b32 	%r1784, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1781, %r1782, %r1783, %r1784 }, { %r1551, %r1552, %r1553, %r1554 }, { %r1569, %r1570 }, { %r1781, %r1782, %r1783, %r1784 };
	// end inline asm
	mov.b32 	%r1795, %r1921;
	mov.b32 	%r1796, %r1921;
	mov.b32 	%r1797, %r1921;
	mov.b32 	%r1798, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1795, %r1796, %r1797, %r1798 }, { %r1551, %r1552, %r1553, %r1554 }, { %r1583, %r1584 }, { %r1795, %r1796, %r1797, %r1798 };
	// end inline asm
	mov.b32 	%r1809, %r1921;
	mov.b32 	%r1810, %r1921;
	mov.b32 	%r1811, %r1921;
	mov.b32 	%r1812, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1809, %r1810, %r1811, %r1812 }, { %r1551, %r1552, %r1553, %r1554 }, { %r1597, %r1598 }, { %r1809, %r1810, %r1811, %r1812 };
	// end inline asm
	mov.b32 	%r1823, %r1921;
	mov.b32 	%r1824, %r1921;
	mov.b32 	%r1825, %r1921;
	mov.b32 	%r1826, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1823, %r1824, %r1825, %r1826 }, { %r1607, %r1608, %r1609, %r1610 }, { %r1555, %r1556 }, { %r1823, %r1824, %r1825, %r1826 };
	// end inline asm
	mov.b32 	%r1837, %r1921;
	mov.b32 	%r1838, %r1921;
	mov.b32 	%r1839, %r1921;
	mov.b32 	%r1840, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1837, %r1838, %r1839, %r1840 }, { %r1607, %r1608, %r1609, %r1610 }, { %r1569, %r1570 }, { %r1837, %r1838, %r1839, %r1840 };
	// end inline asm
	mov.b32 	%r1851, %r1921;
	mov.b32 	%r1852, %r1921;
	mov.b32 	%r1853, %r1921;
	mov.b32 	%r1854, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1851, %r1852, %r1853, %r1854 }, { %r1607, %r1608, %r1609, %r1610 }, { %r1583, %r1584 }, { %r1851, %r1852, %r1853, %r1854 };
	// end inline asm
	mov.b32 	%r1865, %r1921;
	mov.b32 	%r1866, %r1921;
	mov.b32 	%r1867, %r1921;
	mov.b32 	%r1868, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1865, %r1866, %r1867, %r1868 }, { %r1607, %r1608, %r1609, %r1610 }, { %r1597, %r1598 }, { %r1865, %r1866, %r1867, %r1868 };
	// end inline asm
	mov.b32 	%r1879, %r1921;
	mov.b32 	%r1880, %r1921;
	mov.b32 	%r1881, %r1921;
	mov.b32 	%r1882, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1879, %r1880, %r1881, %r1882 }, { %r1663, %r1664, %r1665, %r1666 }, { %r1555, %r1556 }, { %r1879, %r1880, %r1881, %r1882 };
	// end inline asm
	mov.b32 	%r1893, %r1921;
	mov.b32 	%r1894, %r1921;
	mov.b32 	%r1895, %r1921;
	mov.b32 	%r1896, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1893, %r1894, %r1895, %r1896 }, { %r1663, %r1664, %r1665, %r1666 }, { %r1569, %r1570 }, { %r1893, %r1894, %r1895, %r1896 };
	// end inline asm
	mov.b32 	%r1907, %r1921;
	mov.b32 	%r1908, %r1921;
	mov.b32 	%r1909, %r1921;
	mov.b32 	%r1910, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1907, %r1908, %r1909, %r1910 }, { %r1663, %r1664, %r1665, %r1666 }, { %r1583, %r1584 }, { %r1907, %r1908, %r1909, %r1910 };
	// end inline asm
	mov.b32 	%r1922, %r1921;
	mov.b32 	%r1923, %r1921;
	mov.b32 	%r1924, %r1921;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1921, %r1922, %r1923, %r1924 }, { %r1663, %r1664, %r1665, %r1666 }, { %r1597, %r1598 }, { %r1921, %r1922, %r1923, %r1924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1711, %r1712, %r1713, %r1714 }, { %r1719, %r1720, %r1721, %r1722 }, { %r1779, %r1780 }, { %r1711, %r1712, %r1713, %r1714 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1725, %r1726, %r1727, %r1728 }, { %r1719, %r1720, %r1721, %r1722 }, { %r1793, %r1794 }, { %r1725, %r1726, %r1727, %r1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1739, %r1740, %r1741, %r1742 }, { %r1719, %r1720, %r1721, %r1722 }, { %r1807, %r1808 }, { %r1739, %r1740, %r1741, %r1742 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1753, %r1754, %r1755, %r1756 }, { %r1719, %r1720, %r1721, %r1722 }, { %r1821, %r1822 }, { %r1753, %r1754, %r1755, %r1756 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1767, %r1768, %r1769, %r1770 }, { %r1775, %r1776, %r1777, %r1778 }, { %r1779, %r1780 }, { %r1767, %r1768, %r1769, %r1770 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1781, %r1782, %r1783, %r1784 }, { %r1775, %r1776, %r1777, %r1778 }, { %r1793, %r1794 }, { %r1781, %r1782, %r1783, %r1784 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1795, %r1796, %r1797, %r1798 }, { %r1775, %r1776, %r1777, %r1778 }, { %r1807, %r1808 }, { %r1795, %r1796, %r1797, %r1798 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1809, %r1810, %r1811, %r1812 }, { %r1775, %r1776, %r1777, %r1778 }, { %r1821, %r1822 }, { %r1809, %r1810, %r1811, %r1812 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1823, %r1824, %r1825, %r1826 }, { %r1831, %r1832, %r1833, %r1834 }, { %r1779, %r1780 }, { %r1823, %r1824, %r1825, %r1826 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1837, %r1838, %r1839, %r1840 }, { %r1831, %r1832, %r1833, %r1834 }, { %r1793, %r1794 }, { %r1837, %r1838, %r1839, %r1840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1851, %r1852, %r1853, %r1854 }, { %r1831, %r1832, %r1833, %r1834 }, { %r1807, %r1808 }, { %r1851, %r1852, %r1853, %r1854 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1865, %r1866, %r1867, %r1868 }, { %r1831, %r1832, %r1833, %r1834 }, { %r1821, %r1822 }, { %r1865, %r1866, %r1867, %r1868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1879, %r1880, %r1881, %r1882 }, { %r1887, %r1888, %r1889, %r1890 }, { %r1779, %r1780 }, { %r1879, %r1880, %r1881, %r1882 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1893, %r1894, %r1895, %r1896 }, { %r1887, %r1888, %r1889, %r1890 }, { %r1793, %r1794 }, { %r1893, %r1894, %r1895, %r1896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1907, %r1908, %r1909, %r1910 }, { %r1887, %r1888, %r1889, %r1890 }, { %r1807, %r1808 }, { %r1907, %r1908, %r1909, %r1910 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1921, %r1922, %r1923, %r1924 }, { %r1887, %r1888, %r1889, %r1890 }, { %r1821, %r1822 }, { %r1921, %r1922, %r1923, %r1924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1711, %r1712, %r1713, %r1714 }, { %r1943, %r1944, %r1945, %r1946 }, { %r2003, %r2004 }, { %r1711, %r1712, %r1713, %r1714 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1725, %r1726, %r1727, %r1728 }, { %r1943, %r1944, %r1945, %r1946 }, { %r2017, %r2018 }, { %r1725, %r1726, %r1727, %r1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1739, %r1740, %r1741, %r1742 }, { %r1943, %r1944, %r1945, %r1946 }, { %r2031, %r2032 }, { %r1739, %r1740, %r1741, %r1742 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1753, %r1754, %r1755, %r1756 }, { %r1943, %r1944, %r1945, %r1946 }, { %r2045, %r2046 }, { %r1753, %r1754, %r1755, %r1756 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1767, %r1768, %r1769, %r1770 }, { %r1999, %r2000, %r2001, %r2002 }, { %r2003, %r2004 }, { %r1767, %r1768, %r1769, %r1770 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1781, %r1782, %r1783, %r1784 }, { %r1999, %r2000, %r2001, %r2002 }, { %r2017, %r2018 }, { %r1781, %r1782, %r1783, %r1784 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1795, %r1796, %r1797, %r1798 }, { %r1999, %r2000, %r2001, %r2002 }, { %r2031, %r2032 }, { %r1795, %r1796, %r1797, %r1798 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1809, %r1810, %r1811, %r1812 }, { %r1999, %r2000, %r2001, %r2002 }, { %r2045, %r2046 }, { %r1809, %r1810, %r1811, %r1812 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1823, %r1824, %r1825, %r1826 }, { %r2055, %r2056, %r2057, %r2058 }, { %r2003, %r2004 }, { %r1823, %r1824, %r1825, %r1826 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1837, %r1838, %r1839, %r1840 }, { %r2055, %r2056, %r2057, %r2058 }, { %r2017, %r2018 }, { %r1837, %r1838, %r1839, %r1840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1851, %r1852, %r1853, %r1854 }, { %r2055, %r2056, %r2057, %r2058 }, { %r2031, %r2032 }, { %r1851, %r1852, %r1853, %r1854 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1865, %r1866, %r1867, %r1868 }, { %r2055, %r2056, %r2057, %r2058 }, { %r2045, %r2046 }, { %r1865, %r1866, %r1867, %r1868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1879, %r1880, %r1881, %r1882 }, { %r2111, %r2112, %r2113, %r2114 }, { %r2003, %r2004 }, { %r1879, %r1880, %r1881, %r1882 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1893, %r1894, %r1895, %r1896 }, { %r2111, %r2112, %r2113, %r2114 }, { %r2017, %r2018 }, { %r1893, %r1894, %r1895, %r1896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1907, %r1908, %r1909, %r1910 }, { %r2111, %r2112, %r2113, %r2114 }, { %r2031, %r2032 }, { %r1907, %r1908, %r1909, %r1910 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1921, %r1922, %r1923, %r1924 }, { %r2111, %r2112, %r2113, %r2114 }, { %r2045, %r2046 }, { %r1921, %r1922, %r1923, %r1924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1711, %r1712, %r1713, %r1714 }, { %r2167, %r2168, %r2169, %r2170 }, { %r2227, %r2228 }, { %r1711, %r1712, %r1713, %r1714 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1725, %r1726, %r1727, %r1728 }, { %r2167, %r2168, %r2169, %r2170 }, { %r2241, %r2242 }, { %r1725, %r1726, %r1727, %r1728 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1739, %r1740, %r1741, %r1742 }, { %r2167, %r2168, %r2169, %r2170 }, { %r2255, %r2256 }, { %r1739, %r1740, %r1741, %r1742 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1753, %r1754, %r1755, %r1756 }, { %r2167, %r2168, %r2169, %r2170 }, { %r2269, %r2270 }, { %r1753, %r1754, %r1755, %r1756 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1767, %r1768, %r1769, %r1770 }, { %r2223, %r2224, %r2225, %r2226 }, { %r2227, %r2228 }, { %r1767, %r1768, %r1769, %r1770 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1781, %r1782, %r1783, %r1784 }, { %r2223, %r2224, %r2225, %r2226 }, { %r2241, %r2242 }, { %r1781, %r1782, %r1783, %r1784 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1795, %r1796, %r1797, %r1798 }, { %r2223, %r2224, %r2225, %r2226 }, { %r2255, %r2256 }, { %r1795, %r1796, %r1797, %r1798 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1809, %r1810, %r1811, %r1812 }, { %r2223, %r2224, %r2225, %r2226 }, { %r2269, %r2270 }, { %r1809, %r1810, %r1811, %r1812 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1823, %r1824, %r1825, %r1826 }, { %r2279, %r2280, %r2281, %r2282 }, { %r2227, %r2228 }, { %r1823, %r1824, %r1825, %r1826 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1837, %r1838, %r1839, %r1840 }, { %r2279, %r2280, %r2281, %r2282 }, { %r2241, %r2242 }, { %r1837, %r1838, %r1839, %r1840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1851, %r1852, %r1853, %r1854 }, { %r2279, %r2280, %r2281, %r2282 }, { %r2255, %r2256 }, { %r1851, %r1852, %r1853, %r1854 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1865, %r1866, %r1867, %r1868 }, { %r2279, %r2280, %r2281, %r2282 }, { %r2269, %r2270 }, { %r1865, %r1866, %r1867, %r1868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1879, %r1880, %r1881, %r1882 }, { %r2335, %r2336, %r2337, %r2338 }, { %r2227, %r2228 }, { %r1879, %r1880, %r1881, %r1882 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1893, %r1894, %r1895, %r1896 }, { %r2335, %r2336, %r2337, %r2338 }, { %r2241, %r2242 }, { %r1893, %r1894, %r1895, %r1896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1907, %r1908, %r1909, %r1910 }, { %r2335, %r2336, %r2337, %r2338 }, { %r2255, %r2256 }, { %r1907, %r1908, %r1909, %r1910 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1921, %r1922, %r1923, %r1924 }, { %r2335, %r2336, %r2337, %r2338 }, { %r2269, %r2270 }, { %r1921, %r1922, %r1923, %r1924 };
	// end inline asm
	.loc	1 203 29                        // wy_fast.py:203:29
	cvt.rn.bf16x2.f32 	%r2591, %r1712, %r1711;
	cvt.rn.bf16x2.f32 	%r2592, %r1714, %r1713;
	cvt.rn.bf16x2.f32 	%r2593, %r1726, %r1725;
	cvt.rn.bf16x2.f32 	%r2594, %r1728, %r1727;
	cvt.rn.bf16x2.f32 	%r2595, %r1740, %r1739;
	cvt.rn.bf16x2.f32 	%r2596, %r1742, %r1741;
	cvt.rn.bf16x2.f32 	%r2597, %r1754, %r1753;
	cvt.rn.bf16x2.f32 	%r2598, %r1756, %r1755;
	cvt.rn.bf16x2.f32 	%r2599, %r1768, %r1767;
	cvt.rn.bf16x2.f32 	%r2600, %r1770, %r1769;
	cvt.rn.bf16x2.f32 	%r2601, %r1782, %r1781;
	cvt.rn.bf16x2.f32 	%r2602, %r1784, %r1783;
	cvt.rn.bf16x2.f32 	%r2603, %r1796, %r1795;
	cvt.rn.bf16x2.f32 	%r2604, %r1798, %r1797;
	cvt.rn.bf16x2.f32 	%r2605, %r1810, %r1809;
	cvt.rn.bf16x2.f32 	%r2606, %r1812, %r1811;
	cvt.rn.bf16x2.f32 	%r2607, %r1824, %r1823;
	cvt.rn.bf16x2.f32 	%r2608, %r1826, %r1825;
	cvt.rn.bf16x2.f32 	%r2609, %r1838, %r1837;
	cvt.rn.bf16x2.f32 	%r2610, %r1840, %r1839;
	cvt.rn.bf16x2.f32 	%r2611, %r1852, %r1851;
	cvt.rn.bf16x2.f32 	%r2612, %r1854, %r1853;
	cvt.rn.bf16x2.f32 	%r2613, %r1866, %r1865;
	cvt.rn.bf16x2.f32 	%r2614, %r1868, %r1867;
	cvt.rn.bf16x2.f32 	%r2615, %r1880, %r1879;
	cvt.rn.bf16x2.f32 	%r2616, %r1882, %r1881;
	cvt.rn.bf16x2.f32 	%r2617, %r1894, %r1893;
	cvt.rn.bf16x2.f32 	%r2618, %r1896, %r1895;
	cvt.rn.bf16x2.f32 	%r2619, %r1908, %r1907;
	cvt.rn.bf16x2.f32 	%r2620, %r1910, %r1909;
	cvt.rn.bf16x2.f32 	%r2621, %r1922, %r1921;
	cvt.rn.bf16x2.f32 	%r2622, %r1924, %r1923;
	.loc	1 203 22                        // wy_fast.py:203:22
	shl.b64 	%rd201, %rd228, 1;
	add.s64 	%rd184, %rd40, %rd201;
	shl.b64 	%rd202, %rd229, 1;
	add.s64 	%rd185, %rd40, %rd202;
	shl.b64 	%rd203, %rd230, 1;
	add.s64 	%rd186, %rd40, %rd203;
	shl.b64 	%rd204, %rd231, 1;
	add.s64 	%rd187, %rd40, %rd204;
	shl.b64 	%rd205, %rd232, 1;
	add.s64 	%rd188, %rd40, %rd205;
	shl.b64 	%rd206, %rd233, 1;
	add.s64 	%rd189, %rd40, %rd206;
	shl.b64 	%rd207, %rd234, 1;
	add.s64 	%rd190, %rd40, %rd207;
	shl.b64 	%rd208, %rd235, 1;
	add.s64 	%rd191, %rd40, %rd208;
	st.shared.b32 	[%r44], %r2591;
	st.shared.b32 	[%r45+1024], %r2592;
	st.shared.b32 	[%r44+32], %r2593;
	st.shared.b32 	[%r45+1056], %r2594;
	st.shared.b32 	[%r44+64], %r2595;
	st.shared.b32 	[%r45+1088], %r2596;
	st.shared.b32 	[%r44+96], %r2597;
	st.shared.b32 	[%r45+1120], %r2598;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2383, %r2384, %r2385, %r2386}, [%r49];
	ld.shared.v4.b32 	{%r2387, %r2388, %r2389, %r2390}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r2599;
	st.shared.b32 	[%r45+1024], %r2600;
	st.shared.b32 	[%r44+32], %r2601;
	st.shared.b32 	[%r45+1056], %r2602;
	st.shared.b32 	[%r44+64], %r2603;
	st.shared.b32 	[%r45+1088], %r2604;
	st.shared.b32 	[%r44+96], %r2605;
	st.shared.b32 	[%r45+1120], %r2606;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2391, %r2392, %r2393, %r2394}, [%r49];
	ld.shared.v4.b32 	{%r2395, %r2396, %r2397, %r2398}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r2607;
	st.shared.b32 	[%r45+1024], %r2608;
	st.shared.b32 	[%r44+32], %r2609;
	st.shared.b32 	[%r45+1056], %r2610;
	st.shared.b32 	[%r44+64], %r2611;
	st.shared.b32 	[%r45+1088], %r2612;
	st.shared.b32 	[%r44+96], %r2613;
	st.shared.b32 	[%r45+1120], %r2614;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2399, %r2400, %r2401, %r2402}, [%r49];
	ld.shared.v4.b32 	{%r2403, %r2404, %r2405, %r2406}, [%r50+1024];
	bar.sync 	0;
	st.shared.b32 	[%r44], %r2615;
	st.shared.b32 	[%r45+1024], %r2616;
	st.shared.b32 	[%r44+32], %r2617;
	st.shared.b32 	[%r45+1056], %r2618;
	st.shared.b32 	[%r44+64], %r2619;
	st.shared.b32 	[%r45+1088], %r2620;
	st.shared.b32 	[%r44+96], %r2621;
	st.shared.b32 	[%r45+1120], %r2622;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2407, %r2408, %r2409, %r2410}, [%r49];
	ld.shared.v4.b32 	{%r2411, %r2412, %r2413, %r2414}, [%r50+1024];
	// begin inline asm
	@%p94 st.global.v4.b32 [ %rd184 + 0 ], { %r2383, %r2384, %r2385, %r2386 };
	// end inline asm
	// begin inline asm
	@%p95 st.global.v4.b32 [ %rd185 + 0 ], { %r2387, %r2388, %r2389, %r2390 };
	// end inline asm
	// begin inline asm
	@%p96 st.global.v4.b32 [ %rd186 + 0 ], { %r2391, %r2392, %r2393, %r2394 };
	// end inline asm
	// begin inline asm
	@%p97 st.global.v4.b32 [ %rd187 + 0 ], { %r2395, %r2396, %r2397, %r2398 };
	// end inline asm
	// begin inline asm
	@%p98 st.global.v4.b32 [ %rd188 + 0 ], { %r2399, %r2400, %r2401, %r2402 };
	// end inline asm
	// begin inline asm
	@%p99 st.global.v4.b32 [ %rd189 + 0 ], { %r2403, %r2404, %r2405, %r2406 };
	// end inline asm
	// begin inline asm
	@%p100 st.global.v4.b32 [ %rd190 + 0 ], { %r2407, %r2408, %r2409, %r2410 };
	// end inline asm
	// begin inline asm
	@%p101 st.global.v4.b32 [ %rd191 + 0 ], { %r2411, %r2412, %r2413, %r2414 };
	// end inline asm
	.loc	1 195 22                        // wy_fast.py:195:22
	or.b64 	%rd209, %rd227, %rd1;
	or.b64 	%rd228, %rd209, %rd3;
	or.b64 	%rd229, %rd209, %rd4;
	or.b64 	%rd230, %rd209, %rd5;
	or.b64 	%rd231, %rd209, %rd6;
	or.b64 	%rd232, %rd209, %rd7;
	or.b64 	%rd233, %rd209, %rd8;
	or.b64 	%rd234, %rd209, %rd9;
	or.b64 	%rd235, %rd209, %rd10;
	shl.b64 	%rd210, %rd228, 1;
	add.s64 	%rd192, %rd39, %rd210;
	shl.b64 	%rd211, %rd229, 1;
	add.s64 	%rd193, %rd39, %rd211;
	shl.b64 	%rd212, %rd230, 1;
	add.s64 	%rd194, %rd39, %rd212;
	shl.b64 	%rd213, %rd231, 1;
	add.s64 	%rd195, %rd39, %rd213;
	shl.b64 	%rd214, %rd232, 1;
	add.s64 	%rd196, %rd39, %rd214;
	shl.b64 	%rd215, %rd233, 1;
	add.s64 	%rd197, %rd39, %rd215;
	shl.b64 	%rd216, %rd234, 1;
	add.s64 	%rd198, %rd39, %rd216;
	shl.b64 	%rd217, %rd235, 1;
	add.s64 	%rd199, %rd39, %rd217;
	and.pred 	%p94, %p45, %p27;
	and.pred 	%p95, %p46, %p27;
	and.pred 	%p96, %p47, %p27;
	and.pred 	%p97, %p48, %p27;
	and.pred 	%p98, %p49, %p27;
	and.pred 	%p99, %p50, %p27;
	and.pred 	%p100, %p51, %p27;
	and.pred 	%p101, %p52, %p27;
	selp.b32 	%r2416, 16, 0, %p94;
	// begin inline asm
	cp.async.cg.shared.global [ %r1343 + 0 ], [ %rd192 + 0 ], 0x10, %r2416;
	// end inline asm
	selp.b32 	%r2418, 16, 0, %p95;
	// begin inline asm
	cp.async.cg.shared.global [ %r1345 + 0 ], [ %rd193 + 0 ], 0x10, %r2418;
	// end inline asm
	selp.b32 	%r2420, 16, 0, %p96;
	// begin inline asm
	cp.async.cg.shared.global [ %r1347 + 0 ], [ %rd194 + 0 ], 0x10, %r2420;
	// end inline asm
	selp.b32 	%r2422, 16, 0, %p97;
	// begin inline asm
	cp.async.cg.shared.global [ %r1349 + 0 ], [ %rd195 + 0 ], 0x10, %r2422;
	// end inline asm
	selp.b32 	%r2424, 16, 0, %p98;
	// begin inline asm
	cp.async.cg.shared.global [ %r1351 + 0 ], [ %rd196 + 0 ], 0x10, %r2424;
	// end inline asm
	selp.b32 	%r2426, 16, 0, %p99;
	// begin inline asm
	cp.async.cg.shared.global [ %r1353 + 0 ], [ %rd197 + 0 ], 0x10, %r2426;
	// end inline asm
	selp.b32 	%r2428, 16, 0, %p100;
	// begin inline asm
	cp.async.cg.shared.global [ %r1355 + 0 ], [ %rd198 + 0 ], 0x10, %r2428;
	// end inline asm
	selp.b32 	%r2430, 16, 0, %p101;
	// begin inline asm
	cp.async.cg.shared.global [ %r1357 + 0 ], [ %rd199 + 0 ], 0x10, %r2430;
	// end inline asm
	cp.async.commit_group;
	mov.b64 	%rd227, 128;
	mov.pred 	%p93, 0;
	.loc	1 192 21                        // wy_fast.py:192:21
	@%p27 bra 	$L__BB0_3;
// %bb.4:
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 192 4                         // wy_fast.py:192:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.13/site-packages/fla/ops/gated_delta_rule/wy_fast.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 124                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x75 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 119                                 // DW_AT_name
.b8 121
.b8 95
.b8 102
.b8 97
.b8 115
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 51
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 102
.b8 108
.b8 97
.b8 47
.b8 111
.b8 112
.b8 115
.b8 47
.b8 103
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 100
.b8 101
.b8 108
.b8 116
.b8 97
.b8 95
.b8 114
.b8 117
.b8 108
.b8 101
.b8 0
	}
	.section	.debug_macinfo	{	}
