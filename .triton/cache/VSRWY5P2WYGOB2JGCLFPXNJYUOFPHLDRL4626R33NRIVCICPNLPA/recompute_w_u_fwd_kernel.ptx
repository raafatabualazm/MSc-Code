//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	recompute_w_u_fwd_kernel // -- Begin function recompute_w_u_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @recompute_w_u_fwd_kernel
.visible .entry recompute_w_u_fwd_kernel(
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_0,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_1,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_2,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_3,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_4,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_5,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_6,
	.param .u32 recompute_w_u_fwd_kernel_param_7,
	.param .u64 .ptr .global .align 1 recompute_w_u_fwd_kernel_param_8
)
.reqntid 64
{
	.reg .pred 	%p<122>;
	.reg .b16 	%rs<66>;
	.reg .b32 	%r<2693>;
	.reg .b64 	%rd<317>;
	.loc	1 144 0                         // wy_fast.py:144:0
$L__func_begin0:
	.loc	1 144 0                         // wy_fast.py:144:0

// %bb.0:
	ld.param.b64 	%rd92, [recompute_w_u_fwd_kernel_param_6];
	ld.param.b64 	%rd91, [recompute_w_u_fwd_kernel_param_3];
	ld.param.b64 	%rd90, [recompute_w_u_fwd_kernel_param_0];
	ld.param.b64 	%rd119, [recompute_w_u_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 166 30                        // wy_fast.py:166:30
	mov.u32 	%r173, %ctaid.x;
	ld.param.b64 	%rd120, [recompute_w_u_fwd_kernel_param_2];
	.loc	1 166 48                        // wy_fast.py:166:48
	mov.u32 	%r174, %ctaid.y;
	.loc	1 173 25                        // wy_fast.py:173:25
	and.b32 	%r175, %r174, 65504;
	.loc	1 167 33                        // wy_fast.py:167:33
	and.b32 	%r176, %r174, 31;
	ld.param.b64 	%rd121, [recompute_w_u_fwd_kernel_param_4];
	ld.param.b32 	%r177, [recompute_w_u_fwd_kernel_param_7];
	.loc	1 174 42                        // wy_fast.py:174:42
	mul.lo.s32 	%r178, %r175, %r177;
	ld.param.b64 	%rd122, [recompute_w_u_fwd_kernel_param_5];
	.loc	1 174 38                        // wy_fast.py:174:38
	mul.wide.s32 	%rd123, %r178, 2;
	add.s64 	%rd124, %rd120, %rd123;
	.loc	1 174 46                        // wy_fast.py:174:46
	mul.wide.u32 	%rd125, %r176, 2;
	add.s64 	%rd126, %rd124, %rd125;
	.loc	1 174 70                        // wy_fast.py:174:70
	shl.b32 	%r179, %r173, 6;
	.loc	1 174 83                        // wy_fast.py:174:83
	cvt.s64.s32 	%rd127, %r177;
	cvt.s64.s32 	%rd128, %r179;
	.loc	1 175 21                        // wy_fast.py:175:21
	mov.u32 	%r180, %tid.x;
	bfe.u32 	%r181, %r180, 3, 3;
	or.b32 	%r182, %r181, 8;
	or.b32 	%r183, %r181, 16;
	or.b32 	%r184, %r181, 24;
	or.b32 	%r185, %r181, 32;
	or.b32 	%r186, %r181, 40;
	or.b32 	%r187, %r181, 48;
	or.b32 	%r188, %r181, 56;
	bfe.s32 	%r189, %r180, 2, 1;
	shl.b32 	%r190, %r180, 3;
	and.b32 	%r191, %r190, 56;
	and.b32 	%r1, %r180, 63;
	cvt.u64.u32 	%rd129, %r181;
	cvt.u64.u32 	%rd130, %r182;
	cvt.u64.u32 	%rd131, %r183;
	cvt.u64.u32 	%rd132, %r184;
	cvt.u64.u32 	%rd133, %r185;
	cvt.u64.u32 	%rd134, %r186;
	cvt.u64.u32 	%rd135, %r187;
	cvt.u64.u32 	%rd136, %r188;
	cvt.u64.u32 	%rd1, %r191;
	cvt.u64.u32 	%rd137, %r1;
	or.b64 	%rd138, %rd129, %rd128;
	or.b64 	%rd139, %rd130, %rd128;
	or.b64 	%rd140, %rd131, %rd128;
	or.b64 	%rd141, %rd132, %rd128;
	or.b64 	%rd142, %rd133, %rd128;
	or.b64 	%rd143, %rd134, %rd128;
	or.b64 	%rd144, %rd135, %rd128;
	or.b64 	%rd145, %rd136, %rd128;
	or.b64 	%rd146, %rd128, %rd137;
	shl.b64 	%rd2, %rd146, 5;
	shl.b64 	%rd147, %rd146, 6;
	add.s64 	%rd93, %rd126, %rd147;
	setp.gt.s32 	%p54, %r179, -1;
	setp.lt.s64 	%p55, %rd146, %rd127;
	and.pred 	%p75, %p54, %p55;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p75 ld.global.b16 { %rs1 }, [ %rd93 + 0 ];
	// end inline asm
	.loc	1 196 21                        // wy_fast.py:196:21
	shl.b32 	%r192, %r180, 1;
	and.b32 	%r2, %r192, 6;
	shl.b32 	%r193, %r1, 1;
	mov.b32 	%r194, global_smem;
	add.s32 	%r195, %r194, %r193;
	st.shared.b16 	[%r195], %rs1;
	bar.sync 	0;
	shl.b32 	%r196, %r2, 1;
	add.s32 	%r197, %r194, %r196;
	ld.shared.b32 	%r3, [%r197];
	ld.shared.b32 	%r4, [%r197+16];
	ld.shared.b32 	%r5, [%r197+32];
	ld.shared.b32 	%r6, [%r197+48];
	ld.shared.b32 	%r7, [%r197+64];
	ld.shared.b32 	%r8, [%r197+80];
	ld.shared.b32 	%r9, [%r197+96];
	ld.shared.b32 	%r10, [%r197+112];
	.loc	1 177 41                        // wy_fast.py:177:41
	or.b32 	%r11, %r178, %r176;
	.loc	1 177 48                        // wy_fast.py:177:48
	shl.b32 	%r198, %r11, 6;
	.loc	1 177 32                        // wy_fast.py:177:32
	mul.wide.s32 	%rd148, %r198, 2;
	add.s64 	%rd149, %rd122, %rd148;
	.loc	1 178 18                        // wy_fast.py:178:18
	shl.b64 	%rd3, %rd138, 12;
	add.s64 	%rd150, %rd149, %rd3;
	mul.wide.u32 	%rd151, %r191, 2;
	add.s64 	%rd94, %rd150, %rd151;
	shl.b64 	%rd4, %rd139, 12;
	add.s64 	%rd152, %rd149, %rd4;
	add.s64 	%rd95, %rd152, %rd151;
	shl.b64 	%rd5, %rd140, 12;
	add.s64 	%rd153, %rd149, %rd5;
	add.s64 	%rd96, %rd153, %rd151;
	shl.b64 	%rd6, %rd141, 12;
	add.s64 	%rd154, %rd149, %rd6;
	add.s64 	%rd97, %rd154, %rd151;
	shl.b64 	%rd7, %rd142, 12;
	add.s64 	%rd155, %rd149, %rd7;
	add.s64 	%rd98, %rd155, %rd151;
	shl.b64 	%rd8, %rd143, 12;
	add.s64 	%rd156, %rd149, %rd8;
	add.s64 	%rd99, %rd156, %rd151;
	shl.b64 	%rd9, %rd144, 12;
	add.s64 	%rd157, %rd149, %rd9;
	add.s64 	%rd100, %rd157, %rd151;
	shl.b64 	%rd10, %rd145, 12;
	add.s64 	%rd158, %rd149, %rd10;
	add.s64 	%rd101, %rd158, %rd151;
	setp.lt.s64 	%p56, %rd138, %rd127;
	setp.lt.s64 	%p57, %rd139, %rd127;
	setp.lt.s64 	%p58, %rd140, %rd127;
	setp.lt.s64 	%p59, %rd141, %rd127;
	setp.lt.s64 	%p60, %rd142, %rd127;
	setp.lt.s64 	%p61, %rd143, %rd127;
	setp.lt.s64 	%p62, %rd144, %rd127;
	setp.lt.s64 	%p63, %rd145, %rd127;
	and.pred 	%p106, %p54, %p56;
	and.pred 	%p107, %p54, %p57;
	and.pred 	%p108, %p54, %p58;
	and.pred 	%p109, %p54, %p59;
	and.pred 	%p110, %p54, %p60;
	and.pred 	%p111, %p54, %p61;
	and.pred 	%p112, %p54, %p62;
	and.pred 	%p113, %p54, %p63;
	// begin inline asm
	mov.u32 %r107, 0x0;
	mov.u32 %r108, 0x0;
	mov.u32 %r109, 0x0;
	mov.u32 %r110, 0x0;
	@%p106 ld.global.v4.b32 { %r107, %r108, %r109, %r110 }, [ %rd94 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r111, 0x0;
	mov.u32 %r112, 0x0;
	mov.u32 %r113, 0x0;
	mov.u32 %r114, 0x0;
	@%p107 ld.global.v4.b32 { %r111, %r112, %r113, %r114 }, [ %rd95 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r115, 0x0;
	mov.u32 %r116, 0x0;
	mov.u32 %r117, 0x0;
	mov.u32 %r118, 0x0;
	@%p108 ld.global.v4.b32 { %r115, %r116, %r117, %r118 }, [ %rd96 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r119, 0x0;
	mov.u32 %r120, 0x0;
	mov.u32 %r121, 0x0;
	mov.u32 %r122, 0x0;
	@%p109 ld.global.v4.b32 { %r119, %r120, %r121, %r122 }, [ %rd97 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r123, 0x0;
	mov.u32 %r124, 0x0;
	mov.u32 %r125, 0x0;
	mov.u32 %r126, 0x0;
	@%p110 ld.global.v4.b32 { %r123, %r124, %r125, %r126 }, [ %rd98 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r127, 0x0;
	mov.u32 %r128, 0x0;
	mov.u32 %r129, 0x0;
	mov.u32 %r130, 0x0;
	@%p111 ld.global.v4.b32 { %r127, %r128, %r129, %r130 }, [ %rd99 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r131, 0x0;
	mov.u32 %r132, 0x0;
	mov.u32 %r133, 0x0;
	mov.u32 %r134, 0x0;
	@%p112 ld.global.v4.b32 { %r131, %r132, %r133, %r134 }, [ %rd100 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r135, 0x0;
	mov.u32 %r136, 0x0;
	mov.u32 %r137, 0x0;
	mov.u32 %r138, 0x0;
	@%p113 ld.global.v4.b32 { %r135, %r136, %r137, %r138 }, [ %rd101 + 0 ];
	// end inline asm
	xor.b32 	%r199, %r190, %r180;
	and.b32 	%r200, %r199, 56;
	shl.b32 	%r201, %r181, 6;
	or.b32 	%r12, %r200, %r201;
	shl.b32 	%r202, %r12, 1;
	add.s32 	%r203, %r194, 18688;
	add.s32 	%r204, %r203, %r202;
	st.shared.v4.b32 	[%r204], {%r107, %r108, %r109, %r110};
	st.shared.v4.b32 	[%r204+1024], {%r111, %r112, %r113, %r114};
	st.shared.v4.b32 	[%r204+2048], {%r115, %r116, %r117, %r118};
	st.shared.v4.b32 	[%r204+3072], {%r119, %r120, %r121, %r122};
	st.shared.v4.b32 	[%r204+4096], {%r123, %r124, %r125, %r126};
	st.shared.v4.b32 	[%r204+5120], {%r127, %r128, %r129, %r130};
	st.shared.v4.b32 	[%r204+6144], {%r131, %r132, %r133, %r134};
	st.shared.v4.b32 	[%r204+7168], {%r135, %r136, %r137, %r138};
	.loc	1 181 52                        // wy_fast.py:181:52
	shl.b32 	%r205, %r11, 7;
	.loc	1 181 36                        // wy_fast.py:181:36
	cvt.s64.s32 	%rd11, %r205;
	mul.wide.s32 	%rd159, %r205, 2;
	add.s64 	%rd12, %rd119, %rd159;
	.loc	1 182 36                        // wy_fast.py:182:36
	add.s64 	%rd13, %rd121, %rd159;
	.loc	1 183 22                        // wy_fast.py:183:22
	or.b64 	%rd309, %rd3, %rd1;
	or.b64 	%rd310, %rd4, %rd1;
	or.b64 	%rd311, %rd5, %rd1;
	or.b64 	%rd312, %rd6, %rd1;
	or.b64 	%rd313, %rd7, %rd1;
	or.b64 	%rd314, %rd8, %rd1;
	or.b64 	%rd315, %rd9, %rd1;
	or.b64 	%rd316, %rd10, %rd1;
	shl.b64 	%rd160, %rd309, 1;
	add.s64 	%rd102, %rd12, %rd160;
	shl.b64 	%rd161, %rd310, 1;
	add.s64 	%rd103, %rd12, %rd161;
	shl.b64 	%rd162, %rd311, 1;
	add.s64 	%rd104, %rd12, %rd162;
	shl.b64 	%rd163, %rd312, 1;
	add.s64 	%rd105, %rd12, %rd163;
	shl.b64 	%rd164, %rd313, 1;
	add.s64 	%rd106, %rd12, %rd164;
	shl.b64 	%rd165, %rd314, 1;
	add.s64 	%rd107, %rd12, %rd165;
	shl.b64 	%rd166, %rd315, 1;
	add.s64 	%rd108, %rd12, %rd166;
	shl.b64 	%rd167, %rd316, 1;
	add.s64 	%rd109, %rd12, %rd167;
	bar.sync 	0;
	add.s32 	%r1377, %r194, %r202;
	add.s32 	%r1379, %r1377, 1024;
	add.s32 	%r1381, %r1377, 2048;
	add.s32 	%r1383, %r1377, 3072;
	add.s32 	%r1385, %r1377, 4096;
	add.s32 	%r1387, %r1377, 5120;
	add.s32 	%r1389, %r1377, 6144;
	add.s32 	%r1391, %r1377, 7168;
	selp.b32 	%r21, 16, 0, %p106;
	// begin inline asm
	cp.async.cg.shared.global [ %r1377 + 0 ], [ %rd102 + 0 ], 0x10, %r21;
	// end inline asm
	selp.b32 	%r22, 16, 0, %p107;
	// begin inline asm
	cp.async.cg.shared.global [ %r1379 + 0 ], [ %rd103 + 0 ], 0x10, %r22;
	// end inline asm
	selp.b32 	%r23, 16, 0, %p108;
	// begin inline asm
	cp.async.cg.shared.global [ %r1381 + 0 ], [ %rd104 + 0 ], 0x10, %r23;
	// end inline asm
	selp.b32 	%r24, 16, 0, %p109;
	// begin inline asm
	cp.async.cg.shared.global [ %r1383 + 0 ], [ %rd105 + 0 ], 0x10, %r24;
	// end inline asm
	selp.b32 	%r25, 16, 0, %p110;
	// begin inline asm
	cp.async.cg.shared.global [ %r1385 + 0 ], [ %rd106 + 0 ], 0x10, %r25;
	// end inline asm
	selp.b32 	%r26, 16, 0, %p111;
	// begin inline asm
	cp.async.cg.shared.global [ %r1387 + 0 ], [ %rd107 + 0 ], 0x10, %r26;
	// end inline asm
	selp.b32 	%r27, 16, 0, %p112;
	// begin inline asm
	cp.async.cg.shared.global [ %r1389 + 0 ], [ %rd108 + 0 ], 0x10, %r27;
	// end inline asm
	selp.b32 	%r28, 16, 0, %p113;
	// begin inline asm
	cp.async.cg.shared.global [ %r1391 + 0 ], [ %rd109 + 0 ], 0x10, %r28;
	// end inline asm
	cp.async.commit_group;
	or.b64 	%rd168, %rd1, 64;
	or.b64 	%rd301, %rd3, %rd168;
	or.b64 	%rd302, %rd4, %rd168;
	or.b64 	%rd303, %rd5, %rd168;
	or.b64 	%rd304, %rd6, %rd168;
	or.b64 	%rd305, %rd7, %rd168;
	or.b64 	%rd306, %rd8, %rd168;
	or.b64 	%rd307, %rd9, %rd168;
	or.b64 	%rd308, %rd10, %rd168;
	add.s64 	%rd110, %rd102, 128;
	add.s64 	%rd111, %rd103, 128;
	add.s64 	%rd112, %rd104, 128;
	add.s64 	%rd113, %rd105, 128;
	add.s64 	%rd114, %rd106, 128;
	add.s64 	%rd115, %rd107, 128;
	add.s64 	%rd116, %rd108, 128;
	add.s64 	%rd117, %rd109, 128;
	bar.sync 	0;
	add.s32 	%r155, %r1377, 8192;
	add.s32 	%r157, %r1377, 9216;
	add.s32 	%r159, %r1377, 10240;
	add.s32 	%r161, %r1377, 11264;
	add.s32 	%r163, %r1377, 12288;
	add.s32 	%r165, %r1377, 13312;
	add.s32 	%r167, %r1377, 14336;
	add.s32 	%r169, %r1377, 15360;
	// begin inline asm
	cp.async.cg.shared.global [ %r155 + 0 ], [ %rd110 + 0 ], 0x10, %r21;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r157 + 0 ], [ %rd111 + 0 ], 0x10, %r22;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r159 + 0 ], [ %rd112 + 0 ], 0x10, %r23;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r161 + 0 ], [ %rd113 + 0 ], 0x10, %r24;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r163 + 0 ], [ %rd114 + 0 ], 0x10, %r25;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r165 + 0 ], [ %rd115 + 0 ], 0x10, %r26;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r167 + 0 ], [ %rd116 + 0 ], 0x10, %r27;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r169 + 0 ], [ %rd117 + 0 ], 0x10, %r28;
	// end inline asm
	cp.async.commit_group;
	and.b32 	%r206, %r180, 3;
	mul.lo.s32 	%r207, %r206, 72;
	and.b32 	%r208, %r189, 288;
	xor.b32 	%r209, %r208, %r207;
	shl.b32 	%r210, %r180, 6;
	and.b32 	%r211, %r210, 512;
	or.b32 	%r212, %r209, %r211;
	and.b32 	%r213, %r210, 1536;
	or.b32 	%r214, %r209, %r213;
	shr.u32 	%r215, %r180, 2;
	and.b32 	%r216, %r215, 8;
	xor.b32 	%r37, %r214, %r216;
	xor.b32 	%r38, %r37, 16;
	xor.b32 	%r39, %r37, 2064;
	xor.b32 	%r40, %r37, 32;
	xor.b32 	%r41, %r37, 2080;
	xor.b32 	%r42, %r37, 48;
	xor.b32 	%r43, %r37, 2096;
	shr.u32 	%r217, %r180, 1;
	and.b32 	%r218, %r217, 8;
	xor.b32 	%r219, %r212, %r218;
	shl.b32 	%r220, %r219, 1;
	add.s32 	%r309, %r203, %r220;
	xor.b32 	%r221, %r219, 16;
	shl.b32 	%r222, %r221, 1;
	add.s32 	%r314, %r203, %r222;
	xor.b32 	%r223, %r219, 32;
	shl.b32 	%r224, %r223, 1;
	add.s32 	%r319, %r203, %r224;
	xor.b32 	%r225, %r219, 48;
	shl.b32 	%r226, %r225, 1;
	add.s32 	%r324, %r203, %r226;
	add.s32 	%r329, %r309, 2048;
	xor.b32 	%r227, %r219, 1040;
	shl.b32 	%r228, %r227, 1;
	add.s32 	%r334, %r203, %r228;
	xor.b32 	%r229, %r219, 1056;
	shl.b32 	%r230, %r229, 1;
	add.s32 	%r339, %r203, %r230;
	xor.b32 	%r231, %r219, 1072;
	shl.b32 	%r232, %r231, 1;
	add.s32 	%r344, %r203, %r232;
	add.s32 	%r349, %r309, 4096;
	xor.b32 	%r233, %r219, 2064;
	shl.b32 	%r234, %r233, 1;
	add.s32 	%r354, %r203, %r234;
	xor.b32 	%r235, %r219, 2080;
	shl.b32 	%r236, %r235, 1;
	add.s32 	%r359, %r203, %r236;
	xor.b32 	%r237, %r219, 2096;
	shl.b32 	%r238, %r237, 1;
	add.s32 	%r364, %r203, %r238;
	add.s32 	%r369, %r309, 6144;
	xor.b32 	%r239, %r219, 3088;
	shl.b32 	%r240, %r239, 1;
	add.s32 	%r374, %r203, %r240;
	xor.b32 	%r241, %r219, 3104;
	shl.b32 	%r242, %r241, 1;
	add.s32 	%r379, %r203, %r242;
	xor.b32 	%r243, %r219, 3120;
	shl.b32 	%r244, %r243, 1;
	add.s32 	%r384, %r203, %r244;
	shl.b32 	%r245, %r180, 4;
	and.b32 	%r246, %r245, 448;
	or.b32 	%r247, %r246, %r2;
	or.b32 	%r248, %r247, %r216;
	and.b32 	%r249, %r190, 504;
	shr.u32 	%r250, %r246, 2;
	add.s32 	%r251, %r194, 16384;
	add.s32 	%r252, %r251, %r250;
	shl.b32 	%r253, %r248, 1;
	add.s32 	%r60, %r252, %r253;
	or.b32 	%r254, %r246, 512;
	shr.u32 	%r255, %r254, 2;
	add.s32 	%r256, %r251, %r255;
	add.s32 	%r61, %r256, %r253;
	and.b32 	%r257, %r180, 56;
	shl.b32 	%r258, %r257, 1;
	add.s32 	%r259, %r251, %r258;
	shl.b32 	%r260, %r249, 1;
	add.s32 	%r65, %r259, %r260;
	or.b32 	%r261, %r249, 512;
	shr.u32 	%r262, %r261, 2;
	and.b32 	%r263, %r262, 240;
	add.s32 	%r264, %r251, %r263;
	add.s32 	%r66, %r264, %r260;
	mov.b32 	%r2690, 1;
	mov.b32 	%r2689, -1;
	mov.b64 	%rd283, 128;
	mov.pred 	%p88, -1;
	mov.pred 	%p89, %p106;
	mov.pred 	%p90, %p107;
	mov.pred 	%p91, %p108;
	mov.pred 	%p92, %p109;
	mov.pred 	%p93, %p110;
	mov.pred 	%p94, %p111;
	mov.pred 	%p95, %p112;
	mov.pred 	%p96, %p113;
	mov.pred 	%p97, %p106;
	mov.pred 	%p98, %p107;
	mov.pred 	%p99, %p108;
	mov.pred 	%p100, %p109;
	mov.pred 	%p101, %p110;
	mov.pred 	%p102, %p111;
	mov.pred 	%p103, %p112;
	mov.pred 	%p104, %p113;
	mov.b64 	%rd284, %rd301;
	mov.b64 	%rd285, %rd302;
	mov.b64 	%rd286, %rd303;
	mov.b64 	%rd287, %rd304;
	mov.b64 	%rd288, %rd305;
	mov.b64 	%rd289, %rd306;
	mov.b64 	%rd290, %rd307;
	mov.b64 	%rd291, %rd308;
	mov.b64 	%rd292, %rd309;
	mov.b64 	%rd293, %rd310;
	mov.b64 	%rd294, %rd311;
	mov.b64 	%rd295, %rd312;
	mov.b64 	%rd296, %rd313;
	mov.b64 	%rd297, %rd314;
	mov.b64 	%rd298, %rd315;
	mov.b64 	%rd299, %rd316;
$L__BB0_1:                              // =>This Inner Loop Header: Depth=1
	.loc	1 0 22                          // wy_fast.py:0:22
	mov.b64 	%rd46, %rd291;
	mov.b64 	%rd45, %rd290;
	mov.b64 	%rd44, %rd289;
	mov.b64 	%rd43, %rd288;
	mov.b64 	%rd42, %rd287;
	mov.b64 	%rd41, %rd286;
	mov.b64 	%rd40, %rd285;
	mov.b64 	%rd39, %rd284;
	mov.pred 	%p18, %p96;
	mov.pred 	%p17, %p95;
	mov.pred 	%p16, %p94;
	mov.pred 	%p15, %p93;
	mov.pred 	%p14, %p92;
	mov.pred 	%p13, %p91;
	mov.pred 	%p12, %p90;
	mov.pred 	%p11, %p89;
	mov.pred 	%p10, %p88;
	.loc	1 180 21                        // wy_fast.py:180:21
	add.s32 	%r1329, %r2689, 1;
	setp.gt.s32 	%p73, %r1329, 1;
	selp.b32 	%r2689, 0, %r1329, %p73;
	.loc	1 183 22                        // wy_fast.py:183:22
	cp.async.wait_group 	1;
	bar.sync 	0;
	shl.b32 	%r1330, %r2689, 13;
	add.s32 	%r1332, %r194, %r1330;
	.loc	1 184 22                        // wy_fast.py:184:22
	shl.b32 	%r1333, %r37, 1;
	add.s32 	%r269, %r1332, %r1333;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r265, %r266, %r267, %r268}, [%r269];
	// end inline asm
	add.s32 	%r274, %r269, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r270, %r271, %r272, %r273}, [%r274];
	// end inline asm
	shl.b32 	%r1334, %r38, 1;
	add.s32 	%r279, %r1332, %r1334;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r275, %r276, %r277, %r278}, [%r279];
	// end inline asm
	shl.b32 	%r1335, %r39, 1;
	add.s32 	%r284, %r1332, %r1335;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r280, %r281, %r282, %r283}, [%r284];
	// end inline asm
	shl.b32 	%r1336, %r40, 1;
	add.s32 	%r289, %r1332, %r1336;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r285, %r286, %r287, %r288}, [%r289];
	// end inline asm
	shl.b32 	%r1337, %r41, 1;
	add.s32 	%r294, %r1332, %r1337;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r290, %r291, %r292, %r293}, [%r294];
	// end inline asm
	shl.b32 	%r1338, %r42, 1;
	add.s32 	%r299, %r1332, %r1338;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r295, %r296, %r297, %r298}, [%r299];
	// end inline asm
	shl.b32 	%r1339, %r43, 1;
	add.s32 	%r304, %r1332, %r1339;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r300, %r301, %r302, %r303}, [%r304];
	// end inline asm
	.loc	1 178 18                        // wy_fast.py:178:18
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r393, %r394, %r395, %r396}, [%r309];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r617, %r618, %r619, %r620}, [%r314];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r841, %r842, %r843, %r844}, [%r319];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1065, %r1066, %r1067, %r1068}, [%r324];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r449, %r450, %r451, %r452}, [%r329];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r673, %r674, %r675, %r676}, [%r334];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r897, %r898, %r899, %r900}, [%r339];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1121, %r1122, %r1123, %r1124}, [%r344];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r505, %r506, %r507, %r508}, [%r349];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r729, %r730, %r731, %r732}, [%r354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r953, %r954, %r955, %r956}, [%r359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1177, %r1178, %r1179, %r1180}, [%r364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r561, %r562, %r563, %r564}, [%r369];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r785, %r786, %r787, %r788}, [%r374];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1009, %r1010, %r1011, %r1012}, [%r379];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1233, %r1234, %r1235, %r1236}, [%r384];
	// end inline asm
	.loc	1 185 26                        // wy_fast.py:185:26
	mul.bf16x2 	%r453, %r3, %r265;
	mul.bf16x2 	%r454, %r4, %r266;
	mul.bf16x2 	%r677, %r5, %r267;
	mul.bf16x2 	%r678, %r6, %r268;
	mul.bf16x2 	%r901, %r7, %r270;
	mul.bf16x2 	%r902, %r8, %r271;
	mul.bf16x2 	%r1125, %r9, %r272;
	mul.bf16x2 	%r1126, %r10, %r273;
	mul.bf16x2 	%r467, %r3, %r275;
	mul.bf16x2 	%r468, %r4, %r276;
	mul.bf16x2 	%r691, %r5, %r277;
	mul.bf16x2 	%r692, %r6, %r278;
	mul.bf16x2 	%r915, %r7, %r280;
	mul.bf16x2 	%r916, %r8, %r281;
	mul.bf16x2 	%r1139, %r9, %r282;
	mul.bf16x2 	%r1140, %r10, %r283;
	mul.bf16x2 	%r481, %r3, %r285;
	mul.bf16x2 	%r482, %r4, %r286;
	mul.bf16x2 	%r705, %r5, %r287;
	mul.bf16x2 	%r706, %r6, %r288;
	mul.bf16x2 	%r929, %r7, %r290;
	mul.bf16x2 	%r930, %r8, %r291;
	mul.bf16x2 	%r1153, %r9, %r292;
	mul.bf16x2 	%r1154, %r10, %r293;
	mul.bf16x2 	%r495, %r3, %r295;
	mul.bf16x2 	%r496, %r4, %r296;
	mul.bf16x2 	%r719, %r5, %r297;
	mul.bf16x2 	%r720, %r6, %r298;
	mul.bf16x2 	%r943, %r7, %r300;
	mul.bf16x2 	%r944, %r8, %r301;
	mul.bf16x2 	%r1167, %r9, %r302;
	mul.bf16x2 	%r1168, %r10, %r303;
	mov.b32 	%r389, 0;
	mov.b32 	%r609, %r389;
	mov.b32 	%r610, %r389;
	mov.b32 	%r611, %r389;
	mov.b32 	%r612, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r609, %r610, %r611, %r612 }, { %r393, %r394, %r395, %r396 }, { %r453, %r454 }, { %r609, %r610, %r611, %r612 };
	// end inline asm
	mov.b32 	%r623, %r389;
	mov.b32 	%r624, %r389;
	mov.b32 	%r625, %r389;
	mov.b32 	%r626, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r623, %r624, %r625, %r626 }, { %r393, %r394, %r395, %r396 }, { %r467, %r468 }, { %r623, %r624, %r625, %r626 };
	// end inline asm
	mov.b32 	%r637, %r389;
	mov.b32 	%r638, %r389;
	mov.b32 	%r639, %r389;
	mov.b32 	%r640, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r637, %r638, %r639, %r640 }, { %r393, %r394, %r395, %r396 }, { %r481, %r482 }, { %r637, %r638, %r639, %r640 };
	// end inline asm
	mov.b32 	%r651, %r389;
	mov.b32 	%r652, %r389;
	mov.b32 	%r653, %r389;
	mov.b32 	%r654, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r651, %r652, %r653, %r654 }, { %r393, %r394, %r395, %r396 }, { %r495, %r496 }, { %r651, %r652, %r653, %r654 };
	// end inline asm
	mov.b32 	%r665, %r389;
	mov.b32 	%r666, %r389;
	mov.b32 	%r667, %r389;
	mov.b32 	%r668, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r665, %r666, %r667, %r668 }, { %r449, %r450, %r451, %r452 }, { %r453, %r454 }, { %r665, %r666, %r667, %r668 };
	// end inline asm
	mov.b32 	%r679, %r389;
	mov.b32 	%r680, %r389;
	mov.b32 	%r681, %r389;
	mov.b32 	%r682, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r679, %r680, %r681, %r682 }, { %r449, %r450, %r451, %r452 }, { %r467, %r468 }, { %r679, %r680, %r681, %r682 };
	// end inline asm
	mov.b32 	%r693, %r389;
	mov.b32 	%r694, %r389;
	mov.b32 	%r695, %r389;
	mov.b32 	%r696, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r693, %r694, %r695, %r696 }, { %r449, %r450, %r451, %r452 }, { %r481, %r482 }, { %r693, %r694, %r695, %r696 };
	// end inline asm
	mov.b32 	%r707, %r389;
	mov.b32 	%r708, %r389;
	mov.b32 	%r709, %r389;
	mov.b32 	%r710, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r707, %r708, %r709, %r710 }, { %r449, %r450, %r451, %r452 }, { %r495, %r496 }, { %r707, %r708, %r709, %r710 };
	// end inline asm
	mov.b32 	%r721, %r389;
	mov.b32 	%r722, %r389;
	mov.b32 	%r723, %r389;
	mov.b32 	%r724, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r721, %r722, %r723, %r724 }, { %r505, %r506, %r507, %r508 }, { %r453, %r454 }, { %r721, %r722, %r723, %r724 };
	// end inline asm
	mov.b32 	%r735, %r389;
	mov.b32 	%r736, %r389;
	mov.b32 	%r737, %r389;
	mov.b32 	%r738, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r735, %r736, %r737, %r738 }, { %r505, %r506, %r507, %r508 }, { %r467, %r468 }, { %r735, %r736, %r737, %r738 };
	// end inline asm
	mov.b32 	%r749, %r389;
	mov.b32 	%r750, %r389;
	mov.b32 	%r751, %r389;
	mov.b32 	%r752, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r749, %r750, %r751, %r752 }, { %r505, %r506, %r507, %r508 }, { %r481, %r482 }, { %r749, %r750, %r751, %r752 };
	// end inline asm
	mov.b32 	%r763, %r389;
	mov.b32 	%r764, %r389;
	mov.b32 	%r765, %r389;
	mov.b32 	%r766, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r763, %r764, %r765, %r766 }, { %r505, %r506, %r507, %r508 }, { %r495, %r496 }, { %r763, %r764, %r765, %r766 };
	// end inline asm
	mov.b32 	%r777, %r389;
	mov.b32 	%r778, %r389;
	mov.b32 	%r779, %r389;
	mov.b32 	%r780, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r777, %r778, %r779, %r780 }, { %r561, %r562, %r563, %r564 }, { %r453, %r454 }, { %r777, %r778, %r779, %r780 };
	// end inline asm
	mov.b32 	%r791, %r389;
	mov.b32 	%r792, %r389;
	mov.b32 	%r793, %r389;
	mov.b32 	%r794, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r791, %r792, %r793, %r794 }, { %r561, %r562, %r563, %r564 }, { %r467, %r468 }, { %r791, %r792, %r793, %r794 };
	// end inline asm
	mov.b32 	%r805, %r389;
	mov.b32 	%r806, %r389;
	mov.b32 	%r807, %r389;
	mov.b32 	%r808, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r805, %r806, %r807, %r808 }, { %r561, %r562, %r563, %r564 }, { %r481, %r482 }, { %r805, %r806, %r807, %r808 };
	// end inline asm
	mov.b32 	%r819, %r389;
	mov.b32 	%r820, %r389;
	mov.b32 	%r821, %r389;
	mov.b32 	%r822, %r389;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r819, %r820, %r821, %r822 }, { %r561, %r562, %r563, %r564 }, { %r495, %r496 }, { %r819, %r820, %r821, %r822 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r609, %r610, %r611, %r612 }, { %r617, %r618, %r619, %r620 }, { %r677, %r678 }, { %r609, %r610, %r611, %r612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r623, %r624, %r625, %r626 }, { %r617, %r618, %r619, %r620 }, { %r691, %r692 }, { %r623, %r624, %r625, %r626 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r637, %r638, %r639, %r640 }, { %r617, %r618, %r619, %r620 }, { %r705, %r706 }, { %r637, %r638, %r639, %r640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r651, %r652, %r653, %r654 }, { %r617, %r618, %r619, %r620 }, { %r719, %r720 }, { %r651, %r652, %r653, %r654 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r665, %r666, %r667, %r668 }, { %r673, %r674, %r675, %r676 }, { %r677, %r678 }, { %r665, %r666, %r667, %r668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r679, %r680, %r681, %r682 }, { %r673, %r674, %r675, %r676 }, { %r691, %r692 }, { %r679, %r680, %r681, %r682 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r693, %r694, %r695, %r696 }, { %r673, %r674, %r675, %r676 }, { %r705, %r706 }, { %r693, %r694, %r695, %r696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r707, %r708, %r709, %r710 }, { %r673, %r674, %r675, %r676 }, { %r719, %r720 }, { %r707, %r708, %r709, %r710 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r721, %r722, %r723, %r724 }, { %r729, %r730, %r731, %r732 }, { %r677, %r678 }, { %r721, %r722, %r723, %r724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r735, %r736, %r737, %r738 }, { %r729, %r730, %r731, %r732 }, { %r691, %r692 }, { %r735, %r736, %r737, %r738 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r749, %r750, %r751, %r752 }, { %r729, %r730, %r731, %r732 }, { %r705, %r706 }, { %r749, %r750, %r751, %r752 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r763, %r764, %r765, %r766 }, { %r729, %r730, %r731, %r732 }, { %r719, %r720 }, { %r763, %r764, %r765, %r766 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r777, %r778, %r779, %r780 }, { %r785, %r786, %r787, %r788 }, { %r677, %r678 }, { %r777, %r778, %r779, %r780 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r791, %r792, %r793, %r794 }, { %r785, %r786, %r787, %r788 }, { %r691, %r692 }, { %r791, %r792, %r793, %r794 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r805, %r806, %r807, %r808 }, { %r785, %r786, %r787, %r788 }, { %r705, %r706 }, { %r805, %r806, %r807, %r808 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r819, %r820, %r821, %r822 }, { %r785, %r786, %r787, %r788 }, { %r719, %r720 }, { %r819, %r820, %r821, %r822 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r609, %r610, %r611, %r612 }, { %r841, %r842, %r843, %r844 }, { %r901, %r902 }, { %r609, %r610, %r611, %r612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r623, %r624, %r625, %r626 }, { %r841, %r842, %r843, %r844 }, { %r915, %r916 }, { %r623, %r624, %r625, %r626 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r637, %r638, %r639, %r640 }, { %r841, %r842, %r843, %r844 }, { %r929, %r930 }, { %r637, %r638, %r639, %r640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r651, %r652, %r653, %r654 }, { %r841, %r842, %r843, %r844 }, { %r943, %r944 }, { %r651, %r652, %r653, %r654 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r665, %r666, %r667, %r668 }, { %r897, %r898, %r899, %r900 }, { %r901, %r902 }, { %r665, %r666, %r667, %r668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r679, %r680, %r681, %r682 }, { %r897, %r898, %r899, %r900 }, { %r915, %r916 }, { %r679, %r680, %r681, %r682 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r693, %r694, %r695, %r696 }, { %r897, %r898, %r899, %r900 }, { %r929, %r930 }, { %r693, %r694, %r695, %r696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r707, %r708, %r709, %r710 }, { %r897, %r898, %r899, %r900 }, { %r943, %r944 }, { %r707, %r708, %r709, %r710 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r721, %r722, %r723, %r724 }, { %r953, %r954, %r955, %r956 }, { %r901, %r902 }, { %r721, %r722, %r723, %r724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r735, %r736, %r737, %r738 }, { %r953, %r954, %r955, %r956 }, { %r915, %r916 }, { %r735, %r736, %r737, %r738 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r749, %r750, %r751, %r752 }, { %r953, %r954, %r955, %r956 }, { %r929, %r930 }, { %r749, %r750, %r751, %r752 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r763, %r764, %r765, %r766 }, { %r953, %r954, %r955, %r956 }, { %r943, %r944 }, { %r763, %r764, %r765, %r766 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r777, %r778, %r779, %r780 }, { %r1009, %r1010, %r1011, %r1012 }, { %r901, %r902 }, { %r777, %r778, %r779, %r780 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r791, %r792, %r793, %r794 }, { %r1009, %r1010, %r1011, %r1012 }, { %r915, %r916 }, { %r791, %r792, %r793, %r794 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r805, %r806, %r807, %r808 }, { %r1009, %r1010, %r1011, %r1012 }, { %r929, %r930 }, { %r805, %r806, %r807, %r808 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r819, %r820, %r821, %r822 }, { %r1009, %r1010, %r1011, %r1012 }, { %r943, %r944 }, { %r819, %r820, %r821, %r822 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r609, %r610, %r611, %r612 }, { %r1065, %r1066, %r1067, %r1068 }, { %r1125, %r1126 }, { %r609, %r610, %r611, %r612 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r623, %r624, %r625, %r626 }, { %r1065, %r1066, %r1067, %r1068 }, { %r1139, %r1140 }, { %r623, %r624, %r625, %r626 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r637, %r638, %r639, %r640 }, { %r1065, %r1066, %r1067, %r1068 }, { %r1153, %r1154 }, { %r637, %r638, %r639, %r640 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r651, %r652, %r653, %r654 }, { %r1065, %r1066, %r1067, %r1068 }, { %r1167, %r1168 }, { %r651, %r652, %r653, %r654 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r665, %r666, %r667, %r668 }, { %r1121, %r1122, %r1123, %r1124 }, { %r1125, %r1126 }, { %r665, %r666, %r667, %r668 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r679, %r680, %r681, %r682 }, { %r1121, %r1122, %r1123, %r1124 }, { %r1139, %r1140 }, { %r679, %r680, %r681, %r682 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r693, %r694, %r695, %r696 }, { %r1121, %r1122, %r1123, %r1124 }, { %r1153, %r1154 }, { %r693, %r694, %r695, %r696 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r707, %r708, %r709, %r710 }, { %r1121, %r1122, %r1123, %r1124 }, { %r1167, %r1168 }, { %r707, %r708, %r709, %r710 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r721, %r722, %r723, %r724 }, { %r1177, %r1178, %r1179, %r1180 }, { %r1125, %r1126 }, { %r721, %r722, %r723, %r724 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r735, %r736, %r737, %r738 }, { %r1177, %r1178, %r1179, %r1180 }, { %r1139, %r1140 }, { %r735, %r736, %r737, %r738 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r749, %r750, %r751, %r752 }, { %r1177, %r1178, %r1179, %r1180 }, { %r1153, %r1154 }, { %r749, %r750, %r751, %r752 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r763, %r764, %r765, %r766 }, { %r1177, %r1178, %r1179, %r1180 }, { %r1167, %r1168 }, { %r763, %r764, %r765, %r766 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r777, %r778, %r779, %r780 }, { %r1233, %r1234, %r1235, %r1236 }, { %r1125, %r1126 }, { %r777, %r778, %r779, %r780 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r791, %r792, %r793, %r794 }, { %r1233, %r1234, %r1235, %r1236 }, { %r1139, %r1140 }, { %r791, %r792, %r793, %r794 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r805, %r806, %r807, %r808 }, { %r1233, %r1234, %r1235, %r1236 }, { %r1153, %r1154 }, { %r805, %r806, %r807, %r808 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r819, %r820, %r821, %r822 }, { %r1233, %r1234, %r1235, %r1236 }, { %r1167, %r1168 }, { %r819, %r820, %r821, %r822 };
	// end inline asm
	.loc	1 186 29                        // wy_fast.py:186:29
	cvt.rn.bf16x2.f32 	%r1340, %r610, %r609;
	cvt.rn.bf16x2.f32 	%r1341, %r612, %r611;
	cvt.rn.bf16x2.f32 	%r1342, %r624, %r623;
	cvt.rn.bf16x2.f32 	%r1343, %r626, %r625;
	cvt.rn.bf16x2.f32 	%r1344, %r638, %r637;
	cvt.rn.bf16x2.f32 	%r1345, %r640, %r639;
	cvt.rn.bf16x2.f32 	%r1346, %r652, %r651;
	cvt.rn.bf16x2.f32 	%r1347, %r654, %r653;
	cvt.rn.bf16x2.f32 	%r1348, %r666, %r665;
	cvt.rn.bf16x2.f32 	%r1349, %r668, %r667;
	cvt.rn.bf16x2.f32 	%r1350, %r680, %r679;
	cvt.rn.bf16x2.f32 	%r1351, %r682, %r681;
	cvt.rn.bf16x2.f32 	%r1352, %r694, %r693;
	cvt.rn.bf16x2.f32 	%r1353, %r696, %r695;
	cvt.rn.bf16x2.f32 	%r1354, %r708, %r707;
	cvt.rn.bf16x2.f32 	%r1355, %r710, %r709;
	cvt.rn.bf16x2.f32 	%r1356, %r722, %r721;
	cvt.rn.bf16x2.f32 	%r1357, %r724, %r723;
	cvt.rn.bf16x2.f32 	%r1358, %r736, %r735;
	cvt.rn.bf16x2.f32 	%r1359, %r738, %r737;
	cvt.rn.bf16x2.f32 	%r1360, %r750, %r749;
	cvt.rn.bf16x2.f32 	%r1361, %r752, %r751;
	cvt.rn.bf16x2.f32 	%r1362, %r764, %r763;
	cvt.rn.bf16x2.f32 	%r1363, %r766, %r765;
	cvt.rn.bf16x2.f32 	%r1364, %r778, %r777;
	cvt.rn.bf16x2.f32 	%r1365, %r780, %r779;
	cvt.rn.bf16x2.f32 	%r1366, %r792, %r791;
	cvt.rn.bf16x2.f32 	%r1367, %r794, %r793;
	cvt.rn.bf16x2.f32 	%r1368, %r806, %r805;
	cvt.rn.bf16x2.f32 	%r1369, %r808, %r807;
	cvt.rn.bf16x2.f32 	%r1370, %r820, %r819;
	cvt.rn.bf16x2.f32 	%r1371, %r822, %r821;
	.loc	1 186 22                        // wy_fast.py:186:22
	shl.b64 	%rd186, %rd292, 1;
	add.s64 	%rd169, %rd13, %rd186;
	shl.b64 	%rd187, %rd293, 1;
	add.s64 	%rd170, %rd13, %rd187;
	shl.b64 	%rd188, %rd294, 1;
	add.s64 	%rd171, %rd13, %rd188;
	shl.b64 	%rd189, %rd295, 1;
	add.s64 	%rd172, %rd13, %rd189;
	shl.b64 	%rd190, %rd296, 1;
	add.s64 	%rd173, %rd13, %rd190;
	shl.b64 	%rd191, %rd297, 1;
	add.s64 	%rd174, %rd13, %rd191;
	shl.b64 	%rd192, %rd298, 1;
	add.s64 	%rd175, %rd13, %rd192;
	shl.b64 	%rd193, %rd299, 1;
	add.s64 	%rd176, %rd13, %rd193;
	st.shared.b32 	[%r60], %r1340;
	st.shared.b32 	[%r61+1024], %r1341;
	st.shared.b32 	[%r60+32], %r1342;
	st.shared.b32 	[%r61+1056], %r1343;
	st.shared.b32 	[%r60+64], %r1344;
	st.shared.b32 	[%r61+1088], %r1345;
	st.shared.b32 	[%r60+96], %r1346;
	st.shared.b32 	[%r61+1120], %r1347;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1281, %r1282, %r1283, %r1284}, [%r65];
	ld.shared.v4.b32 	{%r1285, %r1286, %r1287, %r1288}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r1348;
	st.shared.b32 	[%r61+1024], %r1349;
	st.shared.b32 	[%r60+32], %r1350;
	st.shared.b32 	[%r61+1056], %r1351;
	st.shared.b32 	[%r60+64], %r1352;
	st.shared.b32 	[%r61+1088], %r1353;
	st.shared.b32 	[%r60+96], %r1354;
	st.shared.b32 	[%r61+1120], %r1355;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1289, %r1290, %r1291, %r1292}, [%r65];
	ld.shared.v4.b32 	{%r1293, %r1294, %r1295, %r1296}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r1356;
	st.shared.b32 	[%r61+1024], %r1357;
	st.shared.b32 	[%r60+32], %r1358;
	st.shared.b32 	[%r61+1056], %r1359;
	st.shared.b32 	[%r60+64], %r1360;
	st.shared.b32 	[%r61+1088], %r1361;
	st.shared.b32 	[%r60+96], %r1362;
	st.shared.b32 	[%r61+1120], %r1363;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1297, %r1298, %r1299, %r1300}, [%r65];
	ld.shared.v4.b32 	{%r1301, %r1302, %r1303, %r1304}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r1364;
	st.shared.b32 	[%r61+1024], %r1365;
	st.shared.b32 	[%r60+32], %r1366;
	st.shared.b32 	[%r61+1056], %r1367;
	st.shared.b32 	[%r60+64], %r1368;
	st.shared.b32 	[%r61+1088], %r1369;
	st.shared.b32 	[%r60+96], %r1370;
	st.shared.b32 	[%r61+1120], %r1371;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1305, %r1306, %r1307, %r1308}, [%r65];
	ld.shared.v4.b32 	{%r1309, %r1310, %r1311, %r1312}, [%r66+1024];
	// begin inline asm
	@%p97 st.global.v4.b32 [ %rd169 + 0 ], { %r1281, %r1282, %r1283, %r1284 };
	// end inline asm
	// begin inline asm
	@%p98 st.global.v4.b32 [ %rd170 + 0 ], { %r1285, %r1286, %r1287, %r1288 };
	// end inline asm
	// begin inline asm
	@%p99 st.global.v4.b32 [ %rd171 + 0 ], { %r1289, %r1290, %r1291, %r1292 };
	// end inline asm
	// begin inline asm
	@%p100 st.global.v4.b32 [ %rd172 + 0 ], { %r1293, %r1294, %r1295, %r1296 };
	// end inline asm
	// begin inline asm
	@%p101 st.global.v4.b32 [ %rd173 + 0 ], { %r1297, %r1298, %r1299, %r1300 };
	// end inline asm
	// begin inline asm
	@%p102 st.global.v4.b32 [ %rd174 + 0 ], { %r1301, %r1302, %r1303, %r1304 };
	// end inline asm
	// begin inline asm
	@%p103 st.global.v4.b32 [ %rd175 + 0 ], { %r1305, %r1306, %r1307, %r1308 };
	// end inline asm
	// begin inline asm
	@%p104 st.global.v4.b32 [ %rd176 + 0 ], { %r1309, %r1310, %r1311, %r1312 };
	// end inline asm
	.loc	1 180 21                        // wy_fast.py:180:21
	add.s32 	%r1372, %r2690, 1;
	setp.gt.s32 	%p74, %r1372, 1;
	selp.b32 	%r2690, 0, %r1372, %p74;
	.loc	1 183 22                        // wy_fast.py:183:22
	or.b64 	%rd194, %rd283, %rd1;
	or.b64 	%rd284, %rd194, %rd3;
	or.b64 	%rd285, %rd194, %rd4;
	or.b64 	%rd286, %rd194, %rd5;
	or.b64 	%rd287, %rd194, %rd6;
	or.b64 	%rd288, %rd194, %rd7;
	or.b64 	%rd289, %rd194, %rd8;
	or.b64 	%rd290, %rd194, %rd9;
	or.b64 	%rd291, %rd194, %rd10;
	shl.b64 	%rd195, %rd284, 1;
	add.s64 	%rd177, %rd12, %rd195;
	shl.b64 	%rd196, %rd285, 1;
	add.s64 	%rd178, %rd12, %rd196;
	shl.b64 	%rd197, %rd286, 1;
	add.s64 	%rd179, %rd12, %rd197;
	shl.b64 	%rd198, %rd287, 1;
	add.s64 	%rd180, %rd12, %rd198;
	shl.b64 	%rd199, %rd288, 1;
	add.s64 	%rd181, %rd12, %rd199;
	shl.b64 	%rd200, %rd289, 1;
	add.s64 	%rd182, %rd12, %rd200;
	shl.b64 	%rd201, %rd290, 1;
	add.s64 	%rd183, %rd12, %rd201;
	shl.b64 	%rd202, %rd291, 1;
	add.s64 	%rd184, %rd12, %rd202;
	shl.b32 	%r1373, %r2690, 13;
	add.s32 	%r1374, %r194, %r1373;
	add.s32 	%r1313, %r1374, %r202;
	add.s32 	%r1315, %r1313, 1024;
	add.s32 	%r1317, %r1313, 2048;
	add.s32 	%r1319, %r1313, 3072;
	add.s32 	%r1321, %r1313, 4096;
	add.s32 	%r1323, %r1313, 5120;
	add.s32 	%r1325, %r1313, 6144;
	add.s32 	%r1327, %r1313, 7168;
	// begin inline asm
	cp.async.cg.shared.global [ %r1313 + 0 ], [ %rd177 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1315 + 0 ], [ %rd178 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1317 + 0 ], [ %rd179 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1319 + 0 ], [ %rd180 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1321 + 0 ], [ %rd181 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1323 + 0 ], [ %rd182 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1325 + 0 ], [ %rd183 + 0 ], 0x10, %r389;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1327 + 0 ], [ %rd184 + 0 ], 0x10, %r389;
	// end inline asm
	cp.async.commit_group;
	mov.b64 	%rd283, 192;
	mov.pred 	%p88, 0;
	mov.pred 	%p89, %p88;
	mov.pred 	%p90, %p88;
	mov.pred 	%p91, %p88;
	mov.pred 	%p92, %p88;
	mov.pred 	%p93, %p88;
	mov.pred 	%p94, %p88;
	mov.pred 	%p95, %p88;
	mov.pred 	%p96, %p88;
	mov.pred 	%p97, %p11;
	mov.pred 	%p98, %p12;
	mov.pred 	%p99, %p13;
	mov.pred 	%p100, %p14;
	mov.pred 	%p101, %p15;
	mov.pred 	%p102, %p16;
	mov.pred 	%p103, %p17;
	mov.pred 	%p104, %p18;
	mov.b64 	%rd292, %rd39;
	mov.b64 	%rd293, %rd40;
	mov.b64 	%rd294, %rd41;
	mov.b64 	%rd295, %rd42;
	mov.b64 	%rd296, %rd43;
	mov.b64 	%rd297, %rd44;
	mov.b64 	%rd298, %rd45;
	mov.b64 	%rd299, %rd46;
	.loc	1 180 21                        // wy_fast.py:180:21
	@%p10 bra 	$L__BB0_1;
// %bb.2:
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 189 37                        // wy_fast.py:189:37
	mul.wide.s32 	%rd221, %r11, 4;
	add.s64 	%rd222, %rd92, %rd221;
	.loc	1 190 26                        // wy_fast.py:190:26
	shl.b64 	%rd223, %rd2, 2;
	add.s64 	%rd203, %rd222, %rd223;
	// begin inline asm
	mov.u32 %r1376, 0x0;
	@%p75 ld.global.b32 { %r1376 }, [ %rd203 + 0 ];
	// end inline asm
	.loc	1 190 18                        // wy_fast.py:190:18
	mul.f32 	%r1411, %r1376, 0f3FB8AA3B;
	ex2.approx.f32 	%r1412, %r1411;
	shl.b32 	%r1413, %r1, 2;
	add.s32 	%r1415, %r194, %r1413;
	st.shared.b32 	[%r1415], %r1412;
	bar.sync 	0;
	shl.b32 	%r1416, %r2, 2;
	add.s32 	%r1417, %r194, %r1416;
	ld.shared.v2.b32 	{%r101, %r102}, [%r1417];
	ld.shared.v2.b32 	{%r99, %r100}, [%r1417+32];
	ld.shared.v2.b32 	{%r97, %r98}, [%r1417+64];
	ld.shared.v2.b32 	{%r95, %r96}, [%r1417+96];
	ld.shared.v2.b32 	{%r93, %r94}, [%r1417+128];
	ld.shared.v2.b32 	{%r91, %r92}, [%r1417+160];
	ld.shared.v2.b32 	{%r89, %r90}, [%r1417+192];
	ld.shared.v2.b32 	{%r87, %r88}, [%r1417+224];
	.loc	1 193 36                        // wy_fast.py:193:36
	shl.b64 	%rd224, %rd11, 1;
	add.s64 	%rd63, %rd90, %rd224;
	.loc	1 194 36                        // wy_fast.py:194:36
	add.s64 	%rd64, %rd91, %rd224;
	.loc	1 195 22                        // wy_fast.py:195:22
	add.s64 	%rd204, %rd63, %rd160;
	add.s64 	%rd205, %rd63, %rd161;
	add.s64 	%rd206, %rd63, %rd162;
	add.s64 	%rd207, %rd63, %rd163;
	add.s64 	%rd208, %rd63, %rd164;
	add.s64 	%rd209, %rd63, %rd165;
	add.s64 	%rd210, %rd63, %rd166;
	add.s64 	%rd211, %rd63, %rd167;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r1377 + 0 ], [ %rd204 + 0 ], 0x10, %r21;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1379 + 0 ], [ %rd205 + 0 ], 0x10, %r22;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1381 + 0 ], [ %rd206 + 0 ], 0x10, %r23;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1383 + 0 ], [ %rd207 + 0 ], 0x10, %r24;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1385 + 0 ], [ %rd208 + 0 ], 0x10, %r25;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1387 + 0 ], [ %rd209 + 0 ], 0x10, %r26;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1389 + 0 ], [ %rd210 + 0 ], 0x10, %r27;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r1391 + 0 ], [ %rd211 + 0 ], 0x10, %r28;
	// end inline asm
	cp.async.commit_group;
	add.s64 	%rd212, %rd204, 128;
	add.s64 	%rd213, %rd205, 128;
	add.s64 	%rd214, %rd206, 128;
	add.s64 	%rd215, %rd207, 128;
	add.s64 	%rd216, %rd208, 128;
	add.s64 	%rd217, %rd209, 128;
	add.s64 	%rd218, %rd210, 128;
	add.s64 	%rd219, %rd211, 128;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r155 + 0 ], [ %rd212 + 0 ], 0x10, %r21;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r157 + 0 ], [ %rd213 + 0 ], 0x10, %r22;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r159 + 0 ], [ %rd214 + 0 ], 0x10, %r23;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r161 + 0 ], [ %rd215 + 0 ], 0x10, %r24;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r163 + 0 ], [ %rd216 + 0 ], 0x10, %r25;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r165 + 0 ], [ %rd217 + 0 ], 0x10, %r26;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r167 + 0 ], [ %rd218 + 0 ], 0x10, %r27;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r169 + 0 ], [ %rd219 + 0 ], 0x10, %r28;
	// end inline asm
	cp.async.commit_group;
	mov.b32 	%r2692, 1;
	mov.b32 	%r2691, -1;
	mov.b64 	%rd300, 128;
	mov.pred 	%p105, -1;
	mov.pred 	%p114, %p106;
	mov.pred 	%p115, %p107;
	mov.pred 	%p116, %p108;
	mov.pred 	%p117, %p109;
	mov.pred 	%p118, %p110;
	mov.pred 	%p119, %p111;
	mov.pred 	%p120, %p112;
	mov.pred 	%p121, %p113;
$L__BB0_3:                              // =>This Inner Loop Header: Depth=1
	.loc	1 0 22                          // wy_fast.py:0:22
	mov.b64 	%rd73, %rd308;
	mov.b64 	%rd72, %rd307;
	mov.b64 	%rd71, %rd306;
	mov.b64 	%rd70, %rd305;
	mov.b64 	%rd69, %rd304;
	mov.b64 	%rd68, %rd303;
	mov.b64 	%rd67, %rd302;
	mov.b64 	%rd66, %rd301;
	mov.pred 	%p35, %p113;
	mov.pred 	%p34, %p112;
	mov.pred 	%p33, %p111;
	mov.pred 	%p32, %p110;
	mov.pred 	%p31, %p109;
	mov.pred 	%p30, %p108;
	mov.pred 	%p29, %p107;
	mov.pred 	%p28, %p106;
	mov.pred 	%p27, %p105;
	.loc	1 192 21                        // wy_fast.py:192:21
	add.s32 	%r2482, %r2691, 1;
	setp.gt.s32 	%p86, %r2482, 1;
	selp.b32 	%r2691, 0, %r2482, %p86;
	.loc	1 195 22                        // wy_fast.py:195:22
	cp.async.wait_group 	1;
	bar.sync 	0;
	shl.b32 	%r2483, %r2691, 13;
	add.s32 	%r2485, %r194, %r2483;
	.loc	1 202 34                        // wy_fast.py:202:34
	add.s32 	%r1422, %r2485, %r1333;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1418, %r1419, %r1420, %r1421}, [%r1422];
	// end inline asm
	add.s32 	%r1427, %r1422, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1423, %r1424, %r1425, %r1426}, [%r1427];
	// end inline asm
	add.s32 	%r1432, %r2485, %r1334;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1428, %r1429, %r1430, %r1431}, [%r1432];
	// end inline asm
	add.s32 	%r1437, %r2485, %r1335;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1433, %r1434, %r1435, %r1436}, [%r1437];
	// end inline asm
	add.s32 	%r1442, %r2485, %r1336;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1438, %r1439, %r1440, %r1441}, [%r1442];
	// end inline asm
	add.s32 	%r1447, %r2485, %r1337;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1443, %r1444, %r1445, %r1446}, [%r1447];
	// end inline asm
	add.s32 	%r1452, %r2485, %r1338;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1448, %r1449, %r1450, %r1451}, [%r1452];
	// end inline asm
	add.s32 	%r1457, %r2485, %r1339;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1453, %r1454, %r1455, %r1456}, [%r1457];
	// end inline asm
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2493, %r3, %r1418;
	mov.b32 	{%rs2, %rs3}, %r2493;
	mul.bf16x2 	%r2494, %r4, %r1419;
	mov.b32 	{%rs4, %rs5}, %r2494;
	mul.bf16x2 	%r2495, %r5, %r1420;
	mov.b32 	{%rs6, %rs7}, %r2495;
	mul.bf16x2 	%r2496, %r6, %r1421;
	mov.b32 	{%rs8, %rs9}, %r2496;
	mul.bf16x2 	%r2497, %r7, %r1423;
	mov.b32 	{%rs10, %rs11}, %r2497;
	mul.bf16x2 	%r2498, %r8, %r1424;
	mov.b32 	{%rs12, %rs13}, %r2498;
	mul.bf16x2 	%r2499, %r9, %r1425;
	mov.b32 	{%rs14, %rs15}, %r2499;
	mul.bf16x2 	%r2500, %r10, %r1426;
	mov.b32 	{%rs16, %rs17}, %r2500;
	mul.bf16x2 	%r2501, %r3, %r1428;
	mov.b32 	{%rs18, %rs19}, %r2501;
	mul.bf16x2 	%r2502, %r4, %r1429;
	mov.b32 	{%rs20, %rs21}, %r2502;
	mul.bf16x2 	%r2503, %r5, %r1430;
	mov.b32 	{%rs22, %rs23}, %r2503;
	mul.bf16x2 	%r2504, %r6, %r1431;
	mov.b32 	{%rs24, %rs25}, %r2504;
	mul.bf16x2 	%r2505, %r7, %r1433;
	mov.b32 	{%rs26, %rs27}, %r2505;
	mul.bf16x2 	%r2506, %r8, %r1434;
	mov.b32 	{%rs28, %rs29}, %r2506;
	mul.bf16x2 	%r2507, %r9, %r1435;
	mov.b32 	{%rs30, %rs31}, %r2507;
	mul.bf16x2 	%r2508, %r10, %r1436;
	mov.b32 	{%rs32, %rs33}, %r2508;
	mul.bf16x2 	%r2509, %r3, %r1438;
	mov.b32 	{%rs34, %rs35}, %r2509;
	mul.bf16x2 	%r2510, %r4, %r1439;
	mov.b32 	{%rs36, %rs37}, %r2510;
	mul.bf16x2 	%r2511, %r5, %r1440;
	mov.b32 	{%rs38, %rs39}, %r2511;
	mul.bf16x2 	%r2512, %r6, %r1441;
	mov.b32 	{%rs40, %rs41}, %r2512;
	mul.bf16x2 	%r2513, %r7, %r1443;
	mov.b32 	{%rs42, %rs43}, %r2513;
	mul.bf16x2 	%r2514, %r8, %r1444;
	mov.b32 	{%rs44, %rs45}, %r2514;
	mul.bf16x2 	%r2515, %r9, %r1445;
	mov.b32 	{%rs46, %rs47}, %r2515;
	mul.bf16x2 	%r2516, %r10, %r1446;
	mov.b32 	{%rs48, %rs49}, %r2516;
	.loc	1 198 20                        // wy_fast.py:198:20
	cvt.f32.bf16 	%r2517, %rs2;
	cvt.f32.bf16 	%r2518, %rs3;
	cvt.f32.bf16 	%r2519, %rs4;
	cvt.f32.bf16 	%r2520, %rs5;
	cvt.f32.bf16 	%r2521, %rs6;
	cvt.f32.bf16 	%r2522, %rs7;
	cvt.f32.bf16 	%r2523, %rs8;
	cvt.f32.bf16 	%r2524, %rs9;
	cvt.f32.bf16 	%r2525, %rs10;
	cvt.f32.bf16 	%r2526, %rs11;
	cvt.f32.bf16 	%r2527, %rs12;
	cvt.f32.bf16 	%r2528, %rs13;
	cvt.f32.bf16 	%r2529, %rs14;
	cvt.f32.bf16 	%r2530, %rs15;
	cvt.f32.bf16 	%r2531, %rs16;
	cvt.f32.bf16 	%r2532, %rs17;
	cvt.f32.bf16 	%r2533, %rs18;
	cvt.f32.bf16 	%r2534, %rs19;
	cvt.f32.bf16 	%r2535, %rs20;
	cvt.f32.bf16 	%r2536, %rs21;
	cvt.f32.bf16 	%r2537, %rs22;
	cvt.f32.bf16 	%r2538, %rs23;
	cvt.f32.bf16 	%r2539, %rs24;
	cvt.f32.bf16 	%r2540, %rs25;
	cvt.f32.bf16 	%r2541, %rs26;
	cvt.f32.bf16 	%r2542, %rs27;
	cvt.f32.bf16 	%r2543, %rs28;
	cvt.f32.bf16 	%r2544, %rs29;
	cvt.f32.bf16 	%r2545, %rs30;
	cvt.f32.bf16 	%r2546, %rs31;
	cvt.f32.bf16 	%r2547, %rs32;
	cvt.f32.bf16 	%r2548, %rs33;
	cvt.f32.bf16 	%r2549, %rs34;
	cvt.f32.bf16 	%r2550, %rs35;
	cvt.f32.bf16 	%r2551, %rs36;
	cvt.f32.bf16 	%r2552, %rs37;
	cvt.f32.bf16 	%r2553, %rs38;
	cvt.f32.bf16 	%r2554, %rs39;
	cvt.f32.bf16 	%r2555, %rs40;
	cvt.f32.bf16 	%r2556, %rs41;
	cvt.f32.bf16 	%r2557, %rs42;
	cvt.f32.bf16 	%r2558, %rs43;
	cvt.f32.bf16 	%r2559, %rs44;
	cvt.f32.bf16 	%r2560, %rs45;
	cvt.f32.bf16 	%r2561, %rs46;
	cvt.f32.bf16 	%r2562, %rs47;
	cvt.f32.bf16 	%r2563, %rs48;
	cvt.f32.bf16 	%r2564, %rs49;
	mul.f32 	%r2565, %r101, %r2517;
	mul.f32 	%r2566, %r102, %r2518;
	mul.f32 	%r2567, %r99, %r2519;
	mul.f32 	%r2568, %r100, %r2520;
	mul.f32 	%r2569, %r97, %r2521;
	mul.f32 	%r2570, %r98, %r2522;
	mul.f32 	%r2571, %r95, %r2523;
	mul.f32 	%r2572, %r96, %r2524;
	mul.f32 	%r2573, %r93, %r2525;
	mul.f32 	%r2574, %r94, %r2526;
	mul.f32 	%r2575, %r91, %r2527;
	mul.f32 	%r2576, %r92, %r2528;
	mul.f32 	%r2577, %r89, %r2529;
	mul.f32 	%r2578, %r90, %r2530;
	mul.f32 	%r2579, %r87, %r2531;
	mul.f32 	%r2580, %r88, %r2532;
	mul.f32 	%r2581, %r101, %r2533;
	mul.f32 	%r2582, %r102, %r2534;
	mul.f32 	%r2583, %r99, %r2535;
	mul.f32 	%r2584, %r100, %r2536;
	mul.f32 	%r2585, %r97, %r2537;
	mul.f32 	%r2586, %r98, %r2538;
	mul.f32 	%r2587, %r95, %r2539;
	mul.f32 	%r2588, %r96, %r2540;
	mul.f32 	%r2589, %r93, %r2541;
	mul.f32 	%r2590, %r94, %r2542;
	mul.f32 	%r2591, %r91, %r2543;
	mul.f32 	%r2592, %r92, %r2544;
	mul.f32 	%r2593, %r89, %r2545;
	mul.f32 	%r2594, %r90, %r2546;
	mul.f32 	%r2595, %r87, %r2547;
	mul.f32 	%r2596, %r88, %r2548;
	mul.f32 	%r2597, %r101, %r2549;
	mul.f32 	%r2598, %r102, %r2550;
	mul.f32 	%r2599, %r99, %r2551;
	mul.f32 	%r2600, %r100, %r2552;
	mul.f32 	%r2601, %r97, %r2553;
	mul.f32 	%r2602, %r98, %r2554;
	mul.f32 	%r2603, %r95, %r2555;
	mul.f32 	%r2604, %r96, %r2556;
	mul.f32 	%r2605, %r93, %r2557;
	mul.f32 	%r2606, %r94, %r2558;
	mul.f32 	%r2607, %r91, %r2559;
	mul.f32 	%r2608, %r92, %r2560;
	mul.f32 	%r2609, %r89, %r2561;
	mul.f32 	%r2610, %r90, %r2562;
	mul.f32 	%r2611, %r87, %r2563;
	mul.f32 	%r2612, %r88, %r2564;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2613, %r3, %r1448;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs50, %rs51}, %r2613;
	cvt.f32.bf16 	%r2614, %rs51;
	cvt.f32.bf16 	%r2615, %rs50;
	mul.f32 	%r2616, %r101, %r2615;
	mul.f32 	%r2617, %r102, %r2614;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1648, %r2617, %r2616;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2618, %r4, %r1449;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs52, %rs53}, %r2618;
	cvt.f32.bf16 	%r2619, %rs53;
	cvt.f32.bf16 	%r2620, %rs52;
	mul.f32 	%r2621, %r99, %r2620;
	mul.f32 	%r2622, %r100, %r2619;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1649, %r2622, %r2621;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2623, %r5, %r1450;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs54, %rs55}, %r2623;
	cvt.f32.bf16 	%r2624, %rs55;
	cvt.f32.bf16 	%r2625, %rs54;
	mul.f32 	%r2626, %r97, %r2625;
	mul.f32 	%r2627, %r98, %r2624;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1872, %r2627, %r2626;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2628, %r6, %r1451;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs56, %rs57}, %r2628;
	cvt.f32.bf16 	%r2629, %rs57;
	cvt.f32.bf16 	%r2630, %rs56;
	mul.f32 	%r2631, %r95, %r2630;
	mul.f32 	%r2632, %r96, %r2629;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r1873, %r2632, %r2631;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2633, %r7, %r1453;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs58, %rs59}, %r2633;
	cvt.f32.bf16 	%r2634, %rs59;
	cvt.f32.bf16 	%r2635, %rs58;
	mul.f32 	%r2636, %r93, %r2635;
	mul.f32 	%r2637, %r94, %r2634;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2096, %r2637, %r2636;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2638, %r8, %r1454;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs60, %rs61}, %r2638;
	cvt.f32.bf16 	%r2639, %rs61;
	cvt.f32.bf16 	%r2640, %rs60;
	mul.f32 	%r2641, %r91, %r2640;
	mul.f32 	%r2642, %r92, %r2639;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2097, %r2642, %r2641;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2643, %r9, %r1455;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs62, %rs63}, %r2643;
	cvt.f32.bf16 	%r2644, %rs63;
	cvt.f32.bf16 	%r2645, %rs62;
	mul.f32 	%r2646, %r89, %r2645;
	mul.f32 	%r2647, %r90, %r2644;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2320, %r2647, %r2646;
	.loc	1 196 21                        // wy_fast.py:196:21
	mul.bf16x2 	%r2648, %r10, %r1456;
	.loc	1 198 20                        // wy_fast.py:198:20
	mov.b32 	{%rs64, %rs65}, %r2648;
	cvt.f32.bf16 	%r2649, %rs65;
	cvt.f32.bf16 	%r2650, %rs64;
	mul.f32 	%r2651, %r87, %r2650;
	mul.f32 	%r2652, %r88, %r2649;
	.loc	1 202 34                        // wy_fast.py:202:34
	cvt.rn.bf16x2.f32 	%r2321, %r2652, %r2651;
	.loc	1 178 18                        // wy_fast.py:178:18
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1546, %r1547, %r1548, %r1549}, [%r309];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1770, %r1771, %r1772, %r1773}, [%r314];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1994, %r1995, %r1996, %r1997}, [%r319];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2218, %r2219, %r2220, %r2221}, [%r324];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1602, %r1603, %r1604, %r1605}, [%r329];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1826, %r1827, %r1828, %r1829}, [%r334];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2050, %r2051, %r2052, %r2053}, [%r339];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2274, %r2275, %r2276, %r2277}, [%r344];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1658, %r1659, %r1660, %r1661}, [%r349];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1882, %r1883, %r1884, %r1885}, [%r354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2106, %r2107, %r2108, %r2109}, [%r359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2330, %r2331, %r2332, %r2333}, [%r364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1714, %r1715, %r1716, %r1717}, [%r369];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1938, %r1939, %r1940, %r1941}, [%r374];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2162, %r2163, %r2164, %r2165}, [%r379];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2386, %r2387, %r2388, %r2389}, [%r384];
	// end inline asm
	.loc	1 202 26                        // wy_fast.py:202:26
	cvt.rn.bf16x2.f32 	%r1606, %r2566, %r2565;
	cvt.rn.bf16x2.f32 	%r1607, %r2568, %r2567;
	cvt.rn.bf16x2.f32 	%r1830, %r2570, %r2569;
	cvt.rn.bf16x2.f32 	%r1831, %r2572, %r2571;
	cvt.rn.bf16x2.f32 	%r2054, %r2574, %r2573;
	cvt.rn.bf16x2.f32 	%r2055, %r2576, %r2575;
	cvt.rn.bf16x2.f32 	%r2278, %r2578, %r2577;
	cvt.rn.bf16x2.f32 	%r2279, %r2580, %r2579;
	cvt.rn.bf16x2.f32 	%r1620, %r2582, %r2581;
	cvt.rn.bf16x2.f32 	%r1621, %r2584, %r2583;
	cvt.rn.bf16x2.f32 	%r1844, %r2586, %r2585;
	cvt.rn.bf16x2.f32 	%r1845, %r2588, %r2587;
	cvt.rn.bf16x2.f32 	%r2068, %r2590, %r2589;
	cvt.rn.bf16x2.f32 	%r2069, %r2592, %r2591;
	cvt.rn.bf16x2.f32 	%r2292, %r2594, %r2593;
	cvt.rn.bf16x2.f32 	%r2293, %r2596, %r2595;
	cvt.rn.bf16x2.f32 	%r1634, %r2598, %r2597;
	cvt.rn.bf16x2.f32 	%r1635, %r2600, %r2599;
	cvt.rn.bf16x2.f32 	%r1858, %r2602, %r2601;
	cvt.rn.bf16x2.f32 	%r1859, %r2604, %r2603;
	cvt.rn.bf16x2.f32 	%r2082, %r2606, %r2605;
	cvt.rn.bf16x2.f32 	%r2083, %r2608, %r2607;
	cvt.rn.bf16x2.f32 	%r2306, %r2610, %r2609;
	cvt.rn.bf16x2.f32 	%r2307, %r2612, %r2611;
	mov.b32 	%r1542, 0;
	mov.b32 	%r1762, %r1542;
	mov.b32 	%r1763, %r1542;
	mov.b32 	%r1764, %r1542;
	mov.b32 	%r1765, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1762, %r1763, %r1764, %r1765 }, { %r1546, %r1547, %r1548, %r1549 }, { %r1606, %r1607 }, { %r1762, %r1763, %r1764, %r1765 };
	// end inline asm
	mov.b32 	%r1776, %r1542;
	mov.b32 	%r1777, %r1542;
	mov.b32 	%r1778, %r1542;
	mov.b32 	%r1779, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1776, %r1777, %r1778, %r1779 }, { %r1546, %r1547, %r1548, %r1549 }, { %r1620, %r1621 }, { %r1776, %r1777, %r1778, %r1779 };
	// end inline asm
	mov.b32 	%r1790, %r1542;
	mov.b32 	%r1791, %r1542;
	mov.b32 	%r1792, %r1542;
	mov.b32 	%r1793, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1790, %r1791, %r1792, %r1793 }, { %r1546, %r1547, %r1548, %r1549 }, { %r1634, %r1635 }, { %r1790, %r1791, %r1792, %r1793 };
	// end inline asm
	mov.b32 	%r1804, %r1542;
	mov.b32 	%r1805, %r1542;
	mov.b32 	%r1806, %r1542;
	mov.b32 	%r1807, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1804, %r1805, %r1806, %r1807 }, { %r1546, %r1547, %r1548, %r1549 }, { %r1648, %r1649 }, { %r1804, %r1805, %r1806, %r1807 };
	// end inline asm
	mov.b32 	%r1818, %r1542;
	mov.b32 	%r1819, %r1542;
	mov.b32 	%r1820, %r1542;
	mov.b32 	%r1821, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1818, %r1819, %r1820, %r1821 }, { %r1602, %r1603, %r1604, %r1605 }, { %r1606, %r1607 }, { %r1818, %r1819, %r1820, %r1821 };
	// end inline asm
	mov.b32 	%r1832, %r1542;
	mov.b32 	%r1833, %r1542;
	mov.b32 	%r1834, %r1542;
	mov.b32 	%r1835, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1832, %r1833, %r1834, %r1835 }, { %r1602, %r1603, %r1604, %r1605 }, { %r1620, %r1621 }, { %r1832, %r1833, %r1834, %r1835 };
	// end inline asm
	mov.b32 	%r1846, %r1542;
	mov.b32 	%r1847, %r1542;
	mov.b32 	%r1848, %r1542;
	mov.b32 	%r1849, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1846, %r1847, %r1848, %r1849 }, { %r1602, %r1603, %r1604, %r1605 }, { %r1634, %r1635 }, { %r1846, %r1847, %r1848, %r1849 };
	// end inline asm
	mov.b32 	%r1860, %r1542;
	mov.b32 	%r1861, %r1542;
	mov.b32 	%r1862, %r1542;
	mov.b32 	%r1863, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1860, %r1861, %r1862, %r1863 }, { %r1602, %r1603, %r1604, %r1605 }, { %r1648, %r1649 }, { %r1860, %r1861, %r1862, %r1863 };
	// end inline asm
	mov.b32 	%r1874, %r1542;
	mov.b32 	%r1875, %r1542;
	mov.b32 	%r1876, %r1542;
	mov.b32 	%r1877, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1874, %r1875, %r1876, %r1877 }, { %r1658, %r1659, %r1660, %r1661 }, { %r1606, %r1607 }, { %r1874, %r1875, %r1876, %r1877 };
	// end inline asm
	mov.b32 	%r1888, %r1542;
	mov.b32 	%r1889, %r1542;
	mov.b32 	%r1890, %r1542;
	mov.b32 	%r1891, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1888, %r1889, %r1890, %r1891 }, { %r1658, %r1659, %r1660, %r1661 }, { %r1620, %r1621 }, { %r1888, %r1889, %r1890, %r1891 };
	// end inline asm
	mov.b32 	%r1902, %r1542;
	mov.b32 	%r1903, %r1542;
	mov.b32 	%r1904, %r1542;
	mov.b32 	%r1905, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1902, %r1903, %r1904, %r1905 }, { %r1658, %r1659, %r1660, %r1661 }, { %r1634, %r1635 }, { %r1902, %r1903, %r1904, %r1905 };
	// end inline asm
	mov.b32 	%r1916, %r1542;
	mov.b32 	%r1917, %r1542;
	mov.b32 	%r1918, %r1542;
	mov.b32 	%r1919, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1916, %r1917, %r1918, %r1919 }, { %r1658, %r1659, %r1660, %r1661 }, { %r1648, %r1649 }, { %r1916, %r1917, %r1918, %r1919 };
	// end inline asm
	mov.b32 	%r1930, %r1542;
	mov.b32 	%r1931, %r1542;
	mov.b32 	%r1932, %r1542;
	mov.b32 	%r1933, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1930, %r1931, %r1932, %r1933 }, { %r1714, %r1715, %r1716, %r1717 }, { %r1606, %r1607 }, { %r1930, %r1931, %r1932, %r1933 };
	// end inline asm
	mov.b32 	%r1944, %r1542;
	mov.b32 	%r1945, %r1542;
	mov.b32 	%r1946, %r1542;
	mov.b32 	%r1947, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1944, %r1945, %r1946, %r1947 }, { %r1714, %r1715, %r1716, %r1717 }, { %r1620, %r1621 }, { %r1944, %r1945, %r1946, %r1947 };
	// end inline asm
	mov.b32 	%r1958, %r1542;
	mov.b32 	%r1959, %r1542;
	mov.b32 	%r1960, %r1542;
	mov.b32 	%r1961, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1958, %r1959, %r1960, %r1961 }, { %r1714, %r1715, %r1716, %r1717 }, { %r1634, %r1635 }, { %r1958, %r1959, %r1960, %r1961 };
	// end inline asm
	mov.b32 	%r1972, %r1542;
	mov.b32 	%r1973, %r1542;
	mov.b32 	%r1974, %r1542;
	mov.b32 	%r1975, %r1542;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1972, %r1973, %r1974, %r1975 }, { %r1714, %r1715, %r1716, %r1717 }, { %r1648, %r1649 }, { %r1972, %r1973, %r1974, %r1975 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1762, %r1763, %r1764, %r1765 }, { %r1770, %r1771, %r1772, %r1773 }, { %r1830, %r1831 }, { %r1762, %r1763, %r1764, %r1765 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1776, %r1777, %r1778, %r1779 }, { %r1770, %r1771, %r1772, %r1773 }, { %r1844, %r1845 }, { %r1776, %r1777, %r1778, %r1779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1790, %r1791, %r1792, %r1793 }, { %r1770, %r1771, %r1772, %r1773 }, { %r1858, %r1859 }, { %r1790, %r1791, %r1792, %r1793 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1804, %r1805, %r1806, %r1807 }, { %r1770, %r1771, %r1772, %r1773 }, { %r1872, %r1873 }, { %r1804, %r1805, %r1806, %r1807 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1818, %r1819, %r1820, %r1821 }, { %r1826, %r1827, %r1828, %r1829 }, { %r1830, %r1831 }, { %r1818, %r1819, %r1820, %r1821 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1832, %r1833, %r1834, %r1835 }, { %r1826, %r1827, %r1828, %r1829 }, { %r1844, %r1845 }, { %r1832, %r1833, %r1834, %r1835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1846, %r1847, %r1848, %r1849 }, { %r1826, %r1827, %r1828, %r1829 }, { %r1858, %r1859 }, { %r1846, %r1847, %r1848, %r1849 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1860, %r1861, %r1862, %r1863 }, { %r1826, %r1827, %r1828, %r1829 }, { %r1872, %r1873 }, { %r1860, %r1861, %r1862, %r1863 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1874, %r1875, %r1876, %r1877 }, { %r1882, %r1883, %r1884, %r1885 }, { %r1830, %r1831 }, { %r1874, %r1875, %r1876, %r1877 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1888, %r1889, %r1890, %r1891 }, { %r1882, %r1883, %r1884, %r1885 }, { %r1844, %r1845 }, { %r1888, %r1889, %r1890, %r1891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1902, %r1903, %r1904, %r1905 }, { %r1882, %r1883, %r1884, %r1885 }, { %r1858, %r1859 }, { %r1902, %r1903, %r1904, %r1905 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1916, %r1917, %r1918, %r1919 }, { %r1882, %r1883, %r1884, %r1885 }, { %r1872, %r1873 }, { %r1916, %r1917, %r1918, %r1919 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1930, %r1931, %r1932, %r1933 }, { %r1938, %r1939, %r1940, %r1941 }, { %r1830, %r1831 }, { %r1930, %r1931, %r1932, %r1933 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1944, %r1945, %r1946, %r1947 }, { %r1938, %r1939, %r1940, %r1941 }, { %r1844, %r1845 }, { %r1944, %r1945, %r1946, %r1947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1958, %r1959, %r1960, %r1961 }, { %r1938, %r1939, %r1940, %r1941 }, { %r1858, %r1859 }, { %r1958, %r1959, %r1960, %r1961 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1972, %r1973, %r1974, %r1975 }, { %r1938, %r1939, %r1940, %r1941 }, { %r1872, %r1873 }, { %r1972, %r1973, %r1974, %r1975 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1762, %r1763, %r1764, %r1765 }, { %r1994, %r1995, %r1996, %r1997 }, { %r2054, %r2055 }, { %r1762, %r1763, %r1764, %r1765 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1776, %r1777, %r1778, %r1779 }, { %r1994, %r1995, %r1996, %r1997 }, { %r2068, %r2069 }, { %r1776, %r1777, %r1778, %r1779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1790, %r1791, %r1792, %r1793 }, { %r1994, %r1995, %r1996, %r1997 }, { %r2082, %r2083 }, { %r1790, %r1791, %r1792, %r1793 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1804, %r1805, %r1806, %r1807 }, { %r1994, %r1995, %r1996, %r1997 }, { %r2096, %r2097 }, { %r1804, %r1805, %r1806, %r1807 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1818, %r1819, %r1820, %r1821 }, { %r2050, %r2051, %r2052, %r2053 }, { %r2054, %r2055 }, { %r1818, %r1819, %r1820, %r1821 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1832, %r1833, %r1834, %r1835 }, { %r2050, %r2051, %r2052, %r2053 }, { %r2068, %r2069 }, { %r1832, %r1833, %r1834, %r1835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1846, %r1847, %r1848, %r1849 }, { %r2050, %r2051, %r2052, %r2053 }, { %r2082, %r2083 }, { %r1846, %r1847, %r1848, %r1849 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1860, %r1861, %r1862, %r1863 }, { %r2050, %r2051, %r2052, %r2053 }, { %r2096, %r2097 }, { %r1860, %r1861, %r1862, %r1863 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1874, %r1875, %r1876, %r1877 }, { %r2106, %r2107, %r2108, %r2109 }, { %r2054, %r2055 }, { %r1874, %r1875, %r1876, %r1877 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1888, %r1889, %r1890, %r1891 }, { %r2106, %r2107, %r2108, %r2109 }, { %r2068, %r2069 }, { %r1888, %r1889, %r1890, %r1891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1902, %r1903, %r1904, %r1905 }, { %r2106, %r2107, %r2108, %r2109 }, { %r2082, %r2083 }, { %r1902, %r1903, %r1904, %r1905 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1916, %r1917, %r1918, %r1919 }, { %r2106, %r2107, %r2108, %r2109 }, { %r2096, %r2097 }, { %r1916, %r1917, %r1918, %r1919 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1930, %r1931, %r1932, %r1933 }, { %r2162, %r2163, %r2164, %r2165 }, { %r2054, %r2055 }, { %r1930, %r1931, %r1932, %r1933 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1944, %r1945, %r1946, %r1947 }, { %r2162, %r2163, %r2164, %r2165 }, { %r2068, %r2069 }, { %r1944, %r1945, %r1946, %r1947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1958, %r1959, %r1960, %r1961 }, { %r2162, %r2163, %r2164, %r2165 }, { %r2082, %r2083 }, { %r1958, %r1959, %r1960, %r1961 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1972, %r1973, %r1974, %r1975 }, { %r2162, %r2163, %r2164, %r2165 }, { %r2096, %r2097 }, { %r1972, %r1973, %r1974, %r1975 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1762, %r1763, %r1764, %r1765 }, { %r2218, %r2219, %r2220, %r2221 }, { %r2278, %r2279 }, { %r1762, %r1763, %r1764, %r1765 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1776, %r1777, %r1778, %r1779 }, { %r2218, %r2219, %r2220, %r2221 }, { %r2292, %r2293 }, { %r1776, %r1777, %r1778, %r1779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1790, %r1791, %r1792, %r1793 }, { %r2218, %r2219, %r2220, %r2221 }, { %r2306, %r2307 }, { %r1790, %r1791, %r1792, %r1793 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1804, %r1805, %r1806, %r1807 }, { %r2218, %r2219, %r2220, %r2221 }, { %r2320, %r2321 }, { %r1804, %r1805, %r1806, %r1807 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1818, %r1819, %r1820, %r1821 }, { %r2274, %r2275, %r2276, %r2277 }, { %r2278, %r2279 }, { %r1818, %r1819, %r1820, %r1821 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1832, %r1833, %r1834, %r1835 }, { %r2274, %r2275, %r2276, %r2277 }, { %r2292, %r2293 }, { %r1832, %r1833, %r1834, %r1835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1846, %r1847, %r1848, %r1849 }, { %r2274, %r2275, %r2276, %r2277 }, { %r2306, %r2307 }, { %r1846, %r1847, %r1848, %r1849 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1860, %r1861, %r1862, %r1863 }, { %r2274, %r2275, %r2276, %r2277 }, { %r2320, %r2321 }, { %r1860, %r1861, %r1862, %r1863 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1874, %r1875, %r1876, %r1877 }, { %r2330, %r2331, %r2332, %r2333 }, { %r2278, %r2279 }, { %r1874, %r1875, %r1876, %r1877 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1888, %r1889, %r1890, %r1891 }, { %r2330, %r2331, %r2332, %r2333 }, { %r2292, %r2293 }, { %r1888, %r1889, %r1890, %r1891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1902, %r1903, %r1904, %r1905 }, { %r2330, %r2331, %r2332, %r2333 }, { %r2306, %r2307 }, { %r1902, %r1903, %r1904, %r1905 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1916, %r1917, %r1918, %r1919 }, { %r2330, %r2331, %r2332, %r2333 }, { %r2320, %r2321 }, { %r1916, %r1917, %r1918, %r1919 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1930, %r1931, %r1932, %r1933 }, { %r2386, %r2387, %r2388, %r2389 }, { %r2278, %r2279 }, { %r1930, %r1931, %r1932, %r1933 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1944, %r1945, %r1946, %r1947 }, { %r2386, %r2387, %r2388, %r2389 }, { %r2292, %r2293 }, { %r1944, %r1945, %r1946, %r1947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1958, %r1959, %r1960, %r1961 }, { %r2386, %r2387, %r2388, %r2389 }, { %r2306, %r2307 }, { %r1958, %r1959, %r1960, %r1961 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %r1972, %r1973, %r1974, %r1975 }, { %r2386, %r2387, %r2388, %r2389 }, { %r2320, %r2321 }, { %r1972, %r1973, %r1974, %r1975 };
	// end inline asm
	.loc	1 203 29                        // wy_fast.py:203:29
	cvt.rn.bf16x2.f32 	%r2653, %r1763, %r1762;
	cvt.rn.bf16x2.f32 	%r2654, %r1765, %r1764;
	cvt.rn.bf16x2.f32 	%r2655, %r1777, %r1776;
	cvt.rn.bf16x2.f32 	%r2656, %r1779, %r1778;
	cvt.rn.bf16x2.f32 	%r2657, %r1791, %r1790;
	cvt.rn.bf16x2.f32 	%r2658, %r1793, %r1792;
	cvt.rn.bf16x2.f32 	%r2659, %r1805, %r1804;
	cvt.rn.bf16x2.f32 	%r2660, %r1807, %r1806;
	cvt.rn.bf16x2.f32 	%r2661, %r1819, %r1818;
	cvt.rn.bf16x2.f32 	%r2662, %r1821, %r1820;
	cvt.rn.bf16x2.f32 	%r2663, %r1833, %r1832;
	cvt.rn.bf16x2.f32 	%r2664, %r1835, %r1834;
	cvt.rn.bf16x2.f32 	%r2665, %r1847, %r1846;
	cvt.rn.bf16x2.f32 	%r2666, %r1849, %r1848;
	cvt.rn.bf16x2.f32 	%r2667, %r1861, %r1860;
	cvt.rn.bf16x2.f32 	%r2668, %r1863, %r1862;
	cvt.rn.bf16x2.f32 	%r2669, %r1875, %r1874;
	cvt.rn.bf16x2.f32 	%r2670, %r1877, %r1876;
	cvt.rn.bf16x2.f32 	%r2671, %r1889, %r1888;
	cvt.rn.bf16x2.f32 	%r2672, %r1891, %r1890;
	cvt.rn.bf16x2.f32 	%r2673, %r1903, %r1902;
	cvt.rn.bf16x2.f32 	%r2674, %r1905, %r1904;
	cvt.rn.bf16x2.f32 	%r2675, %r1917, %r1916;
	cvt.rn.bf16x2.f32 	%r2676, %r1919, %r1918;
	cvt.rn.bf16x2.f32 	%r2677, %r1931, %r1930;
	cvt.rn.bf16x2.f32 	%r2678, %r1933, %r1932;
	cvt.rn.bf16x2.f32 	%r2679, %r1945, %r1944;
	cvt.rn.bf16x2.f32 	%r2680, %r1947, %r1946;
	cvt.rn.bf16x2.f32 	%r2681, %r1959, %r1958;
	cvt.rn.bf16x2.f32 	%r2682, %r1961, %r1960;
	cvt.rn.bf16x2.f32 	%r2683, %r1973, %r1972;
	cvt.rn.bf16x2.f32 	%r2684, %r1975, %r1974;
	.loc	1 203 22                        // wy_fast.py:203:22
	shl.b64 	%rd266, %rd309, 1;
	add.s64 	%rd249, %rd64, %rd266;
	shl.b64 	%rd267, %rd310, 1;
	add.s64 	%rd250, %rd64, %rd267;
	shl.b64 	%rd268, %rd311, 1;
	add.s64 	%rd251, %rd64, %rd268;
	shl.b64 	%rd269, %rd312, 1;
	add.s64 	%rd252, %rd64, %rd269;
	shl.b64 	%rd270, %rd313, 1;
	add.s64 	%rd253, %rd64, %rd270;
	shl.b64 	%rd271, %rd314, 1;
	add.s64 	%rd254, %rd64, %rd271;
	shl.b64 	%rd272, %rd315, 1;
	add.s64 	%rd255, %rd64, %rd272;
	shl.b64 	%rd273, %rd316, 1;
	add.s64 	%rd256, %rd64, %rd273;
	st.shared.b32 	[%r60], %r2653;
	st.shared.b32 	[%r61+1024], %r2654;
	st.shared.b32 	[%r60+32], %r2655;
	st.shared.b32 	[%r61+1056], %r2656;
	st.shared.b32 	[%r60+64], %r2657;
	st.shared.b32 	[%r61+1088], %r2658;
	st.shared.b32 	[%r60+96], %r2659;
	st.shared.b32 	[%r61+1120], %r2660;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2434, %r2435, %r2436, %r2437}, [%r65];
	ld.shared.v4.b32 	{%r2438, %r2439, %r2440, %r2441}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r2661;
	st.shared.b32 	[%r61+1024], %r2662;
	st.shared.b32 	[%r60+32], %r2663;
	st.shared.b32 	[%r61+1056], %r2664;
	st.shared.b32 	[%r60+64], %r2665;
	st.shared.b32 	[%r61+1088], %r2666;
	st.shared.b32 	[%r60+96], %r2667;
	st.shared.b32 	[%r61+1120], %r2668;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2442, %r2443, %r2444, %r2445}, [%r65];
	ld.shared.v4.b32 	{%r2446, %r2447, %r2448, %r2449}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r2669;
	st.shared.b32 	[%r61+1024], %r2670;
	st.shared.b32 	[%r60+32], %r2671;
	st.shared.b32 	[%r61+1056], %r2672;
	st.shared.b32 	[%r60+64], %r2673;
	st.shared.b32 	[%r61+1088], %r2674;
	st.shared.b32 	[%r60+96], %r2675;
	st.shared.b32 	[%r61+1120], %r2676;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2450, %r2451, %r2452, %r2453}, [%r65];
	ld.shared.v4.b32 	{%r2454, %r2455, %r2456, %r2457}, [%r66+1024];
	bar.sync 	0;
	st.shared.b32 	[%r60], %r2677;
	st.shared.b32 	[%r61+1024], %r2678;
	st.shared.b32 	[%r60+32], %r2679;
	st.shared.b32 	[%r61+1056], %r2680;
	st.shared.b32 	[%r60+64], %r2681;
	st.shared.b32 	[%r61+1088], %r2682;
	st.shared.b32 	[%r60+96], %r2683;
	st.shared.b32 	[%r61+1120], %r2684;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2458, %r2459, %r2460, %r2461}, [%r65];
	ld.shared.v4.b32 	{%r2462, %r2463, %r2464, %r2465}, [%r66+1024];
	// begin inline asm
	@%p114 st.global.v4.b32 [ %rd249 + 0 ], { %r2434, %r2435, %r2436, %r2437 };
	// end inline asm
	// begin inline asm
	@%p115 st.global.v4.b32 [ %rd250 + 0 ], { %r2438, %r2439, %r2440, %r2441 };
	// end inline asm
	// begin inline asm
	@%p116 st.global.v4.b32 [ %rd251 + 0 ], { %r2442, %r2443, %r2444, %r2445 };
	// end inline asm
	// begin inline asm
	@%p117 st.global.v4.b32 [ %rd252 + 0 ], { %r2446, %r2447, %r2448, %r2449 };
	// end inline asm
	// begin inline asm
	@%p118 st.global.v4.b32 [ %rd253 + 0 ], { %r2450, %r2451, %r2452, %r2453 };
	// end inline asm
	// begin inline asm
	@%p119 st.global.v4.b32 [ %rd254 + 0 ], { %r2454, %r2455, %r2456, %r2457 };
	// end inline asm
	// begin inline asm
	@%p120 st.global.v4.b32 [ %rd255 + 0 ], { %r2458, %r2459, %r2460, %r2461 };
	// end inline asm
	// begin inline asm
	@%p121 st.global.v4.b32 [ %rd256 + 0 ], { %r2462, %r2463, %r2464, %r2465 };
	// end inline asm
	.loc	1 192 21                        // wy_fast.py:192:21
	add.s32 	%r2685, %r2692, 1;
	setp.gt.s32 	%p87, %r2685, 1;
	selp.b32 	%r2692, 0, %r2685, %p87;
	.loc	1 195 22                        // wy_fast.py:195:22
	or.b64 	%rd274, %rd300, %rd1;
	or.b64 	%rd301, %rd274, %rd3;
	or.b64 	%rd302, %rd274, %rd4;
	or.b64 	%rd303, %rd274, %rd5;
	or.b64 	%rd304, %rd274, %rd6;
	or.b64 	%rd305, %rd274, %rd7;
	or.b64 	%rd306, %rd274, %rd8;
	or.b64 	%rd307, %rd274, %rd9;
	or.b64 	%rd308, %rd274, %rd10;
	shl.b64 	%rd275, %rd301, 1;
	add.s64 	%rd257, %rd63, %rd275;
	shl.b64 	%rd276, %rd302, 1;
	add.s64 	%rd258, %rd63, %rd276;
	shl.b64 	%rd277, %rd303, 1;
	add.s64 	%rd259, %rd63, %rd277;
	shl.b64 	%rd278, %rd304, 1;
	add.s64 	%rd260, %rd63, %rd278;
	shl.b64 	%rd279, %rd305, 1;
	add.s64 	%rd261, %rd63, %rd279;
	shl.b64 	%rd280, %rd306, 1;
	add.s64 	%rd262, %rd63, %rd280;
	shl.b64 	%rd281, %rd307, 1;
	add.s64 	%rd263, %rd63, %rd281;
	shl.b64 	%rd282, %rd308, 1;
	add.s64 	%rd264, %rd63, %rd282;
	shl.b32 	%r2686, %r2692, 13;
	add.s32 	%r2687, %r194, %r2686;
	add.s32 	%r2466, %r2687, %r202;
	add.s32 	%r2468, %r2466, 1024;
	add.s32 	%r2470, %r2466, 2048;
	add.s32 	%r2472, %r2466, 3072;
	add.s32 	%r2474, %r2466, 4096;
	add.s32 	%r2476, %r2466, 5120;
	add.s32 	%r2478, %r2466, 6144;
	add.s32 	%r2480, %r2466, 7168;
	// begin inline asm
	cp.async.cg.shared.global [ %r2466 + 0 ], [ %rd257 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2468 + 0 ], [ %rd258 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2470 + 0 ], [ %rd259 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2472 + 0 ], [ %rd260 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2474 + 0 ], [ %rd261 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2476 + 0 ], [ %rd262 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2478 + 0 ], [ %rd263 + 0 ], 0x10, %r1542;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2480 + 0 ], [ %rd264 + 0 ], 0x10, %r1542;
	// end inline asm
	cp.async.commit_group;
	mov.b64 	%rd300, 192;
	mov.pred 	%p105, 0;
	mov.pred 	%p106, %p105;
	mov.pred 	%p107, %p105;
	mov.pred 	%p108, %p105;
	mov.pred 	%p109, %p105;
	mov.pred 	%p110, %p105;
	mov.pred 	%p111, %p105;
	mov.pred 	%p112, %p105;
	mov.pred 	%p113, %p105;
	mov.pred 	%p114, %p28;
	mov.pred 	%p115, %p29;
	mov.pred 	%p116, %p30;
	mov.pred 	%p117, %p31;
	mov.pred 	%p118, %p32;
	mov.pred 	%p119, %p33;
	mov.pred 	%p120, %p34;
	mov.pred 	%p121, %p35;
	mov.b64 	%rd309, %rd66;
	mov.b64 	%rd310, %rd67;
	mov.b64 	%rd311, %rd68;
	mov.b64 	%rd312, %rd69;
	mov.b64 	%rd313, %rd70;
	mov.b64 	%rd314, %rd71;
	mov.b64 	%rd315, %rd72;
	mov.b64 	%rd316, %rd73;
	.loc	1 192 21                        // wy_fast.py:192:21
	@%p27 bra 	$L__BB0_3;
// %bb.4:
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 192 4                         // wy_fast.py:192:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/zeus/miniconda3/envs/cloudspace/lib/python3.13/site-packages/fla/ops/gated_delta_rule/wy_fast.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 124                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x75 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 119                                 // DW_AT_name
.b8 121
.b8 95
.b8 102
.b8 97
.b8 115
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 122
.b8 101
.b8 117
.b8 115
.b8 47
.b8 109
.b8 105
.b8 110
.b8 105
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 51
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 99
.b8 108
.b8 111
.b8 117
.b8 100
.b8 115
.b8 112
.b8 97
.b8 99
.b8 101
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 51
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 102
.b8 108
.b8 97
.b8 47
.b8 111
.b8 112
.b8 115
.b8 47
.b8 103
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 100
.b8 101
.b8 108
.b8 116
.b8 97
.b8 95
.b8 114
.b8 117
.b8 108
.b8 101
.b8 0
	}
	.section	.debug_macinfo	{	}
